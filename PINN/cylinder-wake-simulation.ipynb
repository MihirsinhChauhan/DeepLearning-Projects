{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NavierStokes(nn.Module):\n",
    "    \n",
    "    def __init__(self, X, Y, T, u, v):\n",
    "        super(NavierStokes,self).__init__()\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.t = T\n",
    "\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "\n",
    "        #null vector to test against f and g:\n",
    "        self.null = torch.zeros((self.x.shape[0], 1))\n",
    "\n",
    "        # initialize network:\n",
    "        self.network()\n",
    "\n",
    "        self.optimizer = torch.optim.LBFGS(self.net.parameters(), lr=1, max_iter=200000, max_eval=50000,\n",
    "                                           history_size=50, tolerance_grad=1e-05, tolerance_change=0.5 * np.finfo(float).eps,\n",
    "                                           line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "        #loss\n",
    "        self.ls = 0\n",
    "\n",
    "        #iteration number\n",
    "        self.iter = 0\n",
    "\n",
    "    def network(self):\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 2))\n",
    "\n",
    "    def function(self, x, y, t):\n",
    "\n",
    "        res = self.net(torch.hstack((x, y, t)))\n",
    "        psi, p = res[:, 0:1], res[:, 1:2]\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        u = torch.autograd.grad(psi, y, grad_outputs=torch.ones_like(psi), create_graph=True)[0] #retain_graph=True,\n",
    "        v = -1.*torch.autograd.grad(psi, x, grad_outputs=torch.ones_like(psi), create_graph=True)[0]\n",
    "\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "        u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=True)[0]\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "\n",
    "        v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "        v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "        v_t = torch.autograd.grad(v, t, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "\n",
    "        p_x = torch.autograd.grad(p, x, grad_outputs=torch.ones_like(p), create_graph=True)[0]\n",
    "        p_y = torch.autograd.grad(p, y, grad_outputs=torch.ones_like(p), create_graph=True)[0]\n",
    "\n",
    "        f = u_t + u * u_x + v * u_y + p_x - nu * (u_xx + u_yy)\n",
    "        g = v_t + u * v_x + v * v_y + p_y - nu * (v_xx + v_yy)\n",
    "\n",
    "        return u, v, p, f, g\n",
    "\n",
    "    def closure(self):\n",
    "        # reset gradients to zero:\n",
    "        self.optimizer.zero_grad()\n",
    "        # u, v, p, g and f predictions:\n",
    "        u_prediction, v_prediction, p_prediction, f_prediction, g_prediction = self.function(self.x, self.y, self.t)\n",
    "        \n",
    "        # calculate losses\n",
    "        u_loss = self.mse(u_prediction, self.u)\n",
    "        v_loss = self.mse(v_prediction, self.v)\n",
    "        f_loss = self.mse(f_prediction, self.null)\n",
    "        g_loss = self.mse(g_prediction, self.null)\n",
    "        self.ls = u_loss + v_loss + f_loss +g_loss\n",
    "\n",
    "        # derivative with respect to net's weights:\n",
    "        self.ls.backward()\n",
    "\n",
    "        self.iter += 1\n",
    "        if not self.iter % 1:\n",
    "            print('Iteration: {:}, Loss: {:0.6f}'.format(self.iter, self.ls))\n",
    "\n",
    "        return self.ls\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # training loop\n",
    "        self.net.train()\n",
    "        self.optimizer.step(self.closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('../../Data/cylinder_wake/cylinder_wake.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device selection\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_star = data['U_star']  # N x 2 x T\n",
    "P_star = data['p_star']  # N x T\n",
    "t_star = data['t']  # T x 1\n",
    "X_star = data['X_star']  # N x 2\n",
    "\n",
    "N = X_star.shape[0]\n",
    "T = t_star.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_star[:, 0:1]\n",
    "y_test = X_star[:, 1:2]\n",
    "p_test = P_star[:, 0:1]\n",
    "u_test = U_star[:, 0:1, 0]\n",
    "t_test = np.ones((x_test.shape[0], x_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange Data\n",
    "XX = np.tile(X_star[:, 0:1], (1, T))  # N x T\n",
    "YY = np.tile(X_star[:, 1:2], (1, T))  # N x T\n",
    "TT = np.tile(t_star, (1, N)).T  # N x T\n",
    "\n",
    "UU = U_star[:, 0, :]  # N x T\n",
    "VV = U_star[:, 1, :]  # N x T\n",
    "PP = P_star  # N x T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = XX.flatten()[:, None]  # NT x 1\n",
    "y = YY.flatten()[:, None]  # NT x 1\n",
    "t = TT.flatten()[:, None]  # NT x 1\n",
    "\n",
    "u = UU.flatten()[:, None]  # NT x 1\n",
    "v = VV.flatten()[:, None]  # NT x 1\n",
    "p = PP.flatten()[:, None]  # NT x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "idx = np.random.choice(N * T, N_train, replace=False)\n",
    "x_train = x[idx, :]\n",
    "y_train = y[idx, :]\n",
    "t_train = t[idx, :]\n",
    "u_train = u[idx, :]\n",
    "v_train = v[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32,requires_grad=True).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32,requires_grad=True).to(device)\n",
    "t_train = torch.tensor(t_train, dtype=torch.float32,requires_grad=True).to(device)\n",
    "u_train = torch.tensor(u_train, dtype=torch.float32).to(device)\n",
    "v_train = torch.tensor(v_train, dtype=torch.float32).to(device)\n",
    "\n",
    "# Test Data\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32,requires_grad=True).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32,requires_grad=True).to(device)\n",
    "t_test = torch.tensor(t_test, dtype=torch.float32,requires_grad=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NavierStokes(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=20, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (7): Tanh()\n",
       "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (9): Tanh()\n",
       "    (10): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (11): Tanh()\n",
       "    (12): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (13): Tanh()\n",
       "    (14): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (15): Tanh()\n",
       "    (16): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (17): Tanh()\n",
       "    (18): Linear(in_features=20, out_features=2, bias=True)\n",
       "  )\n",
       "  (mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "pinn = NavierStokes(x_train, y_train, t_train, u_train, v_train)\n",
    "pinn = pinn.to(device)\n",
    "pinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, Loss: 0.898912\n",
      "Iteration: 2, Loss: 0.898783\n",
      "Iteration: 3, Loss: 0.897850\n",
      "Iteration: 4, Loss: 0.893194\n",
      "Iteration: 5, Loss: 0.848900\n",
      "Iteration: 6, Loss: 0.848256\n",
      "Iteration: 7, Loss: 0.751983\n",
      "Iteration: 8, Loss: 0.822501\n",
      "Iteration: 9, Loss: 0.629336\n",
      "Iteration: 10, Loss: 15916610.000000\n",
      "Iteration: 11, Loss: 3008.065918\n",
      "Iteration: 12, Loss: 28.211763\n",
      "Iteration: 13, Loss: 2.177789\n",
      "Iteration: 14, Loss: 0.742137\n",
      "Iteration: 15, Loss: 0.628553\n",
      "Iteration: 16, Loss: 0.596936\n",
      "Iteration: 17, Loss: 0.632941\n",
      "Iteration: 18, Loss: 0.525937\n",
      "Iteration: 19, Loss: 0.479313\n",
      "Iteration: 20, Loss: 0.455035\n",
      "Iteration: 21, Loss: 0.423637\n",
      "Iteration: 22, Loss: 0.381270\n",
      "Iteration: 23, Loss: 0.326165\n",
      "Iteration: 24, Loss: 0.298281\n",
      "Iteration: 25, Loss: 0.286569\n",
      "Iteration: 26, Loss: 0.241110\n",
      "Iteration: 27, Loss: 0.206604\n",
      "Iteration: 28, Loss: 0.180500\n",
      "Iteration: 29, Loss: 0.500602\n",
      "Iteration: 30, Loss: 0.173189\n",
      "Iteration: 31, Loss: 0.171212\n",
      "Iteration: 32, Loss: 0.166556\n",
      "Iteration: 33, Loss: 0.161335\n",
      "Iteration: 34, Loss: 0.157003\n",
      "Iteration: 35, Loss: 0.153416\n",
      "Iteration: 36, Loss: 0.149534\n",
      "Iteration: 37, Loss: 0.140622\n",
      "Iteration: 38, Loss: 0.130309\n",
      "Iteration: 39, Loss: 0.123035\n",
      "Iteration: 40, Loss: 0.118623\n",
      "Iteration: 41, Loss: 0.116383\n",
      "Iteration: 42, Loss: 0.113568\n",
      "Iteration: 43, Loss: 0.111867\n",
      "Iteration: 44, Loss: 0.109222\n",
      "Iteration: 45, Loss: 0.106929\n",
      "Iteration: 46, Loss: 0.105991\n",
      "Iteration: 47, Loss: 0.104737\n",
      "Iteration: 48, Loss: 0.104055\n",
      "Iteration: 49, Loss: 0.102456\n",
      "Iteration: 50, Loss: 0.101350\n",
      "Iteration: 51, Loss: 0.099544\n",
      "Iteration: 52, Loss: 0.098551\n",
      "Iteration: 53, Loss: 0.097776\n",
      "Iteration: 54, Loss: 0.097102\n",
      "Iteration: 55, Loss: 0.096304\n",
      "Iteration: 56, Loss: 0.095634\n",
      "Iteration: 57, Loss: 0.094060\n",
      "Iteration: 58, Loss: 0.092562\n",
      "Iteration: 59, Loss: 0.091740\n",
      "Iteration: 60, Loss: 0.091326\n",
      "Iteration: 61, Loss: 0.091149\n",
      "Iteration: 62, Loss: 0.091020\n",
      "Iteration: 63, Loss: 0.090806\n",
      "Iteration: 64, Loss: 0.090528\n",
      "Iteration: 65, Loss: 0.090169\n",
      "Iteration: 66, Loss: 0.089672\n",
      "Iteration: 67, Loss: 0.089214\n",
      "Iteration: 68, Loss: 0.088376\n",
      "Iteration: 69, Loss: 0.087430\n",
      "Iteration: 70, Loss: 0.086816\n",
      "Iteration: 71, Loss: 0.086357\n",
      "Iteration: 72, Loss: 0.085972\n",
      "Iteration: 73, Loss: 0.085423\n",
      "Iteration: 74, Loss: 0.085056\n",
      "Iteration: 75, Loss: 0.084730\n",
      "Iteration: 76, Loss: 0.084469\n",
      "Iteration: 77, Loss: 0.084261\n",
      "Iteration: 78, Loss: 0.083977\n",
      "Iteration: 79, Loss: 0.083631\n",
      "Iteration: 80, Loss: 0.083371\n",
      "Iteration: 81, Loss: 0.083119\n",
      "Iteration: 82, Loss: 0.082917\n",
      "Iteration: 83, Loss: 0.082709\n",
      "Iteration: 84, Loss: 0.082333\n",
      "Iteration: 85, Loss: 0.082097\n",
      "Iteration: 86, Loss: 0.081681\n",
      "Iteration: 87, Loss: 0.081488\n",
      "Iteration: 88, Loss: 0.081305\n",
      "Iteration: 89, Loss: 0.081145\n",
      "Iteration: 90, Loss: 0.080996\n",
      "Iteration: 91, Loss: 0.080742\n",
      "Iteration: 92, Loss: 0.080657\n",
      "Iteration: 93, Loss: 0.080554\n",
      "Iteration: 94, Loss: 0.080356\n",
      "Iteration: 95, Loss: 0.080080\n",
      "Iteration: 96, Loss: 0.079541\n",
      "Iteration: 97, Loss: 0.079171\n",
      "Iteration: 98, Loss: 0.078755\n",
      "Iteration: 99, Loss: 0.078499\n",
      "Iteration: 100, Loss: 0.078114\n",
      "Iteration: 101, Loss: 0.077794\n",
      "Iteration: 102, Loss: 0.077484\n",
      "Iteration: 103, Loss: 0.077188\n",
      "Iteration: 104, Loss: 0.077061\n",
      "Iteration: 105, Loss: 0.076894\n",
      "Iteration: 106, Loss: 0.076600\n",
      "Iteration: 107, Loss: 0.076260\n",
      "Iteration: 108, Loss: 0.075827\n",
      "Iteration: 109, Loss: 0.075482\n",
      "Iteration: 110, Loss: 0.075244\n",
      "Iteration: 111, Loss: 0.075070\n",
      "Iteration: 112, Loss: 0.074858\n",
      "Iteration: 113, Loss: 0.074577\n",
      "Iteration: 114, Loss: 0.074275\n",
      "Iteration: 115, Loss: 0.074083\n",
      "Iteration: 116, Loss: 0.073931\n",
      "Iteration: 117, Loss: 0.073741\n",
      "Iteration: 118, Loss: 0.073606\n",
      "Iteration: 119, Loss: 0.073491\n",
      "Iteration: 120, Loss: 0.073333\n",
      "Iteration: 121, Loss: 0.073155\n",
      "Iteration: 122, Loss: 0.072913\n",
      "Iteration: 123, Loss: 0.072648\n",
      "Iteration: 124, Loss: 0.072570\n",
      "Iteration: 125, Loss: 0.072377\n",
      "Iteration: 126, Loss: 0.072201\n",
      "Iteration: 127, Loss: 0.071883\n",
      "Iteration: 128, Loss: 0.071596\n",
      "Iteration: 129, Loss: 0.071455\n",
      "Iteration: 130, Loss: 0.071351\n",
      "Iteration: 131, Loss: 0.071263\n",
      "Iteration: 132, Loss: 0.071150\n",
      "Iteration: 133, Loss: 0.070932\n",
      "Iteration: 134, Loss: 0.070752\n",
      "Iteration: 135, Loss: 0.070630\n",
      "Iteration: 136, Loss: 0.070580\n",
      "Iteration: 137, Loss: 0.070513\n",
      "Iteration: 138, Loss: 0.070408\n",
      "Iteration: 139, Loss: 0.070341\n",
      "Iteration: 140, Loss: 0.070193\n",
      "Iteration: 141, Loss: 0.070085\n",
      "Iteration: 142, Loss: 0.069979\n",
      "Iteration: 143, Loss: 0.069887\n",
      "Iteration: 144, Loss: 0.069785\n",
      "Iteration: 145, Loss: 0.069630\n",
      "Iteration: 146, Loss: 0.069501\n",
      "Iteration: 147, Loss: 0.069387\n",
      "Iteration: 148, Loss: 0.069311\n",
      "Iteration: 149, Loss: 0.069214\n",
      "Iteration: 150, Loss: 0.069167\n",
      "Iteration: 151, Loss: 0.069096\n",
      "Iteration: 152, Loss: 0.068980\n",
      "Iteration: 153, Loss: 0.068890\n",
      "Iteration: 154, Loss: 0.068786\n",
      "Iteration: 155, Loss: 0.068636\n",
      "Iteration: 156, Loss: 0.068507\n",
      "Iteration: 157, Loss: 0.068379\n",
      "Iteration: 158, Loss: 0.068246\n",
      "Iteration: 159, Loss: 0.068048\n",
      "Iteration: 160, Loss: 0.067853\n",
      "Iteration: 161, Loss: 0.067582\n",
      "Iteration: 162, Loss: 0.067457\n",
      "Iteration: 163, Loss: 0.067377\n",
      "Iteration: 164, Loss: 0.067307\n",
      "Iteration: 165, Loss: 0.067227\n",
      "Iteration: 166, Loss: 0.067179\n",
      "Iteration: 167, Loss: 0.067113\n",
      "Iteration: 168, Loss: 0.067054\n",
      "Iteration: 169, Loss: 0.067001\n",
      "Iteration: 170, Loss: 0.066941\n",
      "Iteration: 171, Loss: 0.066874\n",
      "Iteration: 172, Loss: 0.066743\n",
      "Iteration: 173, Loss: 0.066592\n",
      "Iteration: 174, Loss: 0.066426\n",
      "Iteration: 175, Loss: 0.066235\n",
      "Iteration: 176, Loss: 0.066065\n",
      "Iteration: 177, Loss: 0.065901\n",
      "Iteration: 178, Loss: 0.065842\n",
      "Iteration: 179, Loss: 0.065780\n",
      "Iteration: 180, Loss: 0.065584\n",
      "Iteration: 181, Loss: 0.065345\n",
      "Iteration: 182, Loss: 0.065234\n",
      "Iteration: 183, Loss: 0.065025\n",
      "Iteration: 184, Loss: 0.064924\n",
      "Iteration: 185, Loss: 0.064866\n",
      "Iteration: 186, Loss: 0.064763\n",
      "Iteration: 187, Loss: 0.064644\n",
      "Iteration: 188, Loss: 0.064562\n",
      "Iteration: 189, Loss: 0.064508\n",
      "Iteration: 190, Loss: 0.064427\n",
      "Iteration: 191, Loss: 0.064344\n",
      "Iteration: 192, Loss: 0.064207\n",
      "Iteration: 193, Loss: 0.064155\n",
      "Iteration: 194, Loss: 0.064029\n",
      "Iteration: 195, Loss: 0.063955\n",
      "Iteration: 196, Loss: 0.063766\n",
      "Iteration: 197, Loss: 0.063607\n",
      "Iteration: 198, Loss: 0.063518\n",
      "Iteration: 199, Loss: 0.063411\n",
      "Iteration: 200, Loss: 0.063260\n",
      "Iteration: 201, Loss: 0.062885\n",
      "Iteration: 202, Loss: 0.062744\n",
      "Iteration: 203, Loss: 0.062630\n",
      "Iteration: 204, Loss: 0.062625\n",
      "Iteration: 205, Loss: 0.062588\n",
      "Iteration: 206, Loss: 0.062524\n",
      "Iteration: 207, Loss: 0.062415\n",
      "Iteration: 208, Loss: 0.062265\n",
      "Iteration: 209, Loss: 0.062101\n",
      "Iteration: 210, Loss: 0.062019\n",
      "Iteration: 211, Loss: 0.062006\n",
      "Iteration: 212, Loss: 0.061976\n",
      "Iteration: 213, Loss: 0.061922\n",
      "Iteration: 214, Loss: 0.061873\n",
      "Iteration: 215, Loss: 0.061834\n",
      "Iteration: 216, Loss: 0.061778\n",
      "Iteration: 217, Loss: 0.061707\n",
      "Iteration: 218, Loss: 0.061585\n",
      "Iteration: 219, Loss: 0.061469\n",
      "Iteration: 220, Loss: 0.061422\n",
      "Iteration: 221, Loss: 0.061385\n",
      "Iteration: 222, Loss: 0.061363\n",
      "Iteration: 223, Loss: 0.061334\n",
      "Iteration: 224, Loss: 0.061270\n",
      "Iteration: 225, Loss: 0.061964\n",
      "Iteration: 226, Loss: 0.061226\n",
      "Iteration: 227, Loss: 0.061152\n",
      "Iteration: 228, Loss: 0.061030\n",
      "Iteration: 229, Loss: 0.060939\n",
      "Iteration: 230, Loss: 0.060873\n",
      "Iteration: 231, Loss: 0.060845\n",
      "Iteration: 232, Loss: 0.060815\n",
      "Iteration: 233, Loss: 0.060789\n",
      "Iteration: 234, Loss: 0.060733\n",
      "Iteration: 235, Loss: 0.060681\n",
      "Iteration: 236, Loss: 0.060623\n",
      "Iteration: 237, Loss: 0.060568\n",
      "Iteration: 238, Loss: 0.060493\n",
      "Iteration: 239, Loss: 0.060436\n",
      "Iteration: 240, Loss: 0.060348\n",
      "Iteration: 241, Loss: 0.060301\n",
      "Iteration: 242, Loss: 0.060255\n",
      "Iteration: 243, Loss: 0.060191\n",
      "Iteration: 244, Loss: 0.060093\n",
      "Iteration: 245, Loss: 0.059960\n",
      "Iteration: 246, Loss: 0.059750\n",
      "Iteration: 247, Loss: 0.059604\n",
      "Iteration: 248, Loss: 0.059505\n",
      "Iteration: 249, Loss: 0.059422\n",
      "Iteration: 250, Loss: 0.059364\n",
      "Iteration: 251, Loss: 0.059307\n",
      "Iteration: 252, Loss: 0.059232\n",
      "Iteration: 253, Loss: 0.059127\n",
      "Iteration: 254, Loss: 0.059011\n",
      "Iteration: 255, Loss: 0.058956\n",
      "Iteration: 256, Loss: 0.058912\n",
      "Iteration: 257, Loss: 0.058825\n",
      "Iteration: 258, Loss: 0.058748\n",
      "Iteration: 259, Loss: 0.058702\n",
      "Iteration: 260, Loss: 0.058676\n",
      "Iteration: 261, Loss: 0.058643\n",
      "Iteration: 262, Loss: 0.058604\n",
      "Iteration: 263, Loss: 0.058507\n",
      "Iteration: 264, Loss: 0.058410\n",
      "Iteration: 265, Loss: 0.058320\n",
      "Iteration: 266, Loss: 0.058270\n",
      "Iteration: 267, Loss: 0.058243\n",
      "Iteration: 268, Loss: 0.058212\n",
      "Iteration: 269, Loss: 0.058177\n",
      "Iteration: 270, Loss: 0.058134\n",
      "Iteration: 271, Loss: 0.058075\n",
      "Iteration: 272, Loss: 0.058025\n",
      "Iteration: 273, Loss: 0.057973\n",
      "Iteration: 274, Loss: 0.057911\n",
      "Iteration: 275, Loss: 0.057844\n",
      "Iteration: 276, Loss: 0.057796\n",
      "Iteration: 277, Loss: 0.057767\n",
      "Iteration: 278, Loss: 0.057739\n",
      "Iteration: 279, Loss: 0.057708\n",
      "Iteration: 280, Loss: 0.057666\n",
      "Iteration: 281, Loss: 0.057618\n",
      "Iteration: 282, Loss: 0.057564\n",
      "Iteration: 283, Loss: 0.057511\n",
      "Iteration: 284, Loss: 0.057450\n",
      "Iteration: 285, Loss: 0.057402\n",
      "Iteration: 286, Loss: 0.057345\n",
      "Iteration: 287, Loss: 0.057310\n",
      "Iteration: 288, Loss: 0.057265\n",
      "Iteration: 289, Loss: 0.057174\n",
      "Iteration: 290, Loss: 0.057058\n",
      "Iteration: 291, Loss: 0.056945\n",
      "Iteration: 292, Loss: 0.056877\n",
      "Iteration: 293, Loss: 0.056847\n",
      "Iteration: 294, Loss: 0.056824\n",
      "Iteration: 295, Loss: 0.056800\n",
      "Iteration: 296, Loss: 0.056777\n",
      "Iteration: 297, Loss: 0.056745\n",
      "Iteration: 298, Loss: 0.056661\n",
      "Iteration: 299, Loss: 0.056593\n",
      "Iteration: 300, Loss: 0.056552\n",
      "Iteration: 301, Loss: 0.056523\n",
      "Iteration: 302, Loss: 0.056496\n",
      "Iteration: 303, Loss: 0.056440\n",
      "Iteration: 304, Loss: 0.056332\n",
      "Iteration: 305, Loss: 0.056258\n",
      "Iteration: 306, Loss: 0.056706\n",
      "Iteration: 307, Loss: 0.056234\n",
      "Iteration: 308, Loss: 0.056176\n",
      "Iteration: 309, Loss: 0.056144\n",
      "Iteration: 310, Loss: 0.056112\n",
      "Iteration: 311, Loss: 0.056083\n",
      "Iteration: 312, Loss: 0.056066\n",
      "Iteration: 313, Loss: 0.056043\n",
      "Iteration: 314, Loss: 0.056019\n",
      "Iteration: 315, Loss: 0.055989\n",
      "Iteration: 316, Loss: 0.055958\n",
      "Iteration: 317, Loss: 0.055906\n",
      "Iteration: 318, Loss: 0.055826\n",
      "Iteration: 319, Loss: 0.055793\n",
      "Iteration: 320, Loss: 0.055728\n",
      "Iteration: 321, Loss: 0.055697\n",
      "Iteration: 322, Loss: 0.055675\n",
      "Iteration: 323, Loss: 0.055659\n",
      "Iteration: 324, Loss: 0.055639\n",
      "Iteration: 325, Loss: 0.055622\n",
      "Iteration: 326, Loss: 0.055607\n",
      "Iteration: 327, Loss: 0.055596\n",
      "Iteration: 328, Loss: 0.055579\n",
      "Iteration: 329, Loss: 0.055559\n",
      "Iteration: 330, Loss: 0.055538\n",
      "Iteration: 331, Loss: 0.055507\n",
      "Iteration: 332, Loss: 0.055468\n",
      "Iteration: 333, Loss: 0.055436\n",
      "Iteration: 334, Loss: 0.055405\n",
      "Iteration: 335, Loss: 0.055366\n",
      "Iteration: 336, Loss: 0.055317\n",
      "Iteration: 337, Loss: 0.055269\n",
      "Iteration: 338, Loss: 0.055213\n",
      "Iteration: 339, Loss: 0.055163\n",
      "Iteration: 340, Loss: 0.055121\n",
      "Iteration: 341, Loss: 0.055071\n",
      "Iteration: 342, Loss: 0.055032\n",
      "Iteration: 343, Loss: 0.055002\n",
      "Iteration: 344, Loss: 0.054980\n",
      "Iteration: 345, Loss: 0.054963\n",
      "Iteration: 346, Loss: 0.054951\n",
      "Iteration: 347, Loss: 0.054935\n",
      "Iteration: 348, Loss: 0.054879\n",
      "Iteration: 349, Loss: 0.055114\n",
      "Iteration: 350, Loss: 0.054857\n",
      "Iteration: 351, Loss: 0.054796\n",
      "Iteration: 352, Loss: 0.054740\n",
      "Iteration: 353, Loss: 0.054701\n",
      "Iteration: 354, Loss: 0.054666\n",
      "Iteration: 355, Loss: 0.054629\n",
      "Iteration: 356, Loss: 0.054593\n",
      "Iteration: 357, Loss: 0.054579\n",
      "Iteration: 358, Loss: 0.054538\n",
      "Iteration: 359, Loss: 0.054513\n",
      "Iteration: 360, Loss: 0.054483\n",
      "Iteration: 361, Loss: 0.054431\n",
      "Iteration: 362, Loss: 0.054374\n",
      "Iteration: 363, Loss: 0.054341\n",
      "Iteration: 364, Loss: 0.054301\n",
      "Iteration: 365, Loss: 0.054277\n",
      "Iteration: 366, Loss: 0.054259\n",
      "Iteration: 367, Loss: 0.054212\n",
      "Iteration: 368, Loss: 0.054200\n",
      "Iteration: 369, Loss: 0.054144\n",
      "Iteration: 370, Loss: 0.054113\n",
      "Iteration: 371, Loss: 0.054032\n",
      "Iteration: 372, Loss: 0.053956\n",
      "Iteration: 373, Loss: 0.053931\n",
      "Iteration: 374, Loss: 0.053865\n",
      "Iteration: 375, Loss: 0.053843\n",
      "Iteration: 376, Loss: 0.053826\n",
      "Iteration: 377, Loss: 0.053792\n",
      "Iteration: 378, Loss: 0.053760\n",
      "Iteration: 379, Loss: 0.053764\n",
      "Iteration: 380, Loss: 0.053737\n",
      "Iteration: 381, Loss: 0.053707\n",
      "Iteration: 382, Loss: 0.053694\n",
      "Iteration: 383, Loss: 0.053676\n",
      "Iteration: 384, Loss: 0.053632\n",
      "Iteration: 385, Loss: 0.053568\n",
      "Iteration: 386, Loss: 0.053581\n",
      "Iteration: 387, Loss: 0.053504\n",
      "Iteration: 388, Loss: 0.053419\n",
      "Iteration: 389, Loss: 0.053368\n",
      "Iteration: 390, Loss: 0.053328\n",
      "Iteration: 391, Loss: 0.053289\n",
      "Iteration: 392, Loss: 0.053239\n",
      "Iteration: 393, Loss: 0.053162\n",
      "Iteration: 394, Loss: 0.053096\n",
      "Iteration: 395, Loss: 0.053041\n",
      "Iteration: 396, Loss: 0.052990\n",
      "Iteration: 397, Loss: 0.052932\n",
      "Iteration: 398, Loss: 0.052877\n",
      "Iteration: 399, Loss: 0.052820\n",
      "Iteration: 400, Loss: 0.052769\n",
      "Iteration: 401, Loss: 0.052739\n",
      "Iteration: 402, Loss: 0.052675\n",
      "Iteration: 403, Loss: 0.052633\n",
      "Iteration: 404, Loss: 0.052583\n",
      "Iteration: 405, Loss: 0.052473\n",
      "Iteration: 406, Loss: 0.052416\n",
      "Iteration: 407, Loss: 0.052370\n",
      "Iteration: 408, Loss: 0.052327\n",
      "Iteration: 409, Loss: 0.052283\n",
      "Iteration: 410, Loss: 0.052244\n",
      "Iteration: 411, Loss: 0.052212\n",
      "Iteration: 412, Loss: 0.052189\n",
      "Iteration: 413, Loss: 0.052167\n",
      "Iteration: 414, Loss: 0.052128\n",
      "Iteration: 415, Loss: 0.052101\n",
      "Iteration: 416, Loss: 0.052067\n",
      "Iteration: 417, Loss: 0.052033\n",
      "Iteration: 418, Loss: 0.052015\n",
      "Iteration: 419, Loss: 0.051982\n",
      "Iteration: 420, Loss: 0.051969\n",
      "Iteration: 421, Loss: 0.051956\n",
      "Iteration: 422, Loss: 0.051936\n",
      "Iteration: 423, Loss: 0.051910\n",
      "Iteration: 424, Loss: 0.051896\n",
      "Iteration: 425, Loss: 0.051869\n",
      "Iteration: 426, Loss: 0.051844\n",
      "Iteration: 427, Loss: 0.051824\n",
      "Iteration: 428, Loss: 0.051805\n",
      "Iteration: 429, Loss: 0.051781\n",
      "Iteration: 430, Loss: 0.051763\n",
      "Iteration: 431, Loss: 0.051727\n",
      "Iteration: 432, Loss: 0.051682\n",
      "Iteration: 433, Loss: 0.051636\n",
      "Iteration: 434, Loss: 0.051601\n",
      "Iteration: 435, Loss: 0.051571\n",
      "Iteration: 436, Loss: 0.051540\n",
      "Iteration: 437, Loss: 0.051516\n",
      "Iteration: 438, Loss: 0.051484\n",
      "Iteration: 439, Loss: 0.051439\n",
      "Iteration: 440, Loss: 0.051449\n",
      "Iteration: 441, Loss: 0.051416\n",
      "Iteration: 442, Loss: 0.051375\n",
      "Iteration: 443, Loss: 0.051348\n",
      "Iteration: 444, Loss: 0.051323\n",
      "Iteration: 445, Loss: 0.051297\n",
      "Iteration: 446, Loss: 0.051269\n",
      "Iteration: 447, Loss: 0.051254\n",
      "Iteration: 448, Loss: 0.051204\n",
      "Iteration: 449, Loss: 0.051176\n",
      "Iteration: 450, Loss: 0.051136\n",
      "Iteration: 451, Loss: 0.051097\n",
      "Iteration: 452, Loss: 0.051060\n",
      "Iteration: 453, Loss: 0.051023\n",
      "Iteration: 454, Loss: 0.050979\n",
      "Iteration: 455, Loss: 0.050938\n",
      "Iteration: 456, Loss: 0.050904\n",
      "Iteration: 457, Loss: 0.050881\n",
      "Iteration: 458, Loss: 0.050859\n",
      "Iteration: 459, Loss: 0.050840\n",
      "Iteration: 460, Loss: 0.050800\n",
      "Iteration: 461, Loss: 0.050809\n",
      "Iteration: 462, Loss: 0.050758\n",
      "Iteration: 463, Loss: 0.050708\n",
      "Iteration: 464, Loss: 0.050647\n",
      "Iteration: 465, Loss: 0.050824\n",
      "Iteration: 466, Loss: 0.050635\n",
      "Iteration: 467, Loss: 0.050612\n",
      "Iteration: 468, Loss: 0.050582\n",
      "Iteration: 469, Loss: 0.050555\n",
      "Iteration: 470, Loss: 0.050521\n",
      "Iteration: 471, Loss: 0.050494\n",
      "Iteration: 472, Loss: 0.050451\n",
      "Iteration: 473, Loss: 0.050422\n",
      "Iteration: 474, Loss: 0.050367\n",
      "Iteration: 475, Loss: 0.050323\n",
      "Iteration: 476, Loss: 0.050260\n",
      "Iteration: 477, Loss: 0.050112\n",
      "Iteration: 478, Loss: 0.050019\n",
      "Iteration: 479, Loss: 0.049976\n",
      "Iteration: 480, Loss: 0.049940\n",
      "Iteration: 481, Loss: 0.049929\n",
      "Iteration: 482, Loss: 0.049899\n",
      "Iteration: 483, Loss: 0.049869\n",
      "Iteration: 484, Loss: 0.049853\n",
      "Iteration: 485, Loss: 0.049837\n",
      "Iteration: 486, Loss: 0.049811\n",
      "Iteration: 487, Loss: 0.049763\n",
      "Iteration: 488, Loss: 0.049701\n",
      "Iteration: 489, Loss: 0.049620\n",
      "Iteration: 490, Loss: 0.049781\n",
      "Iteration: 491, Loss: 0.049595\n",
      "Iteration: 492, Loss: 0.049530\n",
      "Iteration: 493, Loss: 0.049496\n",
      "Iteration: 494, Loss: 0.049477\n",
      "Iteration: 495, Loss: 0.049462\n",
      "Iteration: 496, Loss: 0.049443\n",
      "Iteration: 497, Loss: 0.049401\n",
      "Iteration: 498, Loss: 0.049374\n",
      "Iteration: 499, Loss: 0.049341\n",
      "Iteration: 500, Loss: 0.049314\n",
      "Iteration: 501, Loss: 0.049253\n",
      "Iteration: 502, Loss: 0.049200\n",
      "Iteration: 503, Loss: 0.049161\n",
      "Iteration: 504, Loss: 0.049128\n",
      "Iteration: 505, Loss: 0.049068\n",
      "Iteration: 506, Loss: 0.049018\n",
      "Iteration: 507, Loss: 0.048944\n",
      "Iteration: 508, Loss: 0.048903\n",
      "Iteration: 509, Loss: 0.048849\n",
      "Iteration: 510, Loss: 0.048778\n",
      "Iteration: 511, Loss: 0.048697\n",
      "Iteration: 512, Loss: 0.048632\n",
      "Iteration: 513, Loss: 0.048588\n",
      "Iteration: 514, Loss: 0.048551\n",
      "Iteration: 515, Loss: 0.048477\n",
      "Iteration: 516, Loss: 0.048406\n",
      "Iteration: 517, Loss: 0.048324\n",
      "Iteration: 518, Loss: 0.048265\n",
      "Iteration: 519, Loss: 0.048207\n",
      "Iteration: 520, Loss: 0.048176\n",
      "Iteration: 521, Loss: 0.048150\n",
      "Iteration: 522, Loss: 0.048112\n",
      "Iteration: 523, Loss: 0.048080\n",
      "Iteration: 524, Loss: 0.048044\n",
      "Iteration: 525, Loss: 0.047975\n",
      "Iteration: 526, Loss: 0.047903\n",
      "Iteration: 527, Loss: 0.047898\n",
      "Iteration: 528, Loss: 0.047848\n",
      "Iteration: 529, Loss: 0.047780\n",
      "Iteration: 530, Loss: 0.047745\n",
      "Iteration: 531, Loss: 0.047719\n",
      "Iteration: 532, Loss: 0.047704\n",
      "Iteration: 533, Loss: 0.047689\n",
      "Iteration: 534, Loss: 0.047666\n",
      "Iteration: 535, Loss: 0.047666\n",
      "Iteration: 536, Loss: 0.047649\n",
      "Iteration: 537, Loss: 0.047623\n",
      "Iteration: 538, Loss: 0.047600\n",
      "Iteration: 539, Loss: 0.047583\n",
      "Iteration: 540, Loss: 0.047573\n",
      "Iteration: 541, Loss: 0.047556\n",
      "Iteration: 542, Loss: 0.047543\n",
      "Iteration: 543, Loss: 0.047521\n",
      "Iteration: 544, Loss: 0.047532\n",
      "Iteration: 545, Loss: 0.047509\n",
      "Iteration: 546, Loss: 0.047495\n",
      "Iteration: 547, Loss: 0.047476\n",
      "Iteration: 548, Loss: 0.047463\n",
      "Iteration: 549, Loss: 0.047450\n",
      "Iteration: 550, Loss: 0.047434\n",
      "Iteration: 551, Loss: 0.047413\n",
      "Iteration: 552, Loss: 0.047391\n",
      "Iteration: 553, Loss: 0.047393\n",
      "Iteration: 554, Loss: 0.047376\n",
      "Iteration: 555, Loss: 0.047358\n",
      "Iteration: 556, Loss: 0.047333\n",
      "Iteration: 557, Loss: 0.047306\n",
      "Iteration: 558, Loss: 0.047266\n",
      "Iteration: 559, Loss: 0.047208\n",
      "Iteration: 560, Loss: 0.047119\n",
      "Iteration: 561, Loss: 0.047073\n",
      "Iteration: 562, Loss: 0.047027\n",
      "Iteration: 563, Loss: 0.047004\n",
      "Iteration: 564, Loss: 0.046988\n",
      "Iteration: 565, Loss: 0.046973\n",
      "Iteration: 566, Loss: 0.046946\n",
      "Iteration: 567, Loss: 0.046901\n",
      "Iteration: 568, Loss: 0.046856\n",
      "Iteration: 569, Loss: 0.046774\n",
      "Iteration: 570, Loss: 0.046719\n",
      "Iteration: 571, Loss: 0.046657\n",
      "Iteration: 572, Loss: 0.046607\n",
      "Iteration: 573, Loss: 0.046530\n",
      "Iteration: 574, Loss: 0.046433\n",
      "Iteration: 575, Loss: 0.046385\n",
      "Iteration: 576, Loss: 0.046369\n",
      "Iteration: 577, Loss: 0.046350\n",
      "Iteration: 578, Loss: 0.046332\n",
      "Iteration: 579, Loss: 0.046303\n",
      "Iteration: 580, Loss: 0.046281\n",
      "Iteration: 581, Loss: 0.046253\n",
      "Iteration: 582, Loss: 0.046223\n",
      "Iteration: 583, Loss: 0.046207\n",
      "Iteration: 584, Loss: 0.046194\n",
      "Iteration: 585, Loss: 0.046185\n",
      "Iteration: 586, Loss: 0.046171\n",
      "Iteration: 587, Loss: 0.046156\n",
      "Iteration: 588, Loss: 0.046145\n",
      "Iteration: 589, Loss: 0.046129\n",
      "Iteration: 590, Loss: 0.046140\n",
      "Iteration: 591, Loss: 0.046119\n",
      "Iteration: 592, Loss: 0.046097\n",
      "Iteration: 593, Loss: 0.046067\n",
      "Iteration: 594, Loss: 0.046034\n",
      "Iteration: 595, Loss: 0.046056\n",
      "Iteration: 596, Loss: 0.046001\n",
      "Iteration: 597, Loss: 0.045945\n",
      "Iteration: 598, Loss: 0.045900\n",
      "Iteration: 599, Loss: 0.045866\n",
      "Iteration: 600, Loss: 0.045844\n",
      "Iteration: 601, Loss: 0.045824\n",
      "Iteration: 602, Loss: 0.045804\n",
      "Iteration: 603, Loss: 0.045823\n",
      "Iteration: 604, Loss: 0.045797\n",
      "Iteration: 605, Loss: 0.045787\n",
      "Iteration: 606, Loss: 0.045770\n",
      "Iteration: 607, Loss: 0.045751\n",
      "Iteration: 608, Loss: 0.045732\n",
      "Iteration: 609, Loss: 0.045715\n",
      "Iteration: 610, Loss: 0.045691\n",
      "Iteration: 611, Loss: 0.045675\n",
      "Iteration: 612, Loss: 0.045656\n",
      "Iteration: 613, Loss: 0.045638\n",
      "Iteration: 614, Loss: 0.045615\n",
      "Iteration: 615, Loss: 0.045593\n",
      "Iteration: 616, Loss: 0.045582\n",
      "Iteration: 617, Loss: 0.045577\n",
      "Iteration: 618, Loss: 0.045545\n",
      "Iteration: 619, Loss: 0.045529\n",
      "Iteration: 620, Loss: 0.045517\n",
      "Iteration: 621, Loss: 0.045512\n",
      "Iteration: 622, Loss: 0.045506\n",
      "Iteration: 623, Loss: 0.045489\n",
      "Iteration: 624, Loss: 0.045470\n",
      "Iteration: 625, Loss: 0.045446\n",
      "Iteration: 626, Loss: 0.045403\n",
      "Iteration: 627, Loss: 0.045355\n",
      "Iteration: 628, Loss: 0.045312\n",
      "Iteration: 629, Loss: 0.045285\n",
      "Iteration: 630, Loss: 0.045260\n",
      "Iteration: 631, Loss: 0.045236\n",
      "Iteration: 632, Loss: 0.045214\n",
      "Iteration: 633, Loss: 0.045189\n",
      "Iteration: 634, Loss: 0.045145\n",
      "Iteration: 635, Loss: 0.045105\n",
      "Iteration: 636, Loss: 0.045085\n",
      "Iteration: 637, Loss: 0.045068\n",
      "Iteration: 638, Loss: 0.045054\n",
      "Iteration: 639, Loss: 0.045034\n",
      "Iteration: 640, Loss: 0.045006\n",
      "Iteration: 641, Loss: 0.044982\n",
      "Iteration: 642, Loss: 0.044972\n",
      "Iteration: 643, Loss: 0.044938\n",
      "Iteration: 644, Loss: 0.044921\n",
      "Iteration: 645, Loss: 0.044904\n",
      "Iteration: 646, Loss: 0.044897\n",
      "Iteration: 647, Loss: 0.044889\n",
      "Iteration: 648, Loss: 0.044882\n",
      "Iteration: 649, Loss: 0.044869\n",
      "Iteration: 650, Loss: 0.044840\n",
      "Iteration: 651, Loss: 0.044857\n",
      "Iteration: 652, Loss: 0.044825\n",
      "Iteration: 653, Loss: 0.044794\n",
      "Iteration: 654, Loss: 0.044762\n",
      "Iteration: 655, Loss: 0.044738\n",
      "Iteration: 656, Loss: 0.044721\n",
      "Iteration: 657, Loss: 0.044857\n",
      "Iteration: 658, Loss: 0.044709\n",
      "Iteration: 659, Loss: 0.044692\n",
      "Iteration: 660, Loss: 0.044680\n",
      "Iteration: 661, Loss: 0.044666\n",
      "Iteration: 662, Loss: 0.044628\n",
      "Iteration: 663, Loss: 0.044579\n",
      "Iteration: 664, Loss: 0.044537\n",
      "Iteration: 665, Loss: 0.044498\n",
      "Iteration: 666, Loss: 0.044464\n",
      "Iteration: 667, Loss: 0.044437\n",
      "Iteration: 668, Loss: 0.044410\n",
      "Iteration: 669, Loss: 0.044372\n",
      "Iteration: 670, Loss: 0.044347\n",
      "Iteration: 671, Loss: 0.044317\n",
      "Iteration: 672, Loss: 0.044305\n",
      "Iteration: 673, Loss: 0.044296\n",
      "Iteration: 674, Loss: 0.044292\n",
      "Iteration: 675, Loss: 0.044290\n",
      "Iteration: 676, Loss: 0.044285\n",
      "Iteration: 677, Loss: 0.044279\n",
      "Iteration: 678, Loss: 0.044267\n",
      "Iteration: 679, Loss: 0.044256\n",
      "Iteration: 680, Loss: 0.044239\n",
      "Iteration: 681, Loss: 0.044228\n",
      "Iteration: 682, Loss: 0.044217\n",
      "Iteration: 683, Loss: 0.044199\n",
      "Iteration: 684, Loss: 0.044181\n",
      "Iteration: 685, Loss: 0.044140\n",
      "Iteration: 686, Loss: 0.044117\n",
      "Iteration: 687, Loss: 0.044093\n",
      "Iteration: 688, Loss: 0.044076\n",
      "Iteration: 689, Loss: 0.044061\n",
      "Iteration: 690, Loss: 0.044045\n",
      "Iteration: 691, Loss: 0.044021\n",
      "Iteration: 692, Loss: 0.044008\n",
      "Iteration: 693, Loss: 0.043989\n",
      "Iteration: 694, Loss: 0.043977\n",
      "Iteration: 695, Loss: 0.043968\n",
      "Iteration: 696, Loss: 0.043952\n",
      "Iteration: 697, Loss: 0.043917\n",
      "Iteration: 698, Loss: 0.044042\n",
      "Iteration: 699, Loss: 0.043909\n",
      "Iteration: 700, Loss: 0.043892\n",
      "Iteration: 701, Loss: 0.043871\n",
      "Iteration: 702, Loss: 0.043858\n",
      "Iteration: 703, Loss: 0.043839\n",
      "Iteration: 704, Loss: 0.043826\n",
      "Iteration: 705, Loss: 0.043801\n",
      "Iteration: 706, Loss: 0.043775\n",
      "Iteration: 707, Loss: 0.043750\n",
      "Iteration: 708, Loss: 0.043733\n",
      "Iteration: 709, Loss: 0.043706\n",
      "Iteration: 710, Loss: 0.043688\n",
      "Iteration: 711, Loss: 0.043673\n",
      "Iteration: 712, Loss: 0.043652\n",
      "Iteration: 713, Loss: 0.043623\n",
      "Iteration: 714, Loss: 0.043598\n",
      "Iteration: 715, Loss: 0.043565\n",
      "Iteration: 716, Loss: 0.043548\n",
      "Iteration: 717, Loss: 0.043536\n",
      "Iteration: 718, Loss: 0.043507\n",
      "Iteration: 719, Loss: 0.043482\n",
      "Iteration: 720, Loss: 0.043449\n",
      "Iteration: 721, Loss: 0.043420\n",
      "Iteration: 722, Loss: 0.043406\n",
      "Iteration: 723, Loss: 0.043388\n",
      "Iteration: 724, Loss: 0.043372\n",
      "Iteration: 725, Loss: 0.043350\n",
      "Iteration: 726, Loss: 0.043335\n",
      "Iteration: 727, Loss: 0.043306\n",
      "Iteration: 728, Loss: 0.043292\n",
      "Iteration: 729, Loss: 0.043278\n",
      "Iteration: 730, Loss: 0.043260\n",
      "Iteration: 731, Loss: 0.043234\n",
      "Iteration: 732, Loss: 0.043211\n",
      "Iteration: 733, Loss: 0.043186\n",
      "Iteration: 734, Loss: 0.043167\n",
      "Iteration: 735, Loss: 0.043155\n",
      "Iteration: 736, Loss: 0.043134\n",
      "Iteration: 737, Loss: 0.043104\n",
      "Iteration: 738, Loss: 0.043077\n",
      "Iteration: 739, Loss: 0.043056\n",
      "Iteration: 740, Loss: 0.043040\n",
      "Iteration: 741, Loss: 0.043010\n",
      "Iteration: 742, Loss: 0.042948\n",
      "Iteration: 743, Loss: 0.042921\n",
      "Iteration: 744, Loss: 0.042893\n",
      "Iteration: 745, Loss: 0.042878\n",
      "Iteration: 746, Loss: 0.042862\n",
      "Iteration: 747, Loss: 0.042844\n",
      "Iteration: 748, Loss: 0.042815\n",
      "Iteration: 749, Loss: 0.042792\n",
      "Iteration: 750, Loss: 0.042781\n",
      "Iteration: 751, Loss: 0.042759\n",
      "Iteration: 752, Loss: 0.042873\n",
      "Iteration: 753, Loss: 0.042745\n",
      "Iteration: 754, Loss: 0.042723\n",
      "Iteration: 755, Loss: 0.042700\n",
      "Iteration: 756, Loss: 0.042688\n",
      "Iteration: 757, Loss: 0.042685\n",
      "Iteration: 758, Loss: 0.042671\n",
      "Iteration: 759, Loss: 0.042654\n",
      "Iteration: 760, Loss: 0.042619\n",
      "Iteration: 761, Loss: 0.042622\n",
      "Iteration: 762, Loss: 0.042599\n",
      "Iteration: 763, Loss: 0.042565\n",
      "Iteration: 764, Loss: 0.042618\n",
      "Iteration: 765, Loss: 0.042552\n",
      "Iteration: 766, Loss: 0.042530\n",
      "Iteration: 767, Loss: 0.042512\n",
      "Iteration: 768, Loss: 0.042495\n",
      "Iteration: 769, Loss: 0.042483\n",
      "Iteration: 770, Loss: 0.042465\n",
      "Iteration: 771, Loss: 0.042444\n",
      "Iteration: 772, Loss: 0.042413\n",
      "Iteration: 773, Loss: 0.042383\n",
      "Iteration: 774, Loss: 0.042357\n",
      "Iteration: 775, Loss: 0.042342\n",
      "Iteration: 776, Loss: 0.042323\n",
      "Iteration: 777, Loss: 0.042292\n",
      "Iteration: 778, Loss: 0.042238\n",
      "Iteration: 779, Loss: 0.042198\n",
      "Iteration: 780, Loss: 0.042212\n",
      "Iteration: 781, Loss: 0.042169\n",
      "Iteration: 782, Loss: 0.042146\n",
      "Iteration: 783, Loss: 0.042129\n",
      "Iteration: 784, Loss: 0.042117\n",
      "Iteration: 785, Loss: 0.042098\n",
      "Iteration: 786, Loss: 0.042078\n",
      "Iteration: 787, Loss: 0.042061\n",
      "Iteration: 788, Loss: 0.042061\n",
      "Iteration: 789, Loss: 0.042051\n",
      "Iteration: 790, Loss: 0.042034\n",
      "Iteration: 791, Loss: 0.042022\n",
      "Iteration: 792, Loss: 0.042012\n",
      "Iteration: 793, Loss: 0.041993\n",
      "Iteration: 794, Loss: 0.041961\n",
      "Iteration: 795, Loss: 0.041930\n",
      "Iteration: 796, Loss: 0.041922\n",
      "Iteration: 797, Loss: 0.041886\n",
      "Iteration: 798, Loss: 0.041855\n",
      "Iteration: 799, Loss: 0.041842\n",
      "Iteration: 800, Loss: 0.041828\n",
      "Iteration: 801, Loss: 0.041827\n",
      "Iteration: 802, Loss: 0.041812\n",
      "Iteration: 803, Loss: 0.041806\n",
      "Iteration: 804, Loss: 0.041789\n",
      "Iteration: 805, Loss: 0.041775\n",
      "Iteration: 806, Loss: 0.041757\n",
      "Iteration: 807, Loss: 0.041742\n",
      "Iteration: 808, Loss: 0.041732\n",
      "Iteration: 809, Loss: 0.041723\n",
      "Iteration: 810, Loss: 0.041708\n",
      "Iteration: 811, Loss: 0.041697\n",
      "Iteration: 812, Loss: 0.041687\n",
      "Iteration: 813, Loss: 0.041669\n",
      "Iteration: 814, Loss: 0.041661\n",
      "Iteration: 815, Loss: 0.041639\n",
      "Iteration: 816, Loss: 0.041630\n",
      "Iteration: 817, Loss: 0.041620\n",
      "Iteration: 818, Loss: 0.041611\n",
      "Iteration: 819, Loss: 0.041617\n",
      "Iteration: 820, Loss: 0.041606\n",
      "Iteration: 821, Loss: 0.041591\n",
      "Iteration: 822, Loss: 0.041582\n",
      "Iteration: 823, Loss: 0.041571\n",
      "Iteration: 824, Loss: 0.041563\n",
      "Iteration: 825, Loss: 0.041551\n",
      "Iteration: 826, Loss: 0.041539\n",
      "Iteration: 827, Loss: 0.041527\n",
      "Iteration: 828, Loss: 0.041515\n",
      "Iteration: 829, Loss: 0.041501\n",
      "Iteration: 830, Loss: 0.041488\n",
      "Iteration: 831, Loss: 0.041476\n",
      "Iteration: 832, Loss: 0.041460\n",
      "Iteration: 833, Loss: 0.041444\n",
      "Iteration: 834, Loss: 0.041417\n",
      "Iteration: 835, Loss: 0.041429\n",
      "Iteration: 836, Loss: 0.041410\n",
      "Iteration: 837, Loss: 0.041398\n",
      "Iteration: 838, Loss: 0.041387\n",
      "Iteration: 839, Loss: 0.041374\n",
      "Iteration: 840, Loss: 0.041365\n",
      "Iteration: 841, Loss: 0.041355\n",
      "Iteration: 842, Loss: 0.041343\n",
      "Iteration: 843, Loss: 0.041331\n",
      "Iteration: 844, Loss: 0.041314\n",
      "Iteration: 845, Loss: 0.041353\n",
      "Iteration: 846, Loss: 0.041307\n",
      "Iteration: 847, Loss: 0.041299\n",
      "Iteration: 848, Loss: 0.041287\n",
      "Iteration: 849, Loss: 0.041278\n",
      "Iteration: 850, Loss: 0.041263\n",
      "Iteration: 851, Loss: 0.041265\n",
      "Iteration: 852, Loss: 0.041251\n",
      "Iteration: 853, Loss: 0.041234\n",
      "Iteration: 854, Loss: 0.041216\n",
      "Iteration: 855, Loss: 0.041203\n",
      "Iteration: 856, Loss: 0.041178\n",
      "Iteration: 857, Loss: 0.041162\n",
      "Iteration: 858, Loss: 0.041143\n",
      "Iteration: 859, Loss: 0.041141\n",
      "Iteration: 860, Loss: 0.041133\n",
      "Iteration: 861, Loss: 0.041121\n",
      "Iteration: 862, Loss: 0.041114\n",
      "Iteration: 863, Loss: 0.041111\n",
      "Iteration: 864, Loss: 0.041106\n",
      "Iteration: 865, Loss: 0.041103\n",
      "Iteration: 866, Loss: 0.041090\n",
      "Iteration: 867, Loss: 0.041080\n",
      "Iteration: 868, Loss: 0.041062\n",
      "Iteration: 869, Loss: 0.041046\n",
      "Iteration: 870, Loss: 0.041035\n",
      "Iteration: 871, Loss: 0.041017\n",
      "Iteration: 872, Loss: 0.041008\n",
      "Iteration: 873, Loss: 0.040995\n",
      "Iteration: 874, Loss: 0.040974\n",
      "Iteration: 875, Loss: 0.040960\n",
      "Iteration: 876, Loss: 0.040944\n",
      "Iteration: 877, Loss: 0.040935\n",
      "Iteration: 878, Loss: 0.040913\n",
      "Iteration: 879, Loss: 0.040909\n",
      "Iteration: 880, Loss: 0.040873\n",
      "Iteration: 881, Loss: 0.040856\n",
      "Iteration: 882, Loss: 0.040842\n",
      "Iteration: 883, Loss: 0.040818\n",
      "Iteration: 884, Loss: 0.040827\n",
      "Iteration: 885, Loss: 0.040809\n",
      "Iteration: 886, Loss: 0.040790\n",
      "Iteration: 887, Loss: 0.040824\n",
      "Iteration: 888, Loss: 0.040783\n",
      "Iteration: 889, Loss: 0.040764\n",
      "Iteration: 890, Loss: 0.040750\n",
      "Iteration: 891, Loss: 0.040735\n",
      "Iteration: 892, Loss: 0.040719\n",
      "Iteration: 893, Loss: 0.040703\n",
      "Iteration: 894, Loss: 0.040692\n",
      "Iteration: 895, Loss: 0.040682\n",
      "Iteration: 896, Loss: 0.040669\n",
      "Iteration: 897, Loss: 0.040656\n",
      "Iteration: 898, Loss: 0.040644\n",
      "Iteration: 899, Loss: 0.040637\n",
      "Iteration: 900, Loss: 0.040635\n",
      "Iteration: 901, Loss: 0.040623\n",
      "Iteration: 902, Loss: 0.040619\n",
      "Iteration: 903, Loss: 0.040613\n",
      "Iteration: 904, Loss: 0.040614\n",
      "Iteration: 905, Loss: 0.040608\n",
      "Iteration: 906, Loss: 0.040601\n",
      "Iteration: 907, Loss: 0.040564\n",
      "Iteration: 908, Loss: 0.040542\n",
      "Iteration: 909, Loss: 0.040613\n",
      "Iteration: 910, Loss: 0.040533\n",
      "Iteration: 911, Loss: 0.040512\n",
      "Iteration: 912, Loss: 0.040503\n",
      "Iteration: 913, Loss: 0.040492\n",
      "Iteration: 914, Loss: 0.040483\n",
      "Iteration: 915, Loss: 0.040473\n",
      "Iteration: 916, Loss: 0.040463\n",
      "Iteration: 917, Loss: 0.040464\n",
      "Iteration: 918, Loss: 0.040460\n",
      "Iteration: 919, Loss: 0.040456\n",
      "Iteration: 920, Loss: 0.040447\n",
      "Iteration: 921, Loss: 0.040440\n",
      "Iteration: 922, Loss: 0.040426\n",
      "Iteration: 923, Loss: 0.040431\n",
      "Iteration: 924, Loss: 0.040420\n",
      "Iteration: 925, Loss: 0.040402\n",
      "Iteration: 926, Loss: 0.040383\n",
      "Iteration: 927, Loss: 0.040363\n",
      "Iteration: 928, Loss: 0.040351\n",
      "Iteration: 929, Loss: 0.040332\n",
      "Iteration: 930, Loss: 0.040317\n",
      "Iteration: 931, Loss: 0.040300\n",
      "Iteration: 932, Loss: 0.040281\n",
      "Iteration: 933, Loss: 0.040262\n",
      "Iteration: 934, Loss: 0.040237\n",
      "Iteration: 935, Loss: 0.040224\n",
      "Iteration: 936, Loss: 0.040216\n",
      "Iteration: 937, Loss: 0.040203\n",
      "Iteration: 938, Loss: 0.040184\n",
      "Iteration: 939, Loss: 0.040180\n",
      "Iteration: 940, Loss: 0.040156\n",
      "Iteration: 941, Loss: 0.040148\n",
      "Iteration: 942, Loss: 0.040137\n",
      "Iteration: 943, Loss: 0.040181\n",
      "Iteration: 944, Loss: 0.040132\n",
      "Iteration: 945, Loss: 0.040117\n",
      "Iteration: 946, Loss: 0.040094\n",
      "Iteration: 947, Loss: 0.040077\n",
      "Iteration: 948, Loss: 0.040064\n",
      "Iteration: 949, Loss: 0.040055\n",
      "Iteration: 950, Loss: 0.040046\n",
      "Iteration: 951, Loss: 0.040050\n",
      "Iteration: 952, Loss: 0.040043\n",
      "Iteration: 953, Loss: 0.040037\n",
      "Iteration: 954, Loss: 0.040024\n",
      "Iteration: 955, Loss: 0.040009\n",
      "Iteration: 956, Loss: 0.039992\n",
      "Iteration: 957, Loss: 0.039971\n",
      "Iteration: 958, Loss: 0.039952\n",
      "Iteration: 959, Loss: 0.039939\n",
      "Iteration: 960, Loss: 0.039929\n",
      "Iteration: 961, Loss: 0.039909\n",
      "Iteration: 962, Loss: 0.039902\n",
      "Iteration: 963, Loss: 0.039885\n",
      "Iteration: 964, Loss: 0.039874\n",
      "Iteration: 965, Loss: 0.039861\n",
      "Iteration: 966, Loss: 0.039846\n",
      "Iteration: 967, Loss: 0.039827\n",
      "Iteration: 968, Loss: 0.039807\n",
      "Iteration: 969, Loss: 0.039789\n",
      "Iteration: 970, Loss: 0.039778\n",
      "Iteration: 971, Loss: 0.039771\n",
      "Iteration: 972, Loss: 0.039756\n",
      "Iteration: 973, Loss: 0.039741\n",
      "Iteration: 974, Loss: 0.039742\n",
      "Iteration: 975, Loss: 0.039735\n",
      "Iteration: 976, Loss: 0.039728\n",
      "Iteration: 977, Loss: 0.039725\n",
      "Iteration: 978, Loss: 0.039722\n",
      "Iteration: 979, Loss: 0.039710\n",
      "Iteration: 980, Loss: 0.039689\n",
      "Iteration: 981, Loss: 0.039676\n",
      "Iteration: 982, Loss: 0.039663\n",
      "Iteration: 983, Loss: 0.039654\n",
      "Iteration: 984, Loss: 0.039648\n",
      "Iteration: 985, Loss: 0.039643\n",
      "Iteration: 986, Loss: 0.039634\n",
      "Iteration: 987, Loss: 0.039624\n",
      "Iteration: 988, Loss: 0.039612\n",
      "Iteration: 989, Loss: 0.039605\n",
      "Iteration: 990, Loss: 0.039620\n",
      "Iteration: 991, Loss: 0.039598\n",
      "Iteration: 992, Loss: 0.039589\n",
      "Iteration: 993, Loss: 0.039575\n",
      "Iteration: 994, Loss: 0.039564\n",
      "Iteration: 995, Loss: 0.039545\n",
      "Iteration: 996, Loss: 0.039532\n",
      "Iteration: 997, Loss: 0.039519\n",
      "Iteration: 998, Loss: 0.039504\n",
      "Iteration: 999, Loss: 0.039505\n",
      "Iteration: 1000, Loss: 0.039496\n",
      "Iteration: 1001, Loss: 0.039483\n",
      "Iteration: 1002, Loss: 0.039474\n",
      "Iteration: 1003, Loss: 0.039461\n",
      "Iteration: 1004, Loss: 0.039450\n",
      "Iteration: 1005, Loss: 0.039439\n",
      "Iteration: 1006, Loss: 0.039430\n",
      "Iteration: 1007, Loss: 0.039420\n",
      "Iteration: 1008, Loss: 0.039415\n",
      "Iteration: 1009, Loss: 0.039410\n",
      "Iteration: 1010, Loss: 0.039401\n",
      "Iteration: 1011, Loss: 0.039390\n",
      "Iteration: 1012, Loss: 0.039375\n",
      "Iteration: 1013, Loss: 0.039351\n",
      "Iteration: 1014, Loss: 0.039322\n",
      "Iteration: 1015, Loss: 0.039294\n",
      "Iteration: 1016, Loss: 0.039274\n",
      "Iteration: 1017, Loss: 0.039260\n",
      "Iteration: 1018, Loss: 0.039240\n",
      "Iteration: 1019, Loss: 0.039214\n",
      "Iteration: 1020, Loss: 0.039199\n",
      "Iteration: 1021, Loss: 0.039186\n",
      "Iteration: 1022, Loss: 0.039174\n",
      "Iteration: 1023, Loss: 0.039162\n",
      "Iteration: 1024, Loss: 0.039154\n",
      "Iteration: 1025, Loss: 0.039145\n",
      "Iteration: 1026, Loss: 0.039136\n",
      "Iteration: 1027, Loss: 0.039128\n",
      "Iteration: 1028, Loss: 0.039123\n",
      "Iteration: 1029, Loss: 0.039119\n",
      "Iteration: 1030, Loss: 0.039116\n",
      "Iteration: 1031, Loss: 0.039114\n",
      "Iteration: 1032, Loss: 0.039111\n",
      "Iteration: 1033, Loss: 0.039100\n",
      "Iteration: 1034, Loss: 0.039091\n",
      "Iteration: 1035, Loss: 0.039081\n",
      "Iteration: 1036, Loss: 0.039069\n",
      "Iteration: 1037, Loss: 0.039052\n",
      "Iteration: 1038, Loss: 0.039096\n",
      "Iteration: 1039, Loss: 0.039045\n",
      "Iteration: 1040, Loss: 0.039029\n",
      "Iteration: 1041, Loss: 0.039008\n",
      "Iteration: 1042, Loss: 0.039003\n",
      "Iteration: 1043, Loss: 0.038987\n",
      "Iteration: 1044, Loss: 0.039066\n",
      "Iteration: 1045, Loss: 0.038975\n",
      "Iteration: 1046, Loss: 0.038948\n",
      "Iteration: 1047, Loss: 0.038936\n",
      "Iteration: 1048, Loss: 0.038921\n",
      "Iteration: 1049, Loss: 0.038908\n",
      "Iteration: 1050, Loss: 0.038895\n",
      "Iteration: 1051, Loss: 0.038899\n",
      "Iteration: 1052, Loss: 0.038887\n",
      "Iteration: 1053, Loss: 0.038876\n",
      "Iteration: 1054, Loss: 0.038862\n",
      "Iteration: 1055, Loss: 0.038885\n",
      "Iteration: 1056, Loss: 0.038856\n",
      "Iteration: 1057, Loss: 0.038844\n",
      "Iteration: 1058, Loss: 0.038835\n",
      "Iteration: 1059, Loss: 0.038827\n",
      "Iteration: 1060, Loss: 0.038820\n",
      "Iteration: 1061, Loss: 0.038816\n",
      "Iteration: 1062, Loss: 0.038812\n",
      "Iteration: 1063, Loss: 0.038808\n",
      "Iteration: 1064, Loss: 0.038806\n",
      "Iteration: 1065, Loss: 0.038801\n",
      "Iteration: 1066, Loss: 0.038797\n",
      "Iteration: 1067, Loss: 0.038793\n",
      "Iteration: 1068, Loss: 0.038788\n",
      "Iteration: 1069, Loss: 0.038781\n",
      "Iteration: 1070, Loss: 0.038774\n",
      "Iteration: 1071, Loss: 0.038764\n",
      "Iteration: 1072, Loss: 0.038755\n",
      "Iteration: 1073, Loss: 0.038749\n",
      "Iteration: 1074, Loss: 0.038734\n",
      "Iteration: 1075, Loss: 0.038751\n",
      "Iteration: 1076, Loss: 0.038724\n",
      "Iteration: 1077, Loss: 0.038708\n",
      "Iteration: 1078, Loss: 0.038702\n",
      "Iteration: 1079, Loss: 0.038696\n",
      "Iteration: 1080, Loss: 0.038690\n",
      "Iteration: 1081, Loss: 0.038680\n",
      "Iteration: 1082, Loss: 0.039737\n",
      "Iteration: 1083, Loss: 0.038679\n",
      "Iteration: 1084, Loss: 0.038672\n",
      "Iteration: 1085, Loss: 0.038666\n",
      "Iteration: 1086, Loss: 0.038660\n",
      "Iteration: 1087, Loss: 0.038651\n",
      "Iteration: 1088, Loss: 0.039059\n",
      "Iteration: 1089, Loss: 0.038649\n",
      "Iteration: 1090, Loss: 0.038639\n",
      "Iteration: 1091, Loss: 0.038629\n",
      "Iteration: 1092, Loss: 0.038624\n",
      "Iteration: 1093, Loss: 0.038619\n",
      "Iteration: 1094, Loss: 0.038610\n",
      "Iteration: 1095, Loss: 0.038601\n",
      "Iteration: 1096, Loss: 0.038583\n",
      "Iteration: 1097, Loss: 0.038567\n",
      "Iteration: 1098, Loss: 0.038550\n",
      "Iteration: 1099, Loss: 0.038543\n",
      "Iteration: 1100, Loss: 0.038524\n",
      "Iteration: 1101, Loss: 0.038512\n",
      "Iteration: 1102, Loss: 0.038500\n",
      "Iteration: 1103, Loss: 0.038483\n",
      "Iteration: 1104, Loss: 0.038471\n",
      "Iteration: 1105, Loss: 0.038454\n",
      "Iteration: 1106, Loss: 0.038448\n",
      "Iteration: 1107, Loss: 0.038443\n",
      "Iteration: 1108, Loss: 0.038434\n",
      "Iteration: 1109, Loss: 0.038422\n",
      "Iteration: 1110, Loss: 0.038399\n",
      "Iteration: 1111, Loss: 0.038391\n",
      "Iteration: 1112, Loss: 0.038358\n",
      "Iteration: 1113, Loss: 0.038334\n",
      "Iteration: 1114, Loss: 0.038316\n",
      "Iteration: 1115, Loss: 0.038296\n",
      "Iteration: 1116, Loss: 0.038280\n",
      "Iteration: 1117, Loss: 0.038267\n",
      "Iteration: 1118, Loss: 0.038250\n",
      "Iteration: 1119, Loss: 0.038226\n",
      "Iteration: 1120, Loss: 0.038217\n",
      "Iteration: 1121, Loss: 0.038205\n",
      "Iteration: 1122, Loss: 0.038306\n",
      "Iteration: 1123, Loss: 0.038201\n",
      "Iteration: 1124, Loss: 0.038191\n",
      "Iteration: 1125, Loss: 0.038184\n",
      "Iteration: 1126, Loss: 0.038180\n",
      "Iteration: 1127, Loss: 0.038176\n",
      "Iteration: 1128, Loss: 0.038171\n",
      "Iteration: 1129, Loss: 0.038166\n",
      "Iteration: 1130, Loss: 0.038159\n",
      "Iteration: 1131, Loss: 0.038153\n",
      "Iteration: 1132, Loss: 0.038147\n",
      "Iteration: 1133, Loss: 0.038135\n",
      "Iteration: 1134, Loss: 0.038124\n",
      "Iteration: 1135, Loss: 0.038115\n",
      "Iteration: 1136, Loss: 0.038104\n",
      "Iteration: 1137, Loss: 0.038101\n",
      "Iteration: 1138, Loss: 0.038095\n",
      "Iteration: 1139, Loss: 0.038091\n",
      "Iteration: 1140, Loss: 0.038086\n",
      "Iteration: 1141, Loss: 0.038082\n",
      "Iteration: 1142, Loss: 0.038099\n",
      "Iteration: 1143, Loss: 0.038080\n",
      "Iteration: 1144, Loss: 0.038077\n",
      "Iteration: 1145, Loss: 0.038068\n",
      "Iteration: 1146, Loss: 0.038060\n",
      "Iteration: 1147, Loss: 0.038046\n",
      "Iteration: 1148, Loss: 0.038040\n",
      "Iteration: 1149, Loss: 0.038031\n",
      "Iteration: 1150, Loss: 0.038023\n",
      "Iteration: 1151, Loss: 0.038009\n",
      "Iteration: 1152, Loss: 0.037986\n",
      "Iteration: 1153, Loss: 0.037968\n",
      "Iteration: 1154, Loss: 0.037945\n",
      "Iteration: 1155, Loss: 0.037975\n",
      "Iteration: 1156, Loss: 0.037937\n",
      "Iteration: 1157, Loss: 0.037923\n",
      "Iteration: 1158, Loss: 0.037907\n",
      "Iteration: 1159, Loss: 0.037887\n",
      "Iteration: 1160, Loss: 0.037866\n",
      "Iteration: 1161, Loss: 0.037837\n",
      "Iteration: 1162, Loss: 0.037798\n",
      "Iteration: 1163, Loss: 0.037763\n",
      "Iteration: 1164, Loss: 0.037746\n",
      "Iteration: 1165, Loss: 0.037727\n",
      "Iteration: 1166, Loss: 0.037709\n",
      "Iteration: 1167, Loss: 0.037716\n",
      "Iteration: 1168, Loss: 0.037698\n",
      "Iteration: 1169, Loss: 0.037686\n",
      "Iteration: 1170, Loss: 0.037674\n",
      "Iteration: 1171, Loss: 0.037657\n",
      "Iteration: 1172, Loss: 0.037650\n",
      "Iteration: 1173, Loss: 0.037622\n",
      "Iteration: 1174, Loss: 0.037606\n",
      "Iteration: 1175, Loss: 0.037595\n",
      "Iteration: 1176, Loss: 0.037574\n",
      "Iteration: 1177, Loss: 0.037562\n",
      "Iteration: 1178, Loss: 0.037555\n",
      "Iteration: 1179, Loss: 0.037549\n",
      "Iteration: 1180, Loss: 0.037542\n",
      "Iteration: 1181, Loss: 0.037574\n",
      "Iteration: 1182, Loss: 0.037538\n",
      "Iteration: 1183, Loss: 0.037524\n",
      "Iteration: 1184, Loss: 0.037511\n",
      "Iteration: 1185, Loss: 0.037483\n",
      "Iteration: 1186, Loss: 0.037457\n",
      "Iteration: 1187, Loss: 0.037433\n",
      "Iteration: 1188, Loss: 0.037419\n",
      "Iteration: 1189, Loss: 0.037412\n",
      "Iteration: 1190, Loss: 0.037404\n",
      "Iteration: 1191, Loss: 0.037395\n",
      "Iteration: 1192, Loss: 0.037400\n",
      "Iteration: 1193, Loss: 0.037388\n",
      "Iteration: 1194, Loss: 0.037380\n",
      "Iteration: 1195, Loss: 0.037373\n",
      "Iteration: 1196, Loss: 0.037361\n",
      "Iteration: 1197, Loss: 0.037347\n",
      "Iteration: 1198, Loss: 0.037319\n",
      "Iteration: 1199, Loss: 0.037305\n",
      "Iteration: 1200, Loss: 0.037253\n",
      "Iteration: 1201, Loss: 0.037226\n",
      "Iteration: 1202, Loss: 0.037198\n",
      "Iteration: 1203, Loss: 0.037172\n",
      "Iteration: 1204, Loss: 0.037143\n",
      "Iteration: 1205, Loss: 0.037113\n",
      "Iteration: 1206, Loss: 0.037093\n",
      "Iteration: 1207, Loss: 0.037075\n",
      "Iteration: 1208, Loss: 0.037046\n",
      "Iteration: 1209, Loss: 0.037012\n",
      "Iteration: 1210, Loss: 0.036990\n",
      "Iteration: 1211, Loss: 0.036967\n",
      "Iteration: 1212, Loss: 0.036949\n",
      "Iteration: 1213, Loss: 0.036937\n",
      "Iteration: 1214, Loss: 0.036924\n",
      "Iteration: 1215, Loss: 0.036910\n",
      "Iteration: 1216, Loss: 0.036904\n",
      "Iteration: 1217, Loss: 0.036894\n",
      "Iteration: 1218, Loss: 0.036880\n",
      "Iteration: 1219, Loss: 0.036869\n",
      "Iteration: 1220, Loss: 0.036853\n",
      "Iteration: 1221, Loss: 0.036847\n",
      "Iteration: 1222, Loss: 0.036842\n",
      "Iteration: 1223, Loss: 0.036837\n",
      "Iteration: 1224, Loss: 0.036827\n",
      "Iteration: 1225, Loss: 0.036818\n",
      "Iteration: 1226, Loss: 0.036807\n",
      "Iteration: 1227, Loss: 0.036802\n",
      "Iteration: 1228, Loss: 0.036788\n",
      "Iteration: 1229, Loss: 0.036774\n",
      "Iteration: 1230, Loss: 0.036761\n",
      "Iteration: 1231, Loss: 0.036742\n",
      "Iteration: 1232, Loss: 0.036728\n",
      "Iteration: 1233, Loss: 0.036710\n",
      "Iteration: 1234, Loss: 0.036699\n",
      "Iteration: 1235, Loss: 0.036691\n",
      "Iteration: 1236, Loss: 0.036680\n",
      "Iteration: 1237, Loss: 0.036670\n",
      "Iteration: 1238, Loss: 0.036654\n",
      "Iteration: 1239, Loss: 0.036661\n",
      "Iteration: 1240, Loss: 0.036644\n",
      "Iteration: 1241, Loss: 0.036632\n",
      "Iteration: 1242, Loss: 0.036605\n",
      "Iteration: 1243, Loss: 0.036594\n",
      "Iteration: 1244, Loss: 0.036581\n",
      "Iteration: 1245, Loss: 0.036571\n",
      "Iteration: 1246, Loss: 0.036558\n",
      "Iteration: 1247, Loss: 0.036549\n",
      "Iteration: 1248, Loss: 0.036529\n",
      "Iteration: 1249, Loss: 0.036518\n",
      "Iteration: 1250, Loss: 0.036509\n",
      "Iteration: 1251, Loss: 0.036500\n",
      "Iteration: 1252, Loss: 0.036479\n",
      "Iteration: 1253, Loss: 0.036501\n",
      "Iteration: 1254, Loss: 0.036473\n",
      "Iteration: 1255, Loss: 0.036461\n",
      "Iteration: 1256, Loss: 0.036443\n",
      "Iteration: 1257, Loss: 0.036429\n",
      "Iteration: 1258, Loss: 0.036409\n",
      "Iteration: 1259, Loss: 0.036378\n",
      "Iteration: 1260, Loss: 0.036384\n",
      "Iteration: 1261, Loss: 0.036361\n",
      "Iteration: 1262, Loss: 0.036340\n",
      "Iteration: 1263, Loss: 0.036315\n",
      "Iteration: 1264, Loss: 0.036374\n",
      "Iteration: 1265, Loss: 0.036311\n",
      "Iteration: 1266, Loss: 0.036300\n",
      "Iteration: 1267, Loss: 0.036276\n",
      "Iteration: 1268, Loss: 0.036264\n",
      "Iteration: 1269, Loss: 0.036251\n",
      "Iteration: 1270, Loss: 0.036245\n",
      "Iteration: 1271, Loss: 0.036241\n",
      "Iteration: 1272, Loss: 0.036232\n",
      "Iteration: 1273, Loss: 0.036219\n",
      "Iteration: 1274, Loss: 0.036191\n",
      "Iteration: 1275, Loss: 0.036192\n",
      "Iteration: 1276, Loss: 0.036176\n",
      "Iteration: 1277, Loss: 0.036160\n",
      "Iteration: 1278, Loss: 0.036149\n",
      "Iteration: 1279, Loss: 0.036143\n",
      "Iteration: 1280, Loss: 0.036128\n",
      "Iteration: 1281, Loss: 0.036105\n",
      "Iteration: 1282, Loss: 0.036090\n",
      "Iteration: 1283, Loss: 0.036100\n",
      "Iteration: 1284, Loss: 0.036079\n",
      "Iteration: 1285, Loss: 0.036068\n",
      "Iteration: 1286, Loss: 0.036058\n",
      "Iteration: 1287, Loss: 0.036048\n",
      "Iteration: 1288, Loss: 0.036033\n",
      "Iteration: 1289, Loss: 0.036022\n",
      "Iteration: 1290, Loss: 0.036006\n",
      "Iteration: 1291, Loss: 0.035992\n",
      "Iteration: 1292, Loss: 0.036038\n",
      "Iteration: 1293, Loss: 0.035984\n",
      "Iteration: 1294, Loss: 0.035964\n",
      "Iteration: 1295, Loss: 0.035948\n",
      "Iteration: 1296, Loss: 0.035934\n",
      "Iteration: 1297, Loss: 0.035924\n",
      "Iteration: 1298, Loss: 0.035911\n",
      "Iteration: 1299, Loss: 0.035911\n",
      "Iteration: 1300, Loss: 0.035902\n",
      "Iteration: 1301, Loss: 0.035894\n",
      "Iteration: 1302, Loss: 0.035882\n",
      "Iteration: 1303, Loss: 0.035871\n",
      "Iteration: 1304, Loss: 0.035854\n",
      "Iteration: 1305, Loss: 0.035839\n",
      "Iteration: 1306, Loss: 0.035830\n",
      "Iteration: 1307, Loss: 0.035825\n",
      "Iteration: 1308, Loss: 0.035814\n",
      "Iteration: 1309, Loss: 0.035813\n",
      "Iteration: 1310, Loss: 0.035806\n",
      "Iteration: 1311, Loss: 0.035795\n",
      "Iteration: 1312, Loss: 0.035780\n",
      "Iteration: 1313, Loss: 0.035768\n",
      "Iteration: 1314, Loss: 0.035754\n",
      "Iteration: 1315, Loss: 0.035740\n",
      "Iteration: 1316, Loss: 0.035716\n",
      "Iteration: 1317, Loss: 0.035698\n",
      "Iteration: 1318, Loss: 0.035693\n",
      "Iteration: 1319, Loss: 0.035677\n",
      "Iteration: 1320, Loss: 0.035668\n",
      "Iteration: 1321, Loss: 0.035658\n",
      "Iteration: 1322, Loss: 0.035646\n",
      "Iteration: 1323, Loss: 0.035632\n",
      "Iteration: 1324, Loss: 0.035615\n",
      "Iteration: 1325, Loss: 0.035602\n",
      "Iteration: 1326, Loss: 0.035577\n",
      "Iteration: 1327, Loss: 0.035562\n",
      "Iteration: 1328, Loss: 0.035556\n",
      "Iteration: 1329, Loss: 0.035548\n",
      "Iteration: 1330, Loss: 0.035537\n",
      "Iteration: 1331, Loss: 0.035517\n",
      "Iteration: 1332, Loss: 0.035488\n",
      "Iteration: 1333, Loss: 0.035513\n",
      "Iteration: 1334, Loss: 0.035466\n",
      "Iteration: 1335, Loss: 0.035440\n",
      "Iteration: 1336, Loss: 0.035413\n",
      "Iteration: 1337, Loss: 0.035400\n",
      "Iteration: 1338, Loss: 0.035386\n",
      "Iteration: 1339, Loss: 0.035373\n",
      "Iteration: 1340, Loss: 0.035375\n",
      "Iteration: 1341, Loss: 0.035367\n",
      "Iteration: 1342, Loss: 0.035355\n",
      "Iteration: 1343, Loss: 0.035342\n",
      "Iteration: 1344, Loss: 0.035321\n",
      "Iteration: 1345, Loss: 0.035301\n",
      "Iteration: 1346, Loss: 0.035320\n",
      "Iteration: 1347, Loss: 0.035293\n",
      "Iteration: 1348, Loss: 0.035277\n",
      "Iteration: 1349, Loss: 0.035249\n",
      "Iteration: 1350, Loss: 0.035227\n",
      "Iteration: 1351, Loss: 0.035202\n",
      "Iteration: 1352, Loss: 0.035174\n",
      "Iteration: 1353, Loss: 0.035149\n",
      "Iteration: 1354, Loss: 0.035134\n",
      "Iteration: 1355, Loss: 0.035122\n",
      "Iteration: 1356, Loss: 0.035112\n",
      "Iteration: 1357, Loss: 0.035102\n",
      "Iteration: 1358, Loss: 0.035093\n",
      "Iteration: 1359, Loss: 0.035079\n",
      "Iteration: 1360, Loss: 0.035067\n",
      "Iteration: 1361, Loss: 0.035070\n",
      "Iteration: 1362, Loss: 0.035046\n",
      "Iteration: 1363, Loss: 0.035020\n",
      "Iteration: 1364, Loss: 0.034993\n",
      "Iteration: 1365, Loss: 0.034971\n",
      "Iteration: 1366, Loss: 0.035098\n",
      "Iteration: 1367, Loss: 0.034954\n",
      "Iteration: 1368, Loss: 0.034941\n",
      "Iteration: 1369, Loss: 0.034927\n",
      "Iteration: 1370, Loss: 0.034921\n",
      "Iteration: 1371, Loss: 0.034911\n",
      "Iteration: 1372, Loss: 0.034899\n",
      "Iteration: 1373, Loss: 0.034895\n",
      "Iteration: 1374, Loss: 0.034864\n",
      "Iteration: 1375, Loss: 0.034847\n",
      "Iteration: 1376, Loss: 0.034830\n",
      "Iteration: 1377, Loss: 0.034824\n",
      "Iteration: 1378, Loss: 0.034810\n",
      "Iteration: 1379, Loss: 0.034798\n",
      "Iteration: 1380, Loss: 0.034777\n",
      "Iteration: 1381, Loss: 0.034763\n",
      "Iteration: 1382, Loss: 0.034753\n",
      "Iteration: 1383, Loss: 0.034743\n",
      "Iteration: 1384, Loss: 0.034727\n",
      "Iteration: 1385, Loss: 0.034719\n",
      "Iteration: 1386, Loss: 0.034709\n",
      "Iteration: 1387, Loss: 0.034700\n",
      "Iteration: 1388, Loss: 0.034677\n",
      "Iteration: 1389, Loss: 0.034660\n",
      "Iteration: 1390, Loss: 0.034634\n",
      "Iteration: 1391, Loss: 0.034611\n",
      "Iteration: 1392, Loss: 0.034592\n",
      "Iteration: 1393, Loss: 0.034574\n",
      "Iteration: 1394, Loss: 0.034564\n",
      "Iteration: 1395, Loss: 0.034557\n",
      "Iteration: 1396, Loss: 0.034551\n",
      "Iteration: 1397, Loss: 0.034536\n",
      "Iteration: 1398, Loss: 0.034521\n",
      "Iteration: 1399, Loss: 0.034502\n",
      "Iteration: 1400, Loss: 0.034460\n",
      "Iteration: 1401, Loss: 0.034440\n",
      "Iteration: 1402, Loss: 0.034427\n",
      "Iteration: 1403, Loss: 0.034406\n",
      "Iteration: 1404, Loss: 0.034397\n",
      "Iteration: 1405, Loss: 0.034388\n",
      "Iteration: 1406, Loss: 0.034380\n",
      "Iteration: 1407, Loss: 0.034366\n",
      "Iteration: 1408, Loss: 0.034359\n",
      "Iteration: 1409, Loss: 0.034348\n",
      "Iteration: 1410, Loss: 0.034434\n",
      "Iteration: 1411, Loss: 0.034346\n",
      "Iteration: 1412, Loss: 0.034338\n",
      "Iteration: 1413, Loss: 0.034330\n",
      "Iteration: 1414, Loss: 0.034322\n",
      "Iteration: 1415, Loss: 0.034313\n",
      "Iteration: 1416, Loss: 0.034302\n",
      "Iteration: 1417, Loss: 0.034296\n",
      "Iteration: 1418, Loss: 0.034284\n",
      "Iteration: 1419, Loss: 0.034276\n",
      "Iteration: 1420, Loss: 0.034268\n",
      "Iteration: 1421, Loss: 0.034259\n",
      "Iteration: 1422, Loss: 0.034251\n",
      "Iteration: 1423, Loss: 0.034306\n",
      "Iteration: 1424, Loss: 0.034247\n",
      "Iteration: 1425, Loss: 0.034237\n",
      "Iteration: 1426, Loss: 0.034224\n",
      "Iteration: 1427, Loss: 0.034214\n",
      "Iteration: 1428, Loss: 0.034204\n",
      "Iteration: 1429, Loss: 0.034195\n",
      "Iteration: 1430, Loss: 0.034189\n",
      "Iteration: 1431, Loss: 0.034182\n",
      "Iteration: 1432, Loss: 0.034171\n",
      "Iteration: 1433, Loss: 0.034223\n",
      "Iteration: 1434, Loss: 0.034166\n",
      "Iteration: 1435, Loss: 0.034162\n",
      "Iteration: 1436, Loss: 0.034149\n",
      "Iteration: 1437, Loss: 0.034141\n",
      "Iteration: 1438, Loss: 0.034134\n",
      "Iteration: 1439, Loss: 0.034127\n",
      "Iteration: 1440, Loss: 0.034121\n",
      "Iteration: 1441, Loss: 0.034105\n",
      "Iteration: 1442, Loss: 0.034093\n",
      "Iteration: 1443, Loss: 0.034087\n",
      "Iteration: 1444, Loss: 0.034070\n",
      "Iteration: 1445, Loss: 0.034057\n",
      "Iteration: 1446, Loss: 0.034035\n",
      "Iteration: 1447, Loss: 0.034023\n",
      "Iteration: 1448, Loss: 0.034017\n",
      "Iteration: 1449, Loss: 0.034012\n",
      "Iteration: 1450, Loss: 0.034006\n",
      "Iteration: 1451, Loss: 0.033997\n",
      "Iteration: 1452, Loss: 0.033993\n",
      "Iteration: 1453, Loss: 0.033972\n",
      "Iteration: 1454, Loss: 0.033956\n",
      "Iteration: 1455, Loss: 0.033937\n",
      "Iteration: 1456, Loss: 0.033914\n",
      "Iteration: 1457, Loss: 0.033924\n",
      "Iteration: 1458, Loss: 0.033904\n",
      "Iteration: 1459, Loss: 0.033893\n",
      "Iteration: 1460, Loss: 0.033880\n",
      "Iteration: 1461, Loss: 0.033874\n",
      "Iteration: 1462, Loss: 0.033858\n",
      "Iteration: 1463, Loss: 0.033848\n",
      "Iteration: 1464, Loss: 0.033833\n",
      "Iteration: 1465, Loss: 0.033820\n",
      "Iteration: 1466, Loss: 0.033805\n",
      "Iteration: 1467, Loss: 0.033781\n",
      "Iteration: 1468, Loss: 0.033904\n",
      "Iteration: 1469, Loss: 0.033767\n",
      "Iteration: 1470, Loss: 0.033884\n",
      "Iteration: 1471, Loss: 0.033724\n",
      "Iteration: 1472, Loss: 0.033697\n",
      "Iteration: 1473, Loss: 0.033676\n",
      "Iteration: 1474, Loss: 0.033668\n",
      "Iteration: 1475, Loss: 0.033657\n",
      "Iteration: 1476, Loss: 0.033649\n",
      "Iteration: 1477, Loss: 0.033643\n",
      "Iteration: 1478, Loss: 0.033636\n",
      "Iteration: 1479, Loss: 0.033625\n",
      "Iteration: 1480, Loss: 0.033613\n",
      "Iteration: 1481, Loss: 0.033605\n",
      "Iteration: 1482, Loss: 0.033588\n",
      "Iteration: 1483, Loss: 0.033669\n",
      "Iteration: 1484, Loss: 0.033584\n",
      "Iteration: 1485, Loss: 0.033577\n",
      "Iteration: 1486, Loss: 0.033566\n",
      "Iteration: 1487, Loss: 0.033560\n",
      "Iteration: 1488, Loss: 0.033547\n",
      "Iteration: 1489, Loss: 0.033533\n",
      "Iteration: 1490, Loss: 0.033518\n",
      "Iteration: 1491, Loss: 0.033502\n",
      "Iteration: 1492, Loss: 0.033485\n",
      "Iteration: 1493, Loss: 0.033552\n",
      "Iteration: 1494, Loss: 0.033483\n",
      "Iteration: 1495, Loss: 0.033475\n",
      "Iteration: 1496, Loss: 0.033470\n",
      "Iteration: 1497, Loss: 0.033464\n",
      "Iteration: 1498, Loss: 0.033460\n",
      "Iteration: 1499, Loss: 0.033457\n",
      "Iteration: 1500, Loss: 0.033454\n",
      "Iteration: 1501, Loss: 0.033447\n",
      "Iteration: 1502, Loss: 0.033440\n",
      "Iteration: 1503, Loss: 0.033433\n",
      "Iteration: 1504, Loss: 0.033440\n",
      "Iteration: 1505, Loss: 0.033431\n",
      "Iteration: 1506, Loss: 0.033427\n",
      "Iteration: 1507, Loss: 0.033423\n",
      "Iteration: 1508, Loss: 0.033421\n",
      "Iteration: 1509, Loss: 0.033416\n",
      "Iteration: 1510, Loss: 0.033474\n",
      "Iteration: 1511, Loss: 0.033414\n",
      "Iteration: 1512, Loss: 0.033407\n",
      "Iteration: 1513, Loss: 0.033400\n",
      "Iteration: 1514, Loss: 0.033391\n",
      "Iteration: 1515, Loss: 0.033385\n",
      "Iteration: 1516, Loss: 0.033379\n",
      "Iteration: 1517, Loss: 0.033367\n",
      "Iteration: 1518, Loss: 0.033362\n",
      "Iteration: 1519, Loss: 0.033354\n",
      "Iteration: 1520, Loss: 0.033347\n",
      "Iteration: 1521, Loss: 0.033333\n",
      "Iteration: 1522, Loss: 0.033331\n",
      "Iteration: 1523, Loss: 0.033314\n",
      "Iteration: 1524, Loss: 0.033300\n",
      "Iteration: 1525, Loss: 0.033290\n",
      "Iteration: 1526, Loss: 0.033278\n",
      "Iteration: 1527, Loss: 0.033266\n",
      "Iteration: 1528, Loss: 0.033253\n",
      "Iteration: 1529, Loss: 0.033236\n",
      "Iteration: 1530, Loss: 0.033218\n",
      "Iteration: 1531, Loss: 0.033191\n",
      "Iteration: 1532, Loss: 0.033164\n",
      "Iteration: 1533, Loss: 0.033140\n",
      "Iteration: 1534, Loss: 0.033118\n",
      "Iteration: 1535, Loss: 0.033114\n",
      "Iteration: 1536, Loss: 0.033105\n",
      "Iteration: 1537, Loss: 0.033100\n",
      "Iteration: 1538, Loss: 0.033096\n",
      "Iteration: 1539, Loss: 0.033097\n",
      "Iteration: 1540, Loss: 0.033094\n",
      "Iteration: 1541, Loss: 0.033089\n",
      "Iteration: 1542, Loss: 0.033075\n",
      "Iteration: 1543, Loss: 0.033058\n",
      "Iteration: 1544, Loss: 0.033039\n",
      "Iteration: 1545, Loss: 0.033029\n",
      "Iteration: 1546, Loss: 0.033012\n",
      "Iteration: 1547, Loss: 0.032997\n",
      "Iteration: 1548, Loss: 0.032983\n",
      "Iteration: 1549, Loss: 0.032972\n",
      "Iteration: 1550, Loss: 0.032966\n",
      "Iteration: 1551, Loss: 0.032962\n",
      "Iteration: 1552, Loss: 0.032950\n",
      "Iteration: 1553, Loss: 0.032941\n",
      "Iteration: 1554, Loss: 0.032927\n",
      "Iteration: 1555, Loss: 0.032913\n",
      "Iteration: 1556, Loss: 0.033144\n",
      "Iteration: 1557, Loss: 0.032910\n",
      "Iteration: 1558, Loss: 0.032898\n",
      "Iteration: 1559, Loss: 0.032890\n",
      "Iteration: 1560, Loss: 0.032885\n",
      "Iteration: 1561, Loss: 0.032881\n",
      "Iteration: 1562, Loss: 0.032872\n",
      "Iteration: 1563, Loss: 0.032857\n",
      "Iteration: 1564, Loss: 0.032853\n",
      "Iteration: 1565, Loss: 0.032832\n",
      "Iteration: 1566, Loss: 0.032826\n",
      "Iteration: 1567, Loss: 0.032821\n",
      "Iteration: 1568, Loss: 0.032815\n",
      "Iteration: 1569, Loss: 0.032801\n",
      "Iteration: 1570, Loss: 0.032787\n",
      "Iteration: 1571, Loss: 0.032774\n",
      "Iteration: 1572, Loss: 0.032761\n",
      "Iteration: 1573, Loss: 0.033012\n",
      "Iteration: 1574, Loss: 0.032757\n",
      "Iteration: 1575, Loss: 0.032742\n",
      "Iteration: 1576, Loss: 0.032723\n",
      "Iteration: 1577, Loss: 0.032709\n",
      "Iteration: 1578, Loss: 0.032699\n",
      "Iteration: 1579, Loss: 0.032684\n",
      "Iteration: 1580, Loss: 0.032668\n",
      "Iteration: 1581, Loss: 0.032658\n",
      "Iteration: 1582, Loss: 0.032649\n",
      "Iteration: 1583, Loss: 0.032640\n",
      "Iteration: 1584, Loss: 0.032653\n",
      "Iteration: 1585, Loss: 0.032634\n",
      "Iteration: 1586, Loss: 0.032625\n",
      "Iteration: 1587, Loss: 0.032615\n",
      "Iteration: 1588, Loss: 0.032608\n",
      "Iteration: 1589, Loss: 0.032602\n",
      "Iteration: 1590, Loss: 0.032600\n",
      "Iteration: 1591, Loss: 0.032590\n",
      "Iteration: 1592, Loss: 0.032586\n",
      "Iteration: 1593, Loss: 0.032585\n",
      "Iteration: 1594, Loss: 0.032581\n",
      "Iteration: 1595, Loss: 0.032577\n",
      "Iteration: 1596, Loss: 0.032566\n",
      "Iteration: 1597, Loss: 0.032558\n",
      "Iteration: 1598, Loss: 0.032547\n",
      "Iteration: 1599, Loss: 0.032536\n",
      "Iteration: 1600, Loss: 0.032523\n",
      "Iteration: 1601, Loss: 0.032517\n",
      "Iteration: 1602, Loss: 0.032512\n",
      "Iteration: 1603, Loss: 0.032507\n",
      "Iteration: 1604, Loss: 0.032502\n",
      "Iteration: 1605, Loss: 0.032498\n",
      "Iteration: 1606, Loss: 0.032495\n",
      "Iteration: 1607, Loss: 0.032491\n",
      "Iteration: 1608, Loss: 0.032485\n",
      "Iteration: 1609, Loss: 0.032480\n",
      "Iteration: 1610, Loss: 0.032470\n",
      "Iteration: 1611, Loss: 0.032462\n",
      "Iteration: 1612, Loss: 0.032452\n",
      "Iteration: 1613, Loss: 0.032436\n",
      "Iteration: 1614, Loss: 0.032416\n",
      "Iteration: 1615, Loss: 0.032407\n",
      "Iteration: 1616, Loss: 0.032412\n",
      "Iteration: 1617, Loss: 0.032400\n",
      "Iteration: 1618, Loss: 0.032393\n",
      "Iteration: 1619, Loss: 0.032384\n",
      "Iteration: 1620, Loss: 0.032380\n",
      "Iteration: 1621, Loss: 0.032375\n",
      "Iteration: 1622, Loss: 0.032371\n",
      "Iteration: 1623, Loss: 0.032367\n",
      "Iteration: 1624, Loss: 0.032362\n",
      "Iteration: 1625, Loss: 0.032355\n",
      "Iteration: 1626, Loss: 0.032367\n",
      "Iteration: 1627, Loss: 0.032352\n",
      "Iteration: 1628, Loss: 0.032341\n",
      "Iteration: 1629, Loss: 0.032330\n",
      "Iteration: 1630, Loss: 0.032317\n",
      "Iteration: 1631, Loss: 0.032309\n",
      "Iteration: 1632, Loss: 0.032299\n",
      "Iteration: 1633, Loss: 0.032421\n",
      "Iteration: 1634, Loss: 0.032291\n",
      "Iteration: 1635, Loss: 0.032278\n",
      "Iteration: 1636, Loss: 0.032234\n",
      "Iteration: 1637, Loss: 0.032247\n",
      "Iteration: 1638, Loss: 0.032222\n",
      "Iteration: 1639, Loss: 0.032212\n",
      "Iteration: 1640, Loss: 0.032195\n",
      "Iteration: 1641, Loss: 0.032188\n",
      "Iteration: 1642, Loss: 0.032181\n",
      "Iteration: 1643, Loss: 0.032172\n",
      "Iteration: 1644, Loss: 0.032156\n",
      "Iteration: 1645, Loss: 0.032196\n",
      "Iteration: 1646, Loss: 0.032150\n",
      "Iteration: 1647, Loss: 0.032136\n",
      "Iteration: 1648, Loss: 0.032120\n",
      "Iteration: 1649, Loss: 0.032115\n",
      "Iteration: 1650, Loss: 0.032104\n",
      "Iteration: 1651, Loss: 0.032095\n",
      "Iteration: 1652, Loss: 0.032085\n",
      "Iteration: 1653, Loss: 0.032080\n",
      "Iteration: 1654, Loss: 0.032076\n",
      "Iteration: 1655, Loss: 0.032075\n",
      "Iteration: 1656, Loss: 0.032072\n",
      "Iteration: 1657, Loss: 0.032067\n",
      "Iteration: 1658, Loss: 0.032063\n",
      "Iteration: 1659, Loss: 0.032058\n",
      "Iteration: 1660, Loss: 0.032053\n",
      "Iteration: 1661, Loss: 0.032047\n",
      "Iteration: 1662, Loss: 0.032040\n",
      "Iteration: 1663, Loss: 0.032306\n",
      "Iteration: 1664, Loss: 0.032037\n",
      "Iteration: 1665, Loss: 0.032031\n",
      "Iteration: 1666, Loss: 0.032019\n",
      "Iteration: 1667, Loss: 0.032011\n",
      "Iteration: 1668, Loss: 0.031991\n",
      "Iteration: 1669, Loss: 0.031974\n",
      "Iteration: 1670, Loss: 0.031961\n",
      "Iteration: 1671, Loss: 0.031946\n",
      "Iteration: 1672, Loss: 0.031935\n",
      "Iteration: 1673, Loss: 0.031928\n",
      "Iteration: 1674, Loss: 0.031919\n",
      "Iteration: 1675, Loss: 0.031909\n",
      "Iteration: 1676, Loss: 0.031938\n",
      "Iteration: 1677, Loss: 0.031906\n",
      "Iteration: 1678, Loss: 0.031901\n",
      "Iteration: 1679, Loss: 0.031899\n",
      "Iteration: 1680, Loss: 0.031897\n",
      "Iteration: 1681, Loss: 0.031896\n",
      "Iteration: 1682, Loss: 0.031915\n",
      "Iteration: 1683, Loss: 0.031889\n",
      "Iteration: 1684, Loss: 0.031884\n",
      "Iteration: 1685, Loss: 0.031881\n",
      "Iteration: 1686, Loss: 0.031876\n",
      "Iteration: 1687, Loss: 0.031868\n",
      "Iteration: 1688, Loss: 0.031884\n",
      "Iteration: 1689, Loss: 0.031864\n",
      "Iteration: 1690, Loss: 0.031857\n",
      "Iteration: 1691, Loss: 0.031848\n",
      "Iteration: 1692, Loss: 0.031840\n",
      "Iteration: 1693, Loss: 0.031841\n",
      "Iteration: 1694, Loss: 0.031833\n",
      "Iteration: 1695, Loss: 0.031825\n",
      "Iteration: 1696, Loss: 0.031814\n",
      "Iteration: 1697, Loss: 0.032349\n",
      "Iteration: 1698, Loss: 0.031812\n",
      "Iteration: 1699, Loss: 0.031802\n",
      "Iteration: 1700, Loss: 0.031800\n",
      "Iteration: 1701, Loss: 0.031776\n",
      "Iteration: 1702, Loss: 0.031767\n",
      "Iteration: 1703, Loss: 0.031754\n",
      "Iteration: 1704, Loss: 0.031770\n",
      "Iteration: 1705, Loss: 0.031749\n",
      "Iteration: 1706, Loss: 0.031735\n",
      "Iteration: 1707, Loss: 0.031708\n",
      "Iteration: 1708, Loss: 0.031684\n",
      "Iteration: 1709, Loss: 0.031658\n",
      "Iteration: 1710, Loss: 0.031641\n",
      "Iteration: 1711, Loss: 0.031624\n",
      "Iteration: 1712, Loss: 0.031618\n",
      "Iteration: 1713, Loss: 0.031614\n",
      "Iteration: 1714, Loss: 0.031605\n",
      "Iteration: 1715, Loss: 0.031601\n",
      "Iteration: 1716, Loss: 0.031592\n",
      "Iteration: 1717, Loss: 0.031582\n",
      "Iteration: 1718, Loss: 0.031573\n",
      "Iteration: 1719, Loss: 0.031552\n",
      "Iteration: 1720, Loss: 0.031546\n",
      "Iteration: 1721, Loss: 0.031536\n",
      "Iteration: 1722, Loss: 0.031587\n",
      "Iteration: 1723, Loss: 0.031533\n",
      "Iteration: 1724, Loss: 0.031525\n",
      "Iteration: 1725, Loss: 0.031505\n",
      "Iteration: 1726, Loss: 0.031490\n",
      "Iteration: 1727, Loss: 0.031483\n",
      "Iteration: 1728, Loss: 0.031476\n",
      "Iteration: 1729, Loss: 0.031467\n",
      "Iteration: 1730, Loss: 0.031469\n",
      "Iteration: 1731, Loss: 0.031462\n",
      "Iteration: 1732, Loss: 0.031454\n",
      "Iteration: 1733, Loss: 0.031447\n",
      "Iteration: 1734, Loss: 0.031430\n",
      "Iteration: 1735, Loss: 0.031445\n",
      "Iteration: 1736, Loss: 0.031425\n",
      "Iteration: 1737, Loss: 0.031424\n",
      "Iteration: 1738, Loss: 0.031420\n",
      "Iteration: 1739, Loss: 0.031415\n",
      "Iteration: 1740, Loss: 0.031409\n",
      "Iteration: 1741, Loss: 0.031401\n",
      "Iteration: 1742, Loss: 0.031391\n",
      "Iteration: 1743, Loss: 0.031385\n",
      "Iteration: 1744, Loss: 0.031385\n",
      "Iteration: 1745, Loss: 0.031378\n",
      "Iteration: 1746, Loss: 0.031368\n",
      "Iteration: 1747, Loss: 0.031361\n",
      "Iteration: 1748, Loss: 0.031356\n",
      "Iteration: 1749, Loss: 0.031351\n",
      "Iteration: 1750, Loss: 0.031342\n",
      "Iteration: 1751, Loss: 0.031335\n",
      "Iteration: 1752, Loss: 0.031328\n",
      "Iteration: 1753, Loss: 0.031344\n",
      "Iteration: 1754, Loss: 0.031324\n",
      "Iteration: 1755, Loss: 0.031319\n",
      "Iteration: 1756, Loss: 0.031312\n",
      "Iteration: 1757, Loss: 0.031304\n",
      "Iteration: 1758, Loss: 0.031290\n",
      "Iteration: 1759, Loss: 0.031278\n",
      "Iteration: 1760, Loss: 0.031275\n",
      "Iteration: 1761, Loss: 0.031265\n",
      "Iteration: 1762, Loss: 0.031260\n",
      "Iteration: 1763, Loss: 0.031249\n",
      "Iteration: 1764, Loss: 0.031245\n",
      "Iteration: 1765, Loss: 0.031231\n",
      "Iteration: 1766, Loss: 0.031225\n",
      "Iteration: 1767, Loss: 0.031221\n",
      "Iteration: 1768, Loss: 0.031223\n",
      "Iteration: 1769, Loss: 0.031219\n",
      "Iteration: 1770, Loss: 0.031215\n",
      "Iteration: 1771, Loss: 0.031208\n",
      "Iteration: 1772, Loss: 0.031196\n",
      "Iteration: 1773, Loss: 0.031282\n",
      "Iteration: 1774, Loss: 0.031191\n",
      "Iteration: 1775, Loss: 0.031183\n",
      "Iteration: 1776, Loss: 0.031176\n",
      "Iteration: 1777, Loss: 0.031170\n",
      "Iteration: 1778, Loss: 0.031159\n",
      "Iteration: 1779, Loss: 0.031151\n",
      "Iteration: 1780, Loss: 0.031141\n",
      "Iteration: 1781, Loss: 0.031135\n",
      "Iteration: 1782, Loss: 0.031130\n",
      "Iteration: 1783, Loss: 0.031131\n",
      "Iteration: 1784, Loss: 0.031126\n",
      "Iteration: 1785, Loss: 0.031126\n",
      "Iteration: 1786, Loss: 0.031124\n",
      "Iteration: 1787, Loss: 0.031119\n",
      "Iteration: 1788, Loss: 0.031107\n",
      "Iteration: 1789, Loss: 0.031097\n",
      "Iteration: 1790, Loss: 0.031089\n",
      "Iteration: 1791, Loss: 0.031081\n",
      "Iteration: 1792, Loss: 0.031074\n",
      "Iteration: 1793, Loss: 0.031064\n",
      "Iteration: 1794, Loss: 0.031052\n",
      "Iteration: 1795, Loss: 0.031039\n",
      "Iteration: 1796, Loss: 0.031369\n",
      "Iteration: 1797, Loss: 0.031034\n",
      "Iteration: 1798, Loss: 0.031019\n",
      "Iteration: 1799, Loss: 0.031001\n",
      "Iteration: 1800, Loss: 0.030993\n",
      "Iteration: 1801, Loss: 0.030984\n",
      "Iteration: 1802, Loss: 0.030965\n",
      "Iteration: 1803, Loss: 0.030955\n",
      "Iteration: 1804, Loss: 0.030919\n",
      "Iteration: 1805, Loss: 0.030910\n",
      "Iteration: 1806, Loss: 0.030901\n",
      "Iteration: 1807, Loss: 0.030891\n",
      "Iteration: 1808, Loss: 0.030882\n",
      "Iteration: 1809, Loss: 0.030866\n",
      "Iteration: 1810, Loss: 0.030865\n",
      "Iteration: 1811, Loss: 0.030861\n",
      "Iteration: 1812, Loss: 0.030854\n",
      "Iteration: 1813, Loss: 0.030843\n",
      "Iteration: 1814, Loss: 0.030835\n",
      "Iteration: 1815, Loss: 0.030845\n",
      "Iteration: 1816, Loss: 0.030830\n",
      "Iteration: 1817, Loss: 0.030825\n",
      "Iteration: 1818, Loss: 0.030822\n",
      "Iteration: 1819, Loss: 0.030818\n",
      "Iteration: 1820, Loss: 0.030810\n",
      "Iteration: 1821, Loss: 0.030803\n",
      "Iteration: 1822, Loss: 0.030796\n",
      "Iteration: 1823, Loss: 0.030783\n",
      "Iteration: 1824, Loss: 0.030790\n",
      "Iteration: 1825, Loss: 0.030775\n",
      "Iteration: 1826, Loss: 0.030768\n",
      "Iteration: 1827, Loss: 0.030756\n",
      "Iteration: 1828, Loss: 0.030751\n",
      "Iteration: 1829, Loss: 0.030737\n",
      "Iteration: 1830, Loss: 0.030721\n",
      "Iteration: 1831, Loss: 0.030713\n",
      "Iteration: 1832, Loss: 0.030709\n",
      "Iteration: 1833, Loss: 0.030705\n",
      "Iteration: 1834, Loss: 0.030701\n",
      "Iteration: 1835, Loss: 0.030694\n",
      "Iteration: 1836, Loss: 0.030685\n",
      "Iteration: 1837, Loss: 0.030674\n",
      "Iteration: 1838, Loss: 0.030668\n",
      "Iteration: 1839, Loss: 0.030663\n",
      "Iteration: 1840, Loss: 0.030659\n",
      "Iteration: 1841, Loss: 0.030657\n",
      "Iteration: 1842, Loss: 0.030660\n",
      "Iteration: 1843, Loss: 0.030654\n",
      "Iteration: 1844, Loss: 0.030651\n",
      "Iteration: 1845, Loss: 0.030645\n",
      "Iteration: 1846, Loss: 0.030640\n",
      "Iteration: 1847, Loss: 0.030635\n",
      "Iteration: 1848, Loss: 0.030642\n",
      "Iteration: 1849, Loss: 0.030626\n",
      "Iteration: 1850, Loss: 0.030618\n",
      "Iteration: 1851, Loss: 0.030610\n",
      "Iteration: 1852, Loss: 0.030604\n",
      "Iteration: 1853, Loss: 0.030596\n",
      "Iteration: 1854, Loss: 0.030629\n",
      "Iteration: 1855, Loss: 0.030590\n",
      "Iteration: 1856, Loss: 0.030583\n",
      "Iteration: 1857, Loss: 0.030574\n",
      "Iteration: 1858, Loss: 0.030570\n",
      "Iteration: 1859, Loss: 0.030563\n",
      "Iteration: 1860, Loss: 0.030571\n",
      "Iteration: 1861, Loss: 0.030561\n",
      "Iteration: 1862, Loss: 0.030559\n",
      "Iteration: 1863, Loss: 0.030558\n",
      "Iteration: 1864, Loss: 0.030554\n",
      "Iteration: 1865, Loss: 0.030549\n",
      "Iteration: 1866, Loss: 0.030543\n",
      "Iteration: 1867, Loss: 0.030539\n",
      "Iteration: 1868, Loss: 0.030532\n",
      "Iteration: 1869, Loss: 0.030735\n",
      "Iteration: 1870, Loss: 0.030530\n",
      "Iteration: 1871, Loss: 0.030527\n",
      "Iteration: 1872, Loss: 0.030516\n",
      "Iteration: 1873, Loss: 0.030500\n",
      "Iteration: 1874, Loss: 0.030491\n",
      "Iteration: 1875, Loss: 0.030474\n",
      "Iteration: 1876, Loss: 0.030460\n",
      "Iteration: 1877, Loss: 0.030449\n",
      "Iteration: 1878, Loss: 0.030445\n",
      "Iteration: 1879, Loss: 0.030441\n",
      "Iteration: 1880, Loss: 0.030437\n",
      "Iteration: 1881, Loss: 0.030432\n",
      "Iteration: 1882, Loss: 0.030430\n",
      "Iteration: 1883, Loss: 0.030427\n",
      "Iteration: 1884, Loss: 0.030421\n",
      "Iteration: 1885, Loss: 0.030415\n",
      "Iteration: 1886, Loss: 0.030409\n",
      "Iteration: 1887, Loss: 0.030403\n",
      "Iteration: 1888, Loss: 0.030398\n",
      "Iteration: 1889, Loss: 0.030431\n",
      "Iteration: 1890, Loss: 0.030397\n",
      "Iteration: 1891, Loss: 0.030392\n",
      "Iteration: 1892, Loss: 0.030382\n",
      "Iteration: 1893, Loss: 0.030369\n",
      "Iteration: 1894, Loss: 0.030357\n",
      "Iteration: 1895, Loss: 0.030346\n",
      "Iteration: 1896, Loss: 0.030343\n",
      "Iteration: 1897, Loss: 0.030340\n",
      "Iteration: 1898, Loss: 0.030338\n",
      "Iteration: 1899, Loss: 0.030334\n",
      "Iteration: 1900, Loss: 0.030330\n",
      "Iteration: 1901, Loss: 0.030327\n",
      "Iteration: 1902, Loss: 0.030326\n",
      "Iteration: 1903, Loss: 0.030324\n",
      "Iteration: 1904, Loss: 0.030319\n",
      "Iteration: 1905, Loss: 0.030330\n",
      "Iteration: 1906, Loss: 0.030317\n",
      "Iteration: 1907, Loss: 0.030312\n",
      "Iteration: 1908, Loss: 0.030304\n",
      "Iteration: 1909, Loss: 0.030300\n",
      "Iteration: 1910, Loss: 0.030297\n",
      "Iteration: 1911, Loss: 0.030293\n",
      "Iteration: 1912, Loss: 0.030291\n",
      "Iteration: 1913, Loss: 0.030287\n",
      "Iteration: 1914, Loss: 0.030284\n",
      "Iteration: 1915, Loss: 0.030279\n",
      "Iteration: 1916, Loss: 0.030277\n",
      "Iteration: 1917, Loss: 0.030271\n",
      "Iteration: 1918, Loss: 0.030266\n",
      "Iteration: 1919, Loss: 0.030260\n",
      "Iteration: 1920, Loss: 0.030252\n",
      "Iteration: 1921, Loss: 0.030293\n",
      "Iteration: 1922, Loss: 0.030249\n",
      "Iteration: 1923, Loss: 0.030239\n",
      "Iteration: 1924, Loss: 0.030235\n",
      "Iteration: 1925, Loss: 0.030231\n",
      "Iteration: 1926, Loss: 0.030229\n",
      "Iteration: 1927, Loss: 0.030224\n",
      "Iteration: 1928, Loss: 0.030231\n",
      "Iteration: 1929, Loss: 0.030221\n",
      "Iteration: 1930, Loss: 0.030217\n",
      "Iteration: 1931, Loss: 0.030216\n",
      "Iteration: 1932, Loss: 0.030211\n",
      "Iteration: 1933, Loss: 0.030207\n",
      "Iteration: 1934, Loss: 0.030200\n",
      "Iteration: 1935, Loss: 0.030209\n",
      "Iteration: 1936, Loss: 0.030198\n",
      "Iteration: 1937, Loss: 0.030195\n",
      "Iteration: 1938, Loss: 0.030191\n",
      "Iteration: 1939, Loss: 0.030189\n",
      "Iteration: 1940, Loss: 0.030185\n",
      "Iteration: 1941, Loss: 0.030181\n",
      "Iteration: 1942, Loss: 0.030174\n",
      "Iteration: 1943, Loss: 0.030165\n",
      "Iteration: 1944, Loss: 0.030153\n",
      "Iteration: 1945, Loss: 0.030159\n",
      "Iteration: 1946, Loss: 0.030150\n",
      "Iteration: 1947, Loss: 0.030142\n",
      "Iteration: 1948, Loss: 0.030135\n",
      "Iteration: 1949, Loss: 0.030129\n",
      "Iteration: 1950, Loss: 0.030123\n",
      "Iteration: 1951, Loss: 0.030118\n",
      "Iteration: 1952, Loss: 0.030114\n",
      "Iteration: 1953, Loss: 0.030109\n",
      "Iteration: 1954, Loss: 0.030106\n",
      "Iteration: 1955, Loss: 0.030103\n",
      "Iteration: 1956, Loss: 0.030101\n",
      "Iteration: 1957, Loss: 0.030099\n",
      "Iteration: 1958, Loss: 0.030098\n",
      "Iteration: 1959, Loss: 0.030094\n",
      "Iteration: 1960, Loss: 0.030088\n",
      "Iteration: 1961, Loss: 0.030175\n",
      "Iteration: 1962, Loss: 0.030087\n",
      "Iteration: 1963, Loss: 0.030082\n",
      "Iteration: 1964, Loss: 0.030072\n",
      "Iteration: 1965, Loss: 0.030063\n",
      "Iteration: 1966, Loss: 0.030046\n",
      "Iteration: 1967, Loss: 0.030290\n",
      "Iteration: 1968, Loss: 0.030043\n",
      "Iteration: 1969, Loss: 0.030037\n",
      "Iteration: 1970, Loss: 0.030031\n",
      "Iteration: 1971, Loss: 0.030026\n",
      "Iteration: 1972, Loss: 0.030018\n",
      "Iteration: 1973, Loss: 0.030005\n",
      "Iteration: 1974, Loss: 0.030872\n",
      "Iteration: 1975, Loss: 0.030002\n",
      "Iteration: 1976, Loss: 0.029993\n",
      "Iteration: 1977, Loss: 0.029985\n",
      "Iteration: 1978, Loss: 0.029973\n",
      "Iteration: 1979, Loss: 0.029964\n",
      "Iteration: 1980, Loss: 0.029952\n",
      "Iteration: 1981, Loss: 0.029945\n",
      "Iteration: 1982, Loss: 0.029940\n",
      "Iteration: 1983, Loss: 0.029936\n",
      "Iteration: 1984, Loss: 0.029930\n",
      "Iteration: 1985, Loss: 0.029926\n",
      "Iteration: 1986, Loss: 0.029921\n",
      "Iteration: 1987, Loss: 0.029930\n",
      "Iteration: 1988, Loss: 0.029920\n",
      "Iteration: 1989, Loss: 0.029917\n",
      "Iteration: 1990, Loss: 0.029915\n",
      "Iteration: 1991, Loss: 0.029911\n",
      "Iteration: 1992, Loss: 0.029909\n",
      "Iteration: 1993, Loss: 0.029903\n",
      "Iteration: 1994, Loss: 0.029904\n",
      "Iteration: 1995, Loss: 0.029901\n",
      "Iteration: 1996, Loss: 0.029896\n",
      "Iteration: 1997, Loss: 0.029892\n",
      "Iteration: 1998, Loss: 0.029889\n",
      "Iteration: 1999, Loss: 0.029884\n",
      "Iteration: 2000, Loss: 0.029875\n",
      "Iteration: 2001, Loss: 0.029868\n",
      "Iteration: 2002, Loss: 0.029861\n",
      "Iteration: 2003, Loss: 0.030120\n",
      "Iteration: 2004, Loss: 0.029859\n",
      "Iteration: 2005, Loss: 0.029855\n",
      "Iteration: 2006, Loss: 0.029852\n",
      "Iteration: 2007, Loss: 0.029845\n",
      "Iteration: 2008, Loss: 0.029838\n",
      "Iteration: 2009, Loss: 0.029858\n",
      "Iteration: 2010, Loss: 0.029837\n",
      "Iteration: 2011, Loss: 0.029832\n",
      "Iteration: 2012, Loss: 0.029826\n",
      "Iteration: 2013, Loss: 0.029822\n",
      "Iteration: 2014, Loss: 0.029817\n",
      "Iteration: 2015, Loss: 0.029811\n",
      "Iteration: 2016, Loss: 0.029807\n",
      "Iteration: 2017, Loss: 0.029873\n",
      "Iteration: 2018, Loss: 0.029805\n",
      "Iteration: 2019, Loss: 0.029800\n",
      "Iteration: 2020, Loss: 0.029796\n",
      "Iteration: 2021, Loss: 0.029796\n",
      "Iteration: 2022, Loss: 0.029791\n",
      "Iteration: 2023, Loss: 0.029787\n",
      "Iteration: 2024, Loss: 0.029781\n",
      "Iteration: 2025, Loss: 0.029774\n",
      "Iteration: 2026, Loss: 0.029768\n",
      "Iteration: 2027, Loss: 0.029758\n",
      "Iteration: 2028, Loss: 0.029752\n",
      "Iteration: 2029, Loss: 0.029745\n",
      "Iteration: 2030, Loss: 0.029738\n",
      "Iteration: 2031, Loss: 0.029731\n",
      "Iteration: 2032, Loss: 0.029724\n",
      "Iteration: 2033, Loss: 0.029722\n",
      "Iteration: 2034, Loss: 0.029713\n",
      "Iteration: 2035, Loss: 0.029709\n",
      "Iteration: 2036, Loss: 0.029705\n",
      "Iteration: 2037, Loss: 0.029701\n",
      "Iteration: 2038, Loss: 0.029698\n",
      "Iteration: 2039, Loss: 0.029696\n",
      "Iteration: 2040, Loss: 0.029695\n",
      "Iteration: 2041, Loss: 0.029692\n",
      "Iteration: 2042, Loss: 0.029873\n",
      "Iteration: 2043, Loss: 0.029691\n",
      "Iteration: 2044, Loss: 0.029689\n",
      "Iteration: 2045, Loss: 0.029687\n",
      "Iteration: 2046, Loss: 0.029685\n",
      "Iteration: 2047, Loss: 0.029683\n",
      "Iteration: 2048, Loss: 0.029678\n",
      "Iteration: 2049, Loss: 0.029671\n",
      "Iteration: 2050, Loss: 0.029671\n",
      "Iteration: 2051, Loss: 0.029668\n",
      "Iteration: 2052, Loss: 0.029663\n",
      "Iteration: 2053, Loss: 0.029658\n",
      "Iteration: 2054, Loss: 0.029686\n",
      "Iteration: 2055, Loss: 0.029656\n",
      "Iteration: 2056, Loss: 0.029654\n",
      "Iteration: 2057, Loss: 0.029647\n",
      "Iteration: 2058, Loss: 0.029645\n",
      "Iteration: 2059, Loss: 0.029641\n",
      "Iteration: 2060, Loss: 0.029644\n",
      "Iteration: 2061, Loss: 0.029639\n",
      "Iteration: 2062, Loss: 0.029636\n",
      "Iteration: 2063, Loss: 0.029640\n",
      "Iteration: 2064, Loss: 0.029635\n",
      "Iteration: 2065, Loss: 0.029633\n",
      "Iteration: 2066, Loss: 0.029632\n",
      "Iteration: 2067, Loss: 0.029630\n",
      "Iteration: 2068, Loss: 0.029630\n",
      "Iteration: 2069, Loss: 0.029628\n",
      "Iteration: 2070, Loss: 0.029626\n",
      "Iteration: 2071, Loss: 0.029622\n",
      "Iteration: 2072, Loss: 0.029618\n",
      "Iteration: 2073, Loss: 0.029615\n",
      "Iteration: 2074, Loss: 0.029612\n",
      "Iteration: 2075, Loss: 0.029715\n",
      "Iteration: 2076, Loss: 0.029609\n",
      "Iteration: 2077, Loss: 0.029604\n",
      "Iteration: 2078, Loss: 0.029596\n",
      "Iteration: 2079, Loss: 0.029594\n",
      "Iteration: 2080, Loss: 0.029595\n",
      "Iteration: 2081, Loss: 0.029592\n",
      "Iteration: 2082, Loss: 0.029589\n",
      "Iteration: 2083, Loss: 0.029587\n",
      "Iteration: 2084, Loss: 0.029584\n",
      "Iteration: 2085, Loss: 0.029582\n",
      "Iteration: 2086, Loss: 0.029580\n",
      "Iteration: 2087, Loss: 0.029577\n",
      "Iteration: 2088, Loss: 0.029574\n",
      "Iteration: 2089, Loss: 0.029568\n",
      "Iteration: 2090, Loss: 0.029561\n",
      "Iteration: 2091, Loss: 0.029555\n",
      "Iteration: 2092, Loss: 0.029553\n",
      "Iteration: 2093, Loss: 0.029551\n",
      "Iteration: 2094, Loss: 0.029548\n",
      "Iteration: 2095, Loss: 0.029548\n",
      "Iteration: 2096, Loss: 0.029546\n",
      "Iteration: 2097, Loss: 0.029546\n",
      "Iteration: 2098, Loss: 0.029546\n",
      "Iteration: 2099, Loss: 0.029545\n",
      "Iteration: 2100, Loss: 0.029556\n",
      "Iteration: 2101, Loss: 0.029541\n",
      "Iteration: 2102, Loss: 0.029538\n",
      "Iteration: 2103, Loss: 0.029532\n",
      "Iteration: 2104, Loss: 0.029530\n",
      "Iteration: 2105, Loss: 0.029528\n",
      "Iteration: 2106, Loss: 0.029529\n",
      "Iteration: 2107, Loss: 0.029526\n",
      "Iteration: 2108, Loss: 0.029523\n",
      "Iteration: 2109, Loss: 0.029520\n",
      "Iteration: 2110, Loss: 0.029518\n",
      "Iteration: 2111, Loss: 0.029513\n",
      "Iteration: 2112, Loss: 0.029509\n",
      "Iteration: 2113, Loss: 0.029510\n",
      "Iteration: 2114, Loss: 0.029505\n",
      "Iteration: 2115, Loss: 0.029501\n",
      "Iteration: 2116, Loss: 0.029496\n",
      "Iteration: 2117, Loss: 0.029491\n",
      "Iteration: 2118, Loss: 0.029487\n",
      "Iteration: 2119, Loss: 0.029478\n",
      "Iteration: 2120, Loss: 0.029474\n",
      "Iteration: 2121, Loss: 0.029467\n",
      "Iteration: 2122, Loss: 0.029466\n",
      "Iteration: 2123, Loss: 0.029460\n",
      "Iteration: 2124, Loss: 0.029458\n",
      "Iteration: 2125, Loss: 0.029456\n",
      "Iteration: 2126, Loss: 0.029454\n",
      "Iteration: 2127, Loss: 0.029452\n",
      "Iteration: 2128, Loss: 0.029451\n",
      "Iteration: 2129, Loss: 0.029449\n",
      "Iteration: 2130, Loss: 0.029446\n",
      "Iteration: 2131, Loss: 0.029444\n",
      "Iteration: 2132, Loss: 0.029439\n",
      "Iteration: 2133, Loss: 0.029431\n",
      "Iteration: 2134, Loss: 0.029422\n",
      "Iteration: 2135, Loss: 0.029418\n",
      "Iteration: 2136, Loss: 0.029415\n",
      "Iteration: 2137, Loss: 0.029509\n",
      "Iteration: 2138, Loss: 0.029414\n",
      "Iteration: 2139, Loss: 0.029412\n",
      "Iteration: 2140, Loss: 0.029408\n",
      "Iteration: 2141, Loss: 0.029405\n",
      "Iteration: 2142, Loss: 0.029404\n",
      "Iteration: 2143, Loss: 0.029401\n",
      "Iteration: 2144, Loss: 0.029398\n",
      "Iteration: 2145, Loss: 0.029396\n",
      "Iteration: 2146, Loss: 0.029391\n",
      "Iteration: 2147, Loss: 0.029391\n",
      "Iteration: 2148, Loss: 0.029388\n",
      "Iteration: 2149, Loss: 0.029384\n",
      "Iteration: 2150, Loss: 0.029378\n",
      "Iteration: 2151, Loss: 0.029466\n",
      "Iteration: 2152, Loss: 0.029376\n",
      "Iteration: 2153, Loss: 0.029371\n",
      "Iteration: 2154, Loss: 0.029370\n",
      "Iteration: 2155, Loss: 0.029366\n",
      "Iteration: 2156, Loss: 0.029364\n",
      "Iteration: 2157, Loss: 0.029358\n",
      "Iteration: 2158, Loss: 0.029350\n",
      "Iteration: 2159, Loss: 0.029356\n",
      "Iteration: 2160, Loss: 0.029345\n",
      "Iteration: 2161, Loss: 0.029341\n",
      "Iteration: 2162, Loss: 0.029334\n",
      "Iteration: 2163, Loss: 0.029331\n",
      "Iteration: 2164, Loss: 0.029327\n",
      "Iteration: 2165, Loss: 0.029323\n",
      "Iteration: 2166, Loss: 0.029317\n",
      "Iteration: 2167, Loss: 0.029321\n",
      "Iteration: 2168, Loss: 0.029313\n",
      "Iteration: 2169, Loss: 0.029308\n",
      "Iteration: 2170, Loss: 0.029306\n",
      "Iteration: 2171, Loss: 0.029302\n",
      "Iteration: 2172, Loss: 0.029299\n",
      "Iteration: 2173, Loss: 0.029293\n",
      "Iteration: 2174, Loss: 0.029286\n",
      "Iteration: 2175, Loss: 0.029278\n",
      "Iteration: 2176, Loss: 0.029274\n",
      "Iteration: 2177, Loss: 0.029270\n",
      "Iteration: 2178, Loss: 0.029258\n",
      "Iteration: 2179, Loss: 0.029249\n",
      "Iteration: 2180, Loss: 0.029241\n",
      "Iteration: 2181, Loss: 0.029236\n",
      "Iteration: 2182, Loss: 0.029234\n",
      "Iteration: 2183, Loss: 0.029229\n",
      "Iteration: 2184, Loss: 0.029247\n",
      "Iteration: 2185, Loss: 0.029223\n",
      "Iteration: 2186, Loss: 0.029210\n",
      "Iteration: 2187, Loss: 0.029200\n",
      "Iteration: 2188, Loss: 0.029192\n",
      "Iteration: 2189, Loss: 0.029191\n",
      "Iteration: 2190, Loss: 0.029183\n",
      "Iteration: 2191, Loss: 0.029180\n",
      "Iteration: 2192, Loss: 0.029176\n",
      "Iteration: 2193, Loss: 0.029191\n",
      "Iteration: 2194, Loss: 0.029175\n",
      "Iteration: 2195, Loss: 0.029173\n",
      "Iteration: 2196, Loss: 0.029382\n",
      "Iteration: 2197, Loss: 0.029172\n",
      "Iteration: 2198, Loss: 0.029170\n",
      "Iteration: 2199, Loss: 0.029169\n",
      "Iteration: 2200, Loss: 0.029167\n",
      "Iteration: 2201, Loss: 0.029165\n",
      "Iteration: 2202, Loss: 0.029161\n",
      "Iteration: 2203, Loss: 0.029158\n",
      "Iteration: 2204, Loss: 0.029150\n",
      "Iteration: 2205, Loss: 0.029143\n",
      "Iteration: 2206, Loss: 0.029135\n",
      "Iteration: 2207, Loss: 0.029130\n",
      "Iteration: 2208, Loss: 0.029172\n",
      "Iteration: 2209, Loss: 0.029128\n",
      "Iteration: 2210, Loss: 0.029122\n",
      "Iteration: 2211, Loss: 0.029118\n",
      "Iteration: 2212, Loss: 0.029115\n",
      "Iteration: 2213, Loss: 0.029113\n",
      "Iteration: 2214, Loss: 0.029109\n",
      "Iteration: 2215, Loss: 0.029122\n",
      "Iteration: 2216, Loss: 0.029107\n",
      "Iteration: 2217, Loss: 0.029104\n",
      "Iteration: 2218, Loss: 0.029100\n",
      "Iteration: 2219, Loss: 0.029091\n",
      "Iteration: 2220, Loss: 0.029083\n",
      "Iteration: 2221, Loss: 0.029078\n",
      "Iteration: 2222, Loss: 0.029073\n",
      "Iteration: 2223, Loss: 0.029069\n",
      "Iteration: 2224, Loss: 0.029064\n",
      "Iteration: 2225, Loss: 0.029062\n",
      "Iteration: 2226, Loss: 0.029060\n",
      "Iteration: 2227, Loss: 0.029058\n",
      "Iteration: 2228, Loss: 0.029055\n",
      "Iteration: 2229, Loss: 0.029051\n",
      "Iteration: 2230, Loss: 0.029049\n",
      "Iteration: 2231, Loss: 0.029042\n",
      "Iteration: 2232, Loss: 0.029037\n",
      "Iteration: 2233, Loss: 0.029033\n",
      "Iteration: 2234, Loss: 0.029029\n",
      "Iteration: 2235, Loss: 0.029024\n",
      "Iteration: 2236, Loss: 0.029022\n",
      "Iteration: 2237, Loss: 0.029018\n",
      "Iteration: 2238, Loss: 0.029017\n",
      "Iteration: 2239, Loss: 0.029015\n",
      "Iteration: 2240, Loss: 0.029014\n",
      "Iteration: 2241, Loss: 0.029012\n",
      "Iteration: 2242, Loss: 0.029011\n",
      "Iteration: 2243, Loss: 0.029009\n",
      "Iteration: 2244, Loss: 0.029005\n",
      "Iteration: 2245, Loss: 0.029024\n",
      "Iteration: 2246, Loss: 0.029004\n",
      "Iteration: 2247, Loss: 0.029001\n",
      "Iteration: 2248, Loss: 0.029006\n",
      "Iteration: 2249, Loss: 0.028999\n",
      "Iteration: 2250, Loss: 0.028997\n",
      "Iteration: 2251, Loss: 0.028995\n",
      "Iteration: 2252, Loss: 0.028993\n",
      "Iteration: 2253, Loss: 0.028991\n",
      "Iteration: 2254, Loss: 0.028993\n",
      "Iteration: 2255, Loss: 0.028989\n",
      "Iteration: 2256, Loss: 0.028984\n",
      "Iteration: 2257, Loss: 0.028977\n",
      "Iteration: 2258, Loss: 0.028973\n",
      "Iteration: 2259, Loss: 0.028968\n",
      "Iteration: 2260, Loss: 0.028970\n",
      "Iteration: 2261, Loss: 0.028965\n",
      "Iteration: 2262, Loss: 0.028961\n",
      "Iteration: 2263, Loss: 0.028957\n",
      "Iteration: 2264, Loss: 0.028952\n",
      "Iteration: 2265, Loss: 0.028948\n",
      "Iteration: 2266, Loss: 0.029004\n",
      "Iteration: 2267, Loss: 0.028948\n",
      "Iteration: 2268, Loss: 0.028945\n",
      "Iteration: 2269, Loss: 0.028941\n",
      "Iteration: 2270, Loss: 0.028938\n",
      "Iteration: 2271, Loss: 0.028936\n",
      "Iteration: 2272, Loss: 0.028933\n",
      "Iteration: 2273, Loss: 0.028930\n",
      "Iteration: 2274, Loss: 0.028928\n",
      "Iteration: 2275, Loss: 0.028926\n",
      "Iteration: 2276, Loss: 0.028924\n",
      "Iteration: 2277, Loss: 0.028919\n",
      "Iteration: 2278, Loss: 0.028919\n",
      "Iteration: 2279, Loss: 0.028915\n",
      "Iteration: 2280, Loss: 0.028907\n",
      "Iteration: 2281, Loss: 0.028901\n",
      "Iteration: 2282, Loss: 0.028891\n",
      "Iteration: 2283, Loss: 0.028889\n",
      "Iteration: 2284, Loss: 0.028887\n",
      "Iteration: 2285, Loss: 0.028883\n",
      "Iteration: 2286, Loss: 0.028881\n",
      "Iteration: 2287, Loss: 0.028877\n",
      "Iteration: 2288, Loss: 0.028871\n",
      "Iteration: 2289, Loss: 0.028865\n",
      "Iteration: 2290, Loss: 0.028861\n",
      "Iteration: 2291, Loss: 0.028858\n",
      "Iteration: 2292, Loss: 0.028855\n",
      "Iteration: 2293, Loss: 0.028854\n",
      "Iteration: 2294, Loss: 0.028849\n",
      "Iteration: 2295, Loss: 0.028846\n",
      "Iteration: 2296, Loss: 0.028843\n",
      "Iteration: 2297, Loss: 0.028839\n",
      "Iteration: 2298, Loss: 0.028836\n",
      "Iteration: 2299, Loss: 0.028835\n",
      "Iteration: 2300, Loss: 0.028831\n",
      "Iteration: 2301, Loss: 0.028828\n",
      "Iteration: 2302, Loss: 0.028826\n",
      "Iteration: 2303, Loss: 0.028824\n",
      "Iteration: 2304, Loss: 0.028823\n",
      "Iteration: 2305, Loss: 0.028821\n",
      "Iteration: 2306, Loss: 0.028820\n",
      "Iteration: 2307, Loss: 0.028818\n",
      "Iteration: 2308, Loss: 0.028816\n",
      "Iteration: 2309, Loss: 0.028813\n",
      "Iteration: 2310, Loss: 0.028808\n",
      "Iteration: 2311, Loss: 0.028803\n",
      "Iteration: 2312, Loss: 0.028799\n",
      "Iteration: 2313, Loss: 0.028796\n",
      "Iteration: 2314, Loss: 0.028792\n",
      "Iteration: 2315, Loss: 0.028786\n",
      "Iteration: 2316, Loss: 0.028783\n",
      "Iteration: 2317, Loss: 0.028782\n",
      "Iteration: 2318, Loss: 0.028780\n",
      "Iteration: 2319, Loss: 0.028778\n",
      "Iteration: 2320, Loss: 0.028775\n",
      "Iteration: 2321, Loss: 0.028773\n",
      "Iteration: 2322, Loss: 0.028771\n",
      "Iteration: 2323, Loss: 0.028790\n",
      "Iteration: 2324, Loss: 0.028769\n",
      "Iteration: 2325, Loss: 0.028767\n",
      "Iteration: 2326, Loss: 0.028766\n",
      "Iteration: 2327, Loss: 0.028765\n",
      "Iteration: 2328, Loss: 0.028762\n",
      "Iteration: 2329, Loss: 0.028760\n",
      "Iteration: 2330, Loss: 0.028758\n",
      "Iteration: 2331, Loss: 0.028754\n",
      "Iteration: 2332, Loss: 0.028750\n",
      "Iteration: 2333, Loss: 0.028745\n",
      "Iteration: 2334, Loss: 0.028742\n",
      "Iteration: 2335, Loss: 0.028736\n",
      "Iteration: 2336, Loss: 0.028733\n",
      "Iteration: 2337, Loss: 0.028737\n",
      "Iteration: 2338, Loss: 0.028733\n",
      "Iteration: 2339, Loss: 0.028731\n",
      "Iteration: 2340, Loss: 0.028729\n",
      "Iteration: 2341, Loss: 0.028723\n",
      "Iteration: 2342, Loss: 0.028715\n",
      "Iteration: 2343, Loss: 0.028701\n",
      "Iteration: 2344, Loss: 0.028775\n",
      "Iteration: 2345, Loss: 0.028696\n",
      "Iteration: 2346, Loss: 0.028691\n",
      "Iteration: 2347, Loss: 0.028688\n",
      "Iteration: 2348, Loss: 0.028687\n",
      "Iteration: 2349, Loss: 0.028685\n",
      "Iteration: 2350, Loss: 0.028696\n",
      "Iteration: 2351, Loss: 0.028685\n",
      "Iteration: 2352, Loss: 0.028683\n",
      "Iteration: 2353, Loss: 0.028681\n",
      "Iteration: 2354, Loss: 0.028680\n",
      "Iteration: 2355, Loss: 0.028679\n",
      "Iteration: 2356, Loss: 0.028678\n",
      "Iteration: 2357, Loss: 0.028677\n",
      "Iteration: 2358, Loss: 0.028676\n",
      "Iteration: 2359, Loss: 0.028898\n",
      "Iteration: 2360, Loss: 0.028676\n",
      "Iteration: 2361, Loss: 0.028675\n",
      "Iteration: 2362, Loss: 0.028673\n",
      "Iteration: 2363, Loss: 0.028670\n",
      "Iteration: 2364, Loss: 0.028678\n",
      "Iteration: 2365, Loss: 0.028669\n",
      "Iteration: 2366, Loss: 0.028667\n",
      "Iteration: 2367, Loss: 0.028662\n",
      "Iteration: 2368, Loss: 0.028659\n",
      "Iteration: 2369, Loss: 0.028656\n",
      "Iteration: 2370, Loss: 0.028653\n",
      "Iteration: 2371, Loss: 0.028647\n",
      "Iteration: 2372, Loss: 0.028643\n",
      "Iteration: 2373, Loss: 0.028640\n",
      "Iteration: 2374, Loss: 0.028638\n",
      "Iteration: 2375, Loss: 0.028635\n",
      "Iteration: 2376, Loss: 0.028633\n",
      "Iteration: 2377, Loss: 0.028631\n",
      "Iteration: 2378, Loss: 0.028630\n",
      "Iteration: 2379, Loss: 0.028628\n",
      "Iteration: 2380, Loss: 0.028625\n",
      "Iteration: 2381, Loss: 0.028620\n",
      "Iteration: 2382, Loss: 0.029112\n",
      "Iteration: 2383, Loss: 0.028614\n",
      "Iteration: 2384, Loss: 0.028606\n",
      "Iteration: 2385, Loss: 0.028598\n",
      "Iteration: 2386, Loss: 0.028596\n",
      "Iteration: 2387, Loss: 0.028594\n",
      "Iteration: 2388, Loss: 0.028593\n",
      "Iteration: 2389, Loss: 0.028590\n",
      "Iteration: 2390, Loss: 0.028586\n",
      "Iteration: 2391, Loss: 0.028582\n",
      "Iteration: 2392, Loss: 0.028579\n",
      "Iteration: 2393, Loss: 0.028574\n",
      "Iteration: 2394, Loss: 0.028577\n",
      "Iteration: 2395, Loss: 0.028572\n",
      "Iteration: 2396, Loss: 0.028570\n",
      "Iteration: 2397, Loss: 0.028568\n",
      "Iteration: 2398, Loss: 0.028567\n",
      "Iteration: 2399, Loss: 0.028565\n",
      "Iteration: 2400, Loss: 0.028563\n",
      "Iteration: 2401, Loss: 0.028561\n",
      "Iteration: 2402, Loss: 0.028560\n",
      "Iteration: 2403, Loss: 0.028557\n",
      "Iteration: 2404, Loss: 0.028555\n",
      "Iteration: 2405, Loss: 0.028554\n",
      "Iteration: 2406, Loss: 0.028553\n",
      "Iteration: 2407, Loss: 0.028553\n",
      "Iteration: 2408, Loss: 0.028552\n",
      "Iteration: 2409, Loss: 0.028549\n",
      "Iteration: 2410, Loss: 0.028547\n",
      "Iteration: 2411, Loss: 0.028545\n",
      "Iteration: 2412, Loss: 0.028554\n",
      "Iteration: 2413, Loss: 0.028544\n",
      "Iteration: 2414, Loss: 0.028544\n",
      "Iteration: 2415, Loss: 0.028543\n",
      "Iteration: 2416, Loss: 0.028542\n",
      "Iteration: 2417, Loss: 0.028575\n",
      "Iteration: 2418, Loss: 0.028541\n",
      "Iteration: 2419, Loss: 0.028539\n",
      "Iteration: 2420, Loss: 0.028536\n",
      "Iteration: 2421, Loss: 0.028532\n",
      "Iteration: 2422, Loss: 0.028709\n",
      "Iteration: 2423, Loss: 0.028531\n",
      "Iteration: 2424, Loss: 0.028529\n",
      "Iteration: 2425, Loss: 0.028525\n",
      "Iteration: 2426, Loss: 0.028523\n",
      "Iteration: 2427, Loss: 0.028528\n",
      "Iteration: 2428, Loss: 0.028519\n",
      "Iteration: 2429, Loss: 0.028512\n",
      "Iteration: 2430, Loss: 0.028499\n",
      "Iteration: 2431, Loss: 0.028496\n",
      "Iteration: 2432, Loss: 0.028488\n",
      "Iteration: 2433, Loss: 0.028487\n",
      "Iteration: 2434, Loss: 0.028489\n",
      "Iteration: 2435, Loss: 0.028485\n",
      "Iteration: 2436, Loss: 0.028483\n",
      "Iteration: 2437, Loss: 0.028479\n",
      "Iteration: 2438, Loss: 0.028474\n",
      "Iteration: 2439, Loss: 0.028468\n",
      "Iteration: 2440, Loss: 0.028463\n",
      "Iteration: 2441, Loss: 0.028459\n",
      "Iteration: 2442, Loss: 0.028453\n",
      "Iteration: 2443, Loss: 0.028447\n",
      "Iteration: 2444, Loss: 0.028444\n",
      "Iteration: 2445, Loss: 0.028438\n",
      "Iteration: 2446, Loss: 0.028432\n",
      "Iteration: 2447, Loss: 0.028428\n",
      "Iteration: 2448, Loss: 0.028426\n",
      "Iteration: 2449, Loss: 0.028424\n",
      "Iteration: 2450, Loss: 0.028421\n",
      "Iteration: 2451, Loss: 0.028418\n",
      "Iteration: 2452, Loss: 0.028414\n",
      "Iteration: 2453, Loss: 0.028428\n",
      "Iteration: 2454, Loss: 0.028412\n",
      "Iteration: 2455, Loss: 0.028407\n",
      "Iteration: 2456, Loss: 0.028403\n",
      "Iteration: 2457, Loss: 0.028400\n",
      "Iteration: 2458, Loss: 0.028396\n",
      "Iteration: 2459, Loss: 0.028391\n",
      "Iteration: 2460, Loss: 0.028386\n",
      "Iteration: 2461, Loss: 0.028382\n",
      "Iteration: 2462, Loss: 0.028379\n",
      "Iteration: 2463, Loss: 0.028377\n",
      "Iteration: 2464, Loss: 0.028374\n",
      "Iteration: 2465, Loss: 0.028369\n",
      "Iteration: 2466, Loss: 0.028409\n",
      "Iteration: 2467, Loss: 0.028368\n",
      "Iteration: 2468, Loss: 0.028364\n",
      "Iteration: 2469, Loss: 0.028357\n",
      "Iteration: 2470, Loss: 0.028353\n",
      "Iteration: 2471, Loss: 0.028390\n",
      "Iteration: 2472, Loss: 0.028352\n",
      "Iteration: 2473, Loss: 0.028348\n",
      "Iteration: 2474, Loss: 0.028343\n",
      "Iteration: 2475, Loss: 0.028339\n",
      "Iteration: 2476, Loss: 0.028336\n",
      "Iteration: 2477, Loss: 0.028354\n",
      "Iteration: 2478, Loss: 0.028335\n",
      "Iteration: 2479, Loss: 0.028333\n",
      "Iteration: 2480, Loss: 0.028331\n",
      "Iteration: 2481, Loss: 0.028329\n",
      "Iteration: 2482, Loss: 0.028328\n",
      "Iteration: 2483, Loss: 0.028326\n",
      "Iteration: 2484, Loss: 0.028325\n",
      "Iteration: 2485, Loss: 0.028324\n",
      "Iteration: 2486, Loss: 0.028322\n",
      "Iteration: 2487, Loss: 0.028319\n",
      "Iteration: 2488, Loss: 0.028368\n",
      "Iteration: 2489, Loss: 0.028318\n",
      "Iteration: 2490, Loss: 0.028315\n",
      "Iteration: 2491, Loss: 0.028312\n",
      "Iteration: 2492, Loss: 0.028310\n",
      "Iteration: 2493, Loss: 0.028305\n",
      "Iteration: 2494, Loss: 0.028300\n",
      "Iteration: 2495, Loss: 0.028299\n",
      "Iteration: 2496, Loss: 0.028297\n",
      "Iteration: 2497, Loss: 0.028296\n",
      "Iteration: 2498, Loss: 0.028295\n",
      "Iteration: 2499, Loss: 0.028292\n",
      "Iteration: 2500, Loss: 0.028290\n",
      "Iteration: 2501, Loss: 0.028288\n",
      "Iteration: 2502, Loss: 0.028285\n",
      "Iteration: 2503, Loss: 0.028281\n",
      "Iteration: 2504, Loss: 0.028277\n",
      "Iteration: 2505, Loss: 0.028287\n",
      "Iteration: 2506, Loss: 0.028276\n",
      "Iteration: 2507, Loss: 0.028272\n",
      "Iteration: 2508, Loss: 0.028269\n",
      "Iteration: 2509, Loss: 0.028265\n",
      "Iteration: 2510, Loss: 0.028261\n",
      "Iteration: 2511, Loss: 0.028256\n",
      "Iteration: 2512, Loss: 0.028251\n",
      "Iteration: 2513, Loss: 0.028247\n",
      "Iteration: 2514, Loss: 0.028244\n",
      "Iteration: 2515, Loss: 0.028242\n",
      "Iteration: 2516, Loss: 0.028238\n",
      "Iteration: 2517, Loss: 0.028235\n",
      "Iteration: 2518, Loss: 0.028260\n",
      "Iteration: 2519, Loss: 0.028234\n",
      "Iteration: 2520, Loss: 0.028231\n",
      "Iteration: 2521, Loss: 0.028227\n",
      "Iteration: 2522, Loss: 0.028222\n",
      "Iteration: 2523, Loss: 0.028219\n",
      "Iteration: 2524, Loss: 0.028216\n",
      "Iteration: 2525, Loss: 0.028215\n",
      "Iteration: 2526, Loss: 0.028213\n",
      "Iteration: 2527, Loss: 0.028211\n",
      "Iteration: 2528, Loss: 0.028211\n",
      "Iteration: 2529, Loss: 0.028211\n",
      "Iteration: 2530, Loss: 0.028210\n",
      "Iteration: 2531, Loss: 0.028209\n",
      "Iteration: 2532, Loss: 0.028208\n",
      "Iteration: 2533, Loss: 0.028205\n",
      "Iteration: 2534, Loss: 0.028202\n",
      "Iteration: 2535, Loss: 0.028200\n",
      "Iteration: 2536, Loss: 0.028200\n",
      "Iteration: 2537, Loss: 0.028198\n",
      "Iteration: 2538, Loss: 0.028198\n",
      "Iteration: 2539, Loss: 0.028195\n",
      "Iteration: 2540, Loss: 0.028194\n",
      "Iteration: 2541, Loss: 0.028192\n",
      "Iteration: 2542, Loss: 0.028191\n",
      "Iteration: 2543, Loss: 0.028189\n",
      "Iteration: 2544, Loss: 0.028187\n",
      "Iteration: 2545, Loss: 0.028185\n",
      "Iteration: 2546, Loss: 0.028183\n",
      "Iteration: 2547, Loss: 0.028184\n",
      "Iteration: 2548, Loss: 0.028181\n",
      "Iteration: 2549, Loss: 0.028180\n",
      "Iteration: 2550, Loss: 0.028176\n",
      "Iteration: 2551, Loss: 0.028169\n",
      "Iteration: 2552, Loss: 0.028164\n",
      "Iteration: 2553, Loss: 0.028161\n",
      "Iteration: 2554, Loss: 0.028157\n",
      "Iteration: 2555, Loss: 0.028155\n",
      "Iteration: 2556, Loss: 0.028154\n",
      "Iteration: 2557, Loss: 0.028152\n",
      "Iteration: 2558, Loss: 0.028150\n",
      "Iteration: 2559, Loss: 0.028148\n",
      "Iteration: 2560, Loss: 0.028145\n",
      "Iteration: 2561, Loss: 0.028142\n",
      "Iteration: 2562, Loss: 0.028140\n",
      "Iteration: 2563, Loss: 0.028137\n",
      "Iteration: 2564, Loss: 0.028134\n",
      "Iteration: 2565, Loss: 0.028127\n",
      "Iteration: 2566, Loss: 0.028121\n",
      "Iteration: 2567, Loss: 0.028117\n",
      "Iteration: 2568, Loss: 0.028114\n",
      "Iteration: 2569, Loss: 0.028113\n",
      "Iteration: 2570, Loss: 0.028110\n",
      "Iteration: 2571, Loss: 0.028107\n",
      "Iteration: 2572, Loss: 0.028104\n",
      "Iteration: 2573, Loss: 0.028101\n",
      "Iteration: 2574, Loss: 0.028098\n",
      "Iteration: 2575, Loss: 0.028095\n",
      "Iteration: 2576, Loss: 0.028093\n",
      "Iteration: 2577, Loss: 0.028090\n",
      "Iteration: 2578, Loss: 0.028082\n",
      "Iteration: 2579, Loss: 0.028077\n",
      "Iteration: 2580, Loss: 0.028072\n",
      "Iteration: 2581, Loss: 0.028069\n",
      "Iteration: 2582, Loss: 0.028068\n",
      "Iteration: 2583, Loss: 0.028067\n",
      "Iteration: 2584, Loss: 0.028066\n",
      "Iteration: 2585, Loss: 0.028064\n",
      "Iteration: 2586, Loss: 0.028062\n",
      "Iteration: 2587, Loss: 0.028060\n",
      "Iteration: 2588, Loss: 0.028057\n",
      "Iteration: 2589, Loss: 0.028052\n",
      "Iteration: 2590, Loss: 0.028049\n",
      "Iteration: 2591, Loss: 0.028045\n",
      "Iteration: 2592, Loss: 0.028048\n",
      "Iteration: 2593, Loss: 0.028043\n",
      "Iteration: 2594, Loss: 0.028042\n",
      "Iteration: 2595, Loss: 0.028040\n",
      "Iteration: 2596, Loss: 0.028039\n",
      "Iteration: 2597, Loss: 0.028037\n",
      "Iteration: 2598, Loss: 0.028035\n",
      "Iteration: 2599, Loss: 0.028033\n",
      "Iteration: 2600, Loss: 0.028032\n",
      "Iteration: 2601, Loss: 0.028030\n",
      "Iteration: 2602, Loss: 0.028029\n",
      "Iteration: 2603, Loss: 0.028027\n",
      "Iteration: 2604, Loss: 0.028023\n",
      "Iteration: 2605, Loss: 0.028020\n",
      "Iteration: 2606, Loss: 0.028016\n",
      "Iteration: 2607, Loss: 0.028012\n",
      "Iteration: 2608, Loss: 0.028010\n",
      "Iteration: 2609, Loss: 0.028009\n",
      "Iteration: 2610, Loss: 0.028007\n",
      "Iteration: 2611, Loss: 0.028004\n",
      "Iteration: 2612, Loss: 0.027998\n",
      "Iteration: 2613, Loss: 0.027993\n",
      "Iteration: 2614, Loss: 0.027986\n",
      "Iteration: 2615, Loss: 0.027977\n",
      "Iteration: 2616, Loss: 0.027965\n",
      "Iteration: 2617, Loss: 0.027947\n",
      "Iteration: 2618, Loss: 0.027936\n",
      "Iteration: 2619, Loss: 0.027925\n",
      "Iteration: 2620, Loss: 0.027918\n",
      "Iteration: 2621, Loss: 0.027908\n",
      "Iteration: 2622, Loss: 0.027901\n",
      "Iteration: 2623, Loss: 0.027893\n",
      "Iteration: 2624, Loss: 0.027888\n",
      "Iteration: 2625, Loss: 0.027884\n",
      "Iteration: 2626, Loss: 0.027882\n",
      "Iteration: 2627, Loss: 0.027877\n",
      "Iteration: 2628, Loss: 0.027883\n",
      "Iteration: 2629, Loss: 0.027873\n",
      "Iteration: 2630, Loss: 0.027866\n",
      "Iteration: 2631, Loss: 0.027855\n",
      "Iteration: 2632, Loss: 0.027844\n",
      "Iteration: 2633, Loss: 0.027826\n",
      "Iteration: 2634, Loss: 0.027831\n",
      "Iteration: 2635, Loss: 0.027822\n",
      "Iteration: 2636, Loss: 0.027814\n",
      "Iteration: 2637, Loss: 0.027830\n",
      "Iteration: 2638, Loss: 0.027812\n",
      "Iteration: 2639, Loss: 0.027808\n",
      "Iteration: 2640, Loss: 0.027805\n",
      "Iteration: 2641, Loss: 0.027802\n",
      "Iteration: 2642, Loss: 0.027800\n",
      "Iteration: 2643, Loss: 0.027798\n",
      "Iteration: 2644, Loss: 0.027797\n",
      "Iteration: 2645, Loss: 0.027795\n",
      "Iteration: 2646, Loss: 0.027793\n",
      "Iteration: 2647, Loss: 0.027792\n",
      "Iteration: 2648, Loss: 0.027789\n",
      "Iteration: 2649, Loss: 0.027803\n",
      "Iteration: 2650, Loss: 0.027786\n",
      "Iteration: 2651, Loss: 0.027786\n",
      "Iteration: 2652, Loss: 0.027781\n",
      "Iteration: 2653, Loss: 0.027775\n",
      "Iteration: 2654, Loss: 0.027769\n",
      "Iteration: 2655, Loss: 0.027764\n",
      "Iteration: 2656, Loss: 0.027757\n",
      "Iteration: 2657, Loss: 0.027931\n",
      "Iteration: 2658, Loss: 0.027756\n",
      "Iteration: 2659, Loss: 0.027750\n",
      "Iteration: 2660, Loss: 0.027742\n",
      "Iteration: 2661, Loss: 0.027737\n",
      "Iteration: 2662, Loss: 0.027731\n",
      "Iteration: 2663, Loss: 0.027726\n",
      "Iteration: 2664, Loss: 0.027735\n",
      "Iteration: 2665, Loss: 0.027724\n",
      "Iteration: 2666, Loss: 0.027722\n",
      "Iteration: 2667, Loss: 0.027721\n",
      "Iteration: 2668, Loss: 0.027720\n",
      "Iteration: 2669, Loss: 0.027717\n",
      "Iteration: 2670, Loss: 0.027713\n",
      "Iteration: 2671, Loss: 0.027710\n",
      "Iteration: 2672, Loss: 0.027707\n",
      "Iteration: 2673, Loss: 0.027704\n",
      "Iteration: 2674, Loss: 0.027702\n",
      "Iteration: 2675, Loss: 0.027699\n",
      "Iteration: 2676, Loss: 0.027694\n",
      "Iteration: 2677, Loss: 0.027688\n",
      "Iteration: 2678, Loss: 0.027681\n",
      "Iteration: 2679, Loss: 0.027676\n",
      "Iteration: 2680, Loss: 0.027672\n",
      "Iteration: 2681, Loss: 0.027664\n",
      "Iteration: 2682, Loss: 0.027658\n",
      "Iteration: 2683, Loss: 0.027648\n",
      "Iteration: 2684, Loss: 0.027711\n",
      "Iteration: 2685, Loss: 0.027644\n",
      "Iteration: 2686, Loss: 0.027640\n",
      "Iteration: 2687, Loss: 0.027636\n",
      "Iteration: 2688, Loss: 0.027631\n",
      "Iteration: 2689, Loss: 0.027625\n",
      "Iteration: 2690, Loss: 0.027619\n",
      "Iteration: 2691, Loss: 0.027614\n",
      "Iteration: 2692, Loss: 0.027609\n",
      "Iteration: 2693, Loss: 0.027604\n",
      "Iteration: 2694, Loss: 0.027602\n",
      "Iteration: 2695, Loss: 0.027601\n",
      "Iteration: 2696, Loss: 0.027598\n",
      "Iteration: 2697, Loss: 0.027594\n",
      "Iteration: 2698, Loss: 0.027589\n",
      "Iteration: 2699, Loss: 0.027585\n",
      "Iteration: 2700, Loss: 0.027581\n",
      "Iteration: 2701, Loss: 0.027578\n",
      "Iteration: 2702, Loss: 0.027569\n",
      "Iteration: 2703, Loss: 0.027561\n",
      "Iteration: 2704, Loss: 0.027553\n",
      "Iteration: 2705, Loss: 0.027546\n",
      "Iteration: 2706, Loss: 0.027540\n",
      "Iteration: 2707, Loss: 0.027533\n",
      "Iteration: 2708, Loss: 0.027525\n",
      "Iteration: 2709, Loss: 0.027522\n",
      "Iteration: 2710, Loss: 0.027516\n",
      "Iteration: 2711, Loss: 0.027513\n",
      "Iteration: 2712, Loss: 0.027511\n",
      "Iteration: 2713, Loss: 0.027508\n",
      "Iteration: 2714, Loss: 0.027504\n",
      "Iteration: 2715, Loss: 0.027500\n",
      "Iteration: 2716, Loss: 0.027496\n",
      "Iteration: 2717, Loss: 0.027493\n",
      "Iteration: 2718, Loss: 0.027490\n",
      "Iteration: 2719, Loss: 0.027486\n",
      "Iteration: 2720, Loss: 0.027485\n",
      "Iteration: 2721, Loss: 0.027481\n",
      "Iteration: 2722, Loss: 0.027478\n",
      "Iteration: 2723, Loss: 0.027476\n",
      "Iteration: 2724, Loss: 0.027469\n",
      "Iteration: 2725, Loss: 0.027463\n",
      "Iteration: 2726, Loss: 0.027459\n",
      "Iteration: 2727, Loss: 0.027455\n",
      "Iteration: 2728, Loss: 0.027450\n",
      "Iteration: 2729, Loss: 0.027445\n",
      "Iteration: 2730, Loss: 0.027455\n",
      "Iteration: 2731, Loss: 0.027443\n",
      "Iteration: 2732, Loss: 0.027442\n",
      "Iteration: 2733, Loss: 0.027439\n",
      "Iteration: 2734, Loss: 0.027444\n",
      "Iteration: 2735, Loss: 0.027439\n",
      "Iteration: 2736, Loss: 0.027437\n",
      "Iteration: 2737, Loss: 0.027433\n",
      "Iteration: 2738, Loss: 0.027428\n",
      "Iteration: 2739, Loss: 0.027426\n",
      "Iteration: 2740, Loss: 0.027418\n",
      "Iteration: 2741, Loss: 0.027415\n",
      "Iteration: 2742, Loss: 0.027412\n",
      "Iteration: 2743, Loss: 0.027409\n",
      "Iteration: 2744, Loss: 0.027405\n",
      "Iteration: 2745, Loss: 0.027401\n",
      "Iteration: 2746, Loss: 0.027396\n",
      "Iteration: 2747, Loss: 0.027394\n",
      "Iteration: 2748, Loss: 0.027391\n",
      "Iteration: 2749, Loss: 0.027390\n",
      "Iteration: 2750, Loss: 0.027389\n",
      "Iteration: 2751, Loss: 0.027387\n",
      "Iteration: 2752, Loss: 0.027385\n",
      "Iteration: 2753, Loss: 0.027383\n",
      "Iteration: 2754, Loss: 0.027380\n",
      "Iteration: 2755, Loss: 0.027374\n",
      "Iteration: 2756, Loss: 0.027368\n",
      "Iteration: 2757, Loss: 0.027360\n",
      "Iteration: 2758, Loss: 0.027356\n",
      "Iteration: 2759, Loss: 0.027352\n",
      "Iteration: 2760, Loss: 0.027347\n",
      "Iteration: 2761, Loss: 0.027355\n",
      "Iteration: 2762, Loss: 0.027345\n",
      "Iteration: 2763, Loss: 0.027340\n",
      "Iteration: 2764, Loss: 0.027336\n",
      "Iteration: 2765, Loss: 0.027333\n",
      "Iteration: 2766, Loss: 0.027328\n",
      "Iteration: 2767, Loss: 0.027320\n",
      "Iteration: 2768, Loss: 0.027501\n",
      "Iteration: 2769, Loss: 0.027316\n",
      "Iteration: 2770, Loss: 0.027309\n",
      "Iteration: 2771, Loss: 0.027304\n",
      "Iteration: 2772, Loss: 0.027302\n",
      "Iteration: 2773, Loss: 0.027300\n",
      "Iteration: 2774, Loss: 0.027298\n",
      "Iteration: 2775, Loss: 0.027296\n",
      "Iteration: 2776, Loss: 0.027295\n",
      "Iteration: 2777, Loss: 0.027299\n",
      "Iteration: 2778, Loss: 0.027294\n",
      "Iteration: 2779, Loss: 0.027292\n",
      "Iteration: 2780, Loss: 0.027286\n",
      "Iteration: 2781, Loss: 0.027282\n",
      "Iteration: 2782, Loss: 0.027278\n",
      "Iteration: 2783, Loss: 0.027275\n",
      "Iteration: 2784, Loss: 0.027272\n",
      "Iteration: 2785, Loss: 0.027271\n",
      "Iteration: 2786, Loss: 0.027269\n",
      "Iteration: 2787, Loss: 0.027270\n",
      "Iteration: 2788, Loss: 0.027268\n",
      "Iteration: 2789, Loss: 0.027266\n",
      "Iteration: 2790, Loss: 0.027265\n",
      "Iteration: 2791, Loss: 0.027263\n",
      "Iteration: 2792, Loss: 0.027258\n",
      "Iteration: 2793, Loss: 0.027251\n",
      "Iteration: 2794, Loss: 0.027289\n",
      "Iteration: 2795, Loss: 0.027248\n",
      "Iteration: 2796, Loss: 0.027241\n",
      "Iteration: 2797, Loss: 0.027234\n",
      "Iteration: 2798, Loss: 0.027229\n",
      "Iteration: 2799, Loss: 0.027223\n",
      "Iteration: 2800, Loss: 0.027213\n",
      "Iteration: 2801, Loss: 0.027204\n",
      "Iteration: 2802, Loss: 0.027211\n",
      "Iteration: 2803, Loss: 0.027202\n",
      "Iteration: 2804, Loss: 0.027197\n",
      "Iteration: 2805, Loss: 0.027194\n",
      "Iteration: 2806, Loss: 0.027191\n",
      "Iteration: 2807, Loss: 0.027189\n",
      "Iteration: 2808, Loss: 0.027184\n",
      "Iteration: 2809, Loss: 0.027179\n",
      "Iteration: 2810, Loss: 0.027175\n",
      "Iteration: 2811, Loss: 0.027176\n",
      "Iteration: 2812, Loss: 0.027173\n",
      "Iteration: 2813, Loss: 0.027169\n",
      "Iteration: 2814, Loss: 0.027168\n",
      "Iteration: 2815, Loss: 0.027166\n",
      "Iteration: 2816, Loss: 0.027165\n",
      "Iteration: 2817, Loss: 0.027162\n",
      "Iteration: 2818, Loss: 0.027158\n",
      "Iteration: 2819, Loss: 0.027183\n",
      "Iteration: 2820, Loss: 0.027157\n",
      "Iteration: 2821, Loss: 0.027153\n",
      "Iteration: 2822, Loss: 0.027150\n",
      "Iteration: 2823, Loss: 0.027146\n",
      "Iteration: 2824, Loss: 0.027143\n",
      "Iteration: 2825, Loss: 0.027137\n",
      "Iteration: 2826, Loss: 0.027133\n",
      "Iteration: 2827, Loss: 0.027130\n",
      "Iteration: 2828, Loss: 0.027128\n",
      "Iteration: 2829, Loss: 0.027124\n",
      "Iteration: 2830, Loss: 0.027118\n",
      "Iteration: 2831, Loss: 0.027114\n",
      "Iteration: 2832, Loss: 0.027112\n",
      "Iteration: 2833, Loss: 0.027109\n",
      "Iteration: 2834, Loss: 0.027113\n",
      "Iteration: 2835, Loss: 0.027108\n",
      "Iteration: 2836, Loss: 0.027103\n",
      "Iteration: 2837, Loss: 0.027100\n",
      "Iteration: 2838, Loss: 0.027097\n",
      "Iteration: 2839, Loss: 0.027094\n",
      "Iteration: 2840, Loss: 0.027091\n",
      "Iteration: 2841, Loss: 0.027089\n",
      "Iteration: 2842, Loss: 0.027086\n",
      "Iteration: 2843, Loss: 0.027084\n",
      "Iteration: 2844, Loss: 0.027094\n",
      "Iteration: 2845, Loss: 0.027084\n",
      "Iteration: 2846, Loss: 0.027082\n",
      "Iteration: 2847, Loss: 0.027080\n",
      "Iteration: 2848, Loss: 0.027078\n",
      "Iteration: 2849, Loss: 0.027076\n",
      "Iteration: 2850, Loss: 0.027072\n",
      "Iteration: 2851, Loss: 0.027068\n",
      "Iteration: 2852, Loss: 0.027064\n",
      "Iteration: 2853, Loss: 0.027062\n",
      "Iteration: 2854, Loss: 0.027063\n",
      "Iteration: 2855, Loss: 0.027061\n",
      "Iteration: 2856, Loss: 0.027059\n",
      "Iteration: 2857, Loss: 0.027055\n",
      "Iteration: 2858, Loss: 0.027052\n",
      "Iteration: 2859, Loss: 0.027051\n",
      "Iteration: 2860, Loss: 0.027050\n",
      "Iteration: 2861, Loss: 0.027063\n",
      "Iteration: 2862, Loss: 0.027049\n",
      "Iteration: 2863, Loss: 0.027047\n",
      "Iteration: 2864, Loss: 0.027040\n",
      "Iteration: 2865, Loss: 0.027035\n",
      "Iteration: 2866, Loss: 0.027032\n",
      "Iteration: 2867, Loss: 0.027028\n",
      "Iteration: 2868, Loss: 0.027110\n",
      "Iteration: 2869, Loss: 0.027026\n",
      "Iteration: 2870, Loss: 0.027065\n",
      "Iteration: 2871, Loss: 0.027024\n",
      "Iteration: 2872, Loss: 0.027019\n",
      "Iteration: 2873, Loss: 0.027016\n",
      "Iteration: 2874, Loss: 0.027013\n",
      "Iteration: 2875, Loss: 0.027046\n",
      "Iteration: 2876, Loss: 0.027013\n",
      "Iteration: 2877, Loss: 0.027011\n",
      "Iteration: 2878, Loss: 0.027009\n",
      "Iteration: 2879, Loss: 0.027008\n",
      "Iteration: 2880, Loss: 0.027008\n",
      "Iteration: 2881, Loss: 0.027007\n",
      "Iteration: 2882, Loss: 0.027005\n",
      "Iteration: 2883, Loss: 0.027001\n",
      "Iteration: 2884, Loss: 0.026999\n",
      "Iteration: 2885, Loss: 0.026995\n",
      "Iteration: 2886, Loss: 0.026993\n",
      "Iteration: 2887, Loss: 0.027043\n",
      "Iteration: 2888, Loss: 0.026992\n",
      "Iteration: 2889, Loss: 0.026990\n",
      "Iteration: 2890, Loss: 0.026988\n",
      "Iteration: 2891, Loss: 0.027010\n",
      "Iteration: 2892, Loss: 0.026987\n",
      "Iteration: 2893, Loss: 0.026985\n",
      "Iteration: 2894, Loss: 0.026981\n",
      "Iteration: 2895, Loss: 0.026978\n",
      "Iteration: 2896, Loss: 0.026974\n",
      "Iteration: 2897, Loss: 0.026971\n",
      "Iteration: 2898, Loss: 0.026968\n",
      "Iteration: 2899, Loss: 0.026966\n",
      "Iteration: 2900, Loss: 0.026961\n",
      "Iteration: 2901, Loss: 0.026956\n",
      "Iteration: 2902, Loss: 0.026950\n",
      "Iteration: 2903, Loss: 0.026946\n",
      "Iteration: 2904, Loss: 0.026944\n",
      "Iteration: 2905, Loss: 0.026941\n",
      "Iteration: 2906, Loss: 0.026938\n",
      "Iteration: 2907, Loss: 0.026934\n",
      "Iteration: 2908, Loss: 0.026928\n",
      "Iteration: 2909, Loss: 0.026921\n",
      "Iteration: 2910, Loss: 0.026954\n",
      "Iteration: 2911, Loss: 0.026917\n",
      "Iteration: 2912, Loss: 0.026908\n",
      "Iteration: 2913, Loss: 0.026903\n",
      "Iteration: 2914, Loss: 0.026900\n",
      "Iteration: 2915, Loss: 0.026896\n",
      "Iteration: 2916, Loss: 0.026889\n",
      "Iteration: 2917, Loss: 0.026888\n",
      "Iteration: 2918, Loss: 0.026884\n",
      "Iteration: 2919, Loss: 0.026879\n",
      "Iteration: 2920, Loss: 0.026876\n",
      "Iteration: 2921, Loss: 0.026873\n",
      "Iteration: 2922, Loss: 0.026882\n",
      "Iteration: 2923, Loss: 0.026872\n",
      "Iteration: 2924, Loss: 0.026869\n",
      "Iteration: 2925, Loss: 0.026866\n",
      "Iteration: 2926, Loss: 0.026863\n",
      "Iteration: 2927, Loss: 0.026861\n",
      "Iteration: 2928, Loss: 0.026857\n",
      "Iteration: 2929, Loss: 0.026853\n",
      "Iteration: 2930, Loss: 0.026850\n",
      "Iteration: 2931, Loss: 0.026847\n",
      "Iteration: 2932, Loss: 0.026843\n",
      "Iteration: 2933, Loss: 0.026838\n",
      "Iteration: 2934, Loss: 0.026866\n",
      "Iteration: 2935, Loss: 0.026836\n",
      "Iteration: 2936, Loss: 0.026830\n",
      "Iteration: 2937, Loss: 0.026825\n",
      "Iteration: 2938, Loss: 0.026823\n",
      "Iteration: 2939, Loss: 0.026821\n",
      "Iteration: 2940, Loss: 0.026819\n",
      "Iteration: 2941, Loss: 0.026818\n",
      "Iteration: 2942, Loss: 0.026816\n",
      "Iteration: 2943, Loss: 0.026815\n",
      "Iteration: 2944, Loss: 0.026814\n",
      "Iteration: 2945, Loss: 0.026813\n",
      "Iteration: 2946, Loss: 0.026811\n",
      "Iteration: 2947, Loss: 0.026808\n",
      "Iteration: 2948, Loss: 0.026808\n",
      "Iteration: 2949, Loss: 0.026806\n",
      "Iteration: 2950, Loss: 0.026802\n",
      "Iteration: 2951, Loss: 0.026798\n",
      "Iteration: 2952, Loss: 0.026793\n",
      "Iteration: 2953, Loss: 0.026789\n",
      "Iteration: 2954, Loss: 0.026786\n",
      "Iteration: 2955, Loss: 0.026783\n",
      "Iteration: 2956, Loss: 0.026780\n",
      "Iteration: 2957, Loss: 0.026779\n",
      "Iteration: 2958, Loss: 0.026778\n",
      "Iteration: 2959, Loss: 0.026777\n",
      "Iteration: 2960, Loss: 0.026776\n",
      "Iteration: 2961, Loss: 0.026775\n",
      "Iteration: 2962, Loss: 0.026774\n",
      "Iteration: 2963, Loss: 0.026772\n",
      "Iteration: 2964, Loss: 0.026770\n",
      "Iteration: 2965, Loss: 0.026766\n",
      "Iteration: 2966, Loss: 0.026763\n",
      "Iteration: 2967, Loss: 0.026759\n",
      "Iteration: 2968, Loss: 0.026758\n",
      "Iteration: 2969, Loss: 0.026757\n",
      "Iteration: 2970, Loss: 0.026752\n",
      "Iteration: 2971, Loss: 0.026748\n",
      "Iteration: 2972, Loss: 0.026742\n",
      "Iteration: 2973, Loss: 0.026747\n",
      "Iteration: 2974, Loss: 0.026741\n",
      "Iteration: 2975, Loss: 0.026737\n",
      "Iteration: 2976, Loss: 0.026736\n",
      "Iteration: 2977, Loss: 0.026732\n",
      "Iteration: 2978, Loss: 0.026728\n",
      "Iteration: 2979, Loss: 0.026724\n",
      "Iteration: 2980, Loss: 0.026721\n",
      "Iteration: 2981, Loss: 0.026716\n",
      "Iteration: 2982, Loss: 0.026710\n",
      "Iteration: 2983, Loss: 0.026706\n",
      "Iteration: 2984, Loss: 0.026705\n",
      "Iteration: 2985, Loss: 0.026701\n",
      "Iteration: 2986, Loss: 0.026700\n",
      "Iteration: 2987, Loss: 0.026698\n",
      "Iteration: 2988, Loss: 0.026695\n",
      "Iteration: 2989, Loss: 0.026697\n",
      "Iteration: 2990, Loss: 0.026692\n",
      "Iteration: 2991, Loss: 0.026687\n",
      "Iteration: 2992, Loss: 0.026682\n",
      "Iteration: 2993, Loss: 0.026677\n",
      "Iteration: 2994, Loss: 0.026680\n",
      "Iteration: 2995, Loss: 0.026673\n",
      "Iteration: 2996, Loss: 0.026666\n",
      "Iteration: 2997, Loss: 0.026659\n",
      "Iteration: 2998, Loss: 0.026668\n",
      "Iteration: 2999, Loss: 0.026657\n",
      "Iteration: 3000, Loss: 0.026653\n",
      "Iteration: 3001, Loss: 0.026652\n",
      "Iteration: 3002, Loss: 0.026650\n",
      "Iteration: 3003, Loss: 0.026649\n",
      "Iteration: 3004, Loss: 0.026647\n",
      "Iteration: 3005, Loss: 0.026645\n",
      "Iteration: 3006, Loss: 0.026644\n",
      "Iteration: 3007, Loss: 0.026641\n",
      "Iteration: 3008, Loss: 0.026638\n",
      "Iteration: 3009, Loss: 0.026635\n",
      "Iteration: 3010, Loss: 0.026638\n",
      "Iteration: 3011, Loss: 0.026633\n",
      "Iteration: 3012, Loss: 0.026630\n",
      "Iteration: 3013, Loss: 0.026627\n",
      "Iteration: 3014, Loss: 0.026626\n",
      "Iteration: 3015, Loss: 0.026624\n",
      "Iteration: 3016, Loss: 0.026622\n",
      "Iteration: 3017, Loss: 0.026619\n",
      "Iteration: 3018, Loss: 0.026618\n",
      "Iteration: 3019, Loss: 0.026618\n",
      "Iteration: 3020, Loss: 0.026616\n",
      "Iteration: 3021, Loss: 0.026614\n",
      "Iteration: 3022, Loss: 0.026610\n",
      "Iteration: 3023, Loss: 0.026608\n",
      "Iteration: 3024, Loss: 0.026606\n",
      "Iteration: 3025, Loss: 0.026604\n",
      "Iteration: 3026, Loss: 0.026602\n",
      "Iteration: 3027, Loss: 0.026599\n",
      "Iteration: 3028, Loss: 0.026594\n",
      "Iteration: 3029, Loss: 0.026591\n",
      "Iteration: 3030, Loss: 0.026589\n",
      "Iteration: 3031, Loss: 0.026585\n",
      "Iteration: 3032, Loss: 0.026582\n",
      "Iteration: 3033, Loss: 0.026576\n",
      "Iteration: 3034, Loss: 0.026582\n",
      "Iteration: 3035, Loss: 0.026575\n",
      "Iteration: 3036, Loss: 0.026572\n",
      "Iteration: 3037, Loss: 0.026569\n",
      "Iteration: 3038, Loss: 0.026562\n",
      "Iteration: 3039, Loss: 0.026565\n",
      "Iteration: 3040, Loss: 0.026558\n",
      "Iteration: 3041, Loss: 0.026553\n",
      "Iteration: 3042, Loss: 0.026545\n",
      "Iteration: 3043, Loss: 0.026547\n",
      "Iteration: 3044, Loss: 0.026544\n",
      "Iteration: 3045, Loss: 0.026541\n",
      "Iteration: 3046, Loss: 0.026537\n",
      "Iteration: 3047, Loss: 0.026534\n",
      "Iteration: 3048, Loss: 0.026533\n",
      "Iteration: 3049, Loss: 0.026534\n",
      "Iteration: 3050, Loss: 0.026531\n",
      "Iteration: 3051, Loss: 0.026530\n",
      "Iteration: 3052, Loss: 0.026529\n",
      "Iteration: 3053, Loss: 0.026527\n",
      "Iteration: 3054, Loss: 0.026526\n",
      "Iteration: 3055, Loss: 0.026524\n",
      "Iteration: 3056, Loss: 0.026522\n",
      "Iteration: 3057, Loss: 0.026520\n",
      "Iteration: 3058, Loss: 0.026524\n",
      "Iteration: 3059, Loss: 0.026519\n",
      "Iteration: 3060, Loss: 0.026517\n",
      "Iteration: 3061, Loss: 0.026515\n",
      "Iteration: 3062, Loss: 0.026514\n",
      "Iteration: 3063, Loss: 0.026512\n",
      "Iteration: 3064, Loss: 0.026510\n",
      "Iteration: 3065, Loss: 0.026507\n",
      "Iteration: 3066, Loss: 0.026519\n",
      "Iteration: 3067, Loss: 0.026505\n",
      "Iteration: 3068, Loss: 0.026502\n",
      "Iteration: 3069, Loss: 0.026499\n",
      "Iteration: 3070, Loss: 0.026501\n",
      "Iteration: 3071, Loss: 0.026497\n",
      "Iteration: 3072, Loss: 0.026496\n",
      "Iteration: 3073, Loss: 0.026492\n",
      "Iteration: 3074, Loss: 0.026490\n",
      "Iteration: 3075, Loss: 0.026488\n",
      "Iteration: 3076, Loss: 0.026487\n",
      "Iteration: 3077, Loss: 0.026486\n",
      "Iteration: 3078, Loss: 0.026483\n",
      "Iteration: 3079, Loss: 0.026481\n",
      "Iteration: 3080, Loss: 0.026478\n",
      "Iteration: 3081, Loss: 0.026475\n",
      "Iteration: 3082, Loss: 0.026471\n",
      "Iteration: 3083, Loss: 0.026467\n",
      "Iteration: 3084, Loss: 0.026464\n",
      "Iteration: 3085, Loss: 0.026461\n",
      "Iteration: 3086, Loss: 0.026456\n",
      "Iteration: 3087, Loss: 0.026454\n",
      "Iteration: 3088, Loss: 0.026448\n",
      "Iteration: 3089, Loss: 0.026445\n",
      "Iteration: 3090, Loss: 0.026441\n",
      "Iteration: 3091, Loss: 0.026438\n",
      "Iteration: 3092, Loss: 0.026433\n",
      "Iteration: 3093, Loss: 0.026426\n",
      "Iteration: 3094, Loss: 0.026436\n",
      "Iteration: 3095, Loss: 0.026421\n",
      "Iteration: 3096, Loss: 0.026421\n",
      "Iteration: 3097, Loss: 0.026414\n",
      "Iteration: 3098, Loss: 0.026408\n",
      "Iteration: 3099, Loss: 0.026404\n",
      "Iteration: 3100, Loss: 0.026402\n",
      "Iteration: 3101, Loss: 0.026398\n",
      "Iteration: 3102, Loss: 0.026397\n",
      "Iteration: 3103, Loss: 0.026395\n",
      "Iteration: 3104, Loss: 0.026393\n",
      "Iteration: 3105, Loss: 0.026389\n",
      "Iteration: 3106, Loss: 0.026385\n",
      "Iteration: 3107, Loss: 0.026383\n",
      "Iteration: 3108, Loss: 0.026379\n",
      "Iteration: 3109, Loss: 0.026378\n",
      "Iteration: 3110, Loss: 0.026376\n",
      "Iteration: 3111, Loss: 0.026371\n",
      "Iteration: 3112, Loss: 0.026469\n",
      "Iteration: 3113, Loss: 0.026369\n",
      "Iteration: 3114, Loss: 0.026359\n",
      "Iteration: 3115, Loss: 0.026353\n",
      "Iteration: 3116, Loss: 0.026348\n",
      "Iteration: 3117, Loss: 0.026349\n",
      "Iteration: 3118, Loss: 0.026344\n",
      "Iteration: 3119, Loss: 0.026340\n",
      "Iteration: 3120, Loss: 0.026334\n",
      "Iteration: 3121, Loss: 0.026332\n",
      "Iteration: 3122, Loss: 0.026329\n",
      "Iteration: 3123, Loss: 0.026324\n",
      "Iteration: 3124, Loss: 0.026320\n",
      "Iteration: 3125, Loss: 0.026313\n",
      "Iteration: 3126, Loss: 0.026307\n",
      "Iteration: 3127, Loss: 0.026318\n",
      "Iteration: 3128, Loss: 0.026304\n",
      "Iteration: 3129, Loss: 0.026300\n",
      "Iteration: 3130, Loss: 0.026295\n",
      "Iteration: 3131, Loss: 0.026292\n",
      "Iteration: 3132, Loss: 0.026289\n",
      "Iteration: 3133, Loss: 0.026335\n",
      "Iteration: 3134, Loss: 0.026287\n",
      "Iteration: 3135, Loss: 0.026285\n",
      "Iteration: 3136, Loss: 0.026282\n",
      "Iteration: 3137, Loss: 0.026281\n",
      "Iteration: 3138, Loss: 0.026278\n",
      "Iteration: 3139, Loss: 0.026275\n",
      "Iteration: 3140, Loss: 0.026308\n",
      "Iteration: 3141, Loss: 0.026274\n",
      "Iteration: 3142, Loss: 0.026270\n",
      "Iteration: 3143, Loss: 0.026296\n",
      "Iteration: 3144, Loss: 0.026269\n",
      "Iteration: 3145, Loss: 0.026266\n",
      "Iteration: 3146, Loss: 0.026260\n",
      "Iteration: 3147, Loss: 0.026255\n",
      "Iteration: 3148, Loss: 0.026247\n",
      "Iteration: 3149, Loss: 0.026244\n",
      "Iteration: 3150, Loss: 0.026241\n",
      "Iteration: 3151, Loss: 0.026238\n",
      "Iteration: 3152, Loss: 0.026236\n",
      "Iteration: 3153, Loss: 0.026234\n",
      "Iteration: 3154, Loss: 0.026231\n",
      "Iteration: 3155, Loss: 0.026234\n",
      "Iteration: 3156, Loss: 0.026231\n",
      "Iteration: 3157, Loss: 0.026229\n",
      "Iteration: 3158, Loss: 0.026227\n",
      "Iteration: 3159, Loss: 0.026226\n",
      "Iteration: 3160, Loss: 0.026225\n",
      "Iteration: 3161, Loss: 0.026229\n",
      "Iteration: 3162, Loss: 0.026224\n",
      "Iteration: 3163, Loss: 0.026221\n",
      "Iteration: 3164, Loss: 0.026218\n",
      "Iteration: 3165, Loss: 0.026213\n",
      "Iteration: 3166, Loss: 0.026207\n",
      "Iteration: 3167, Loss: 0.026203\n",
      "Iteration: 3168, Loss: 0.026495\n",
      "Iteration: 3169, Loss: 0.026200\n",
      "Iteration: 3170, Loss: 0.026196\n",
      "Iteration: 3171, Loss: 0.026192\n",
      "Iteration: 3172, Loss: 0.026189\n",
      "Iteration: 3173, Loss: 0.026187\n",
      "Iteration: 3174, Loss: 0.026185\n",
      "Iteration: 3175, Loss: 0.026184\n",
      "Iteration: 3176, Loss: 0.026183\n",
      "Iteration: 3177, Loss: 0.026182\n",
      "Iteration: 3178, Loss: 0.026179\n",
      "Iteration: 3179, Loss: 0.026181\n",
      "Iteration: 3180, Loss: 0.026179\n",
      "Iteration: 3181, Loss: 0.026177\n",
      "Iteration: 3182, Loss: 0.026175\n",
      "Iteration: 3183, Loss: 0.026175\n",
      "Iteration: 3184, Loss: 0.026174\n",
      "Iteration: 3185, Loss: 0.026172\n",
      "Iteration: 3186, Loss: 0.026171\n",
      "Iteration: 3187, Loss: 0.026169\n",
      "Iteration: 3188, Loss: 0.026168\n",
      "Iteration: 3189, Loss: 0.026167\n",
      "Iteration: 3190, Loss: 0.026166\n",
      "Iteration: 3191, Loss: 0.026165\n",
      "Iteration: 3192, Loss: 0.026164\n",
      "Iteration: 3193, Loss: 0.026162\n",
      "Iteration: 3194, Loss: 0.026161\n",
      "Iteration: 3195, Loss: 0.026160\n",
      "Iteration: 3196, Loss: 0.026159\n",
      "Iteration: 3197, Loss: 0.026158\n",
      "Iteration: 3198, Loss: 0.026156\n",
      "Iteration: 3199, Loss: 0.026156\n",
      "Iteration: 3200, Loss: 0.026154\n",
      "Iteration: 3201, Loss: 0.026152\n",
      "Iteration: 3202, Loss: 0.026151\n",
      "Iteration: 3203, Loss: 0.026149\n",
      "Iteration: 3204, Loss: 0.026148\n",
      "Iteration: 3205, Loss: 0.026146\n",
      "Iteration: 3206, Loss: 0.026145\n",
      "Iteration: 3207, Loss: 0.026143\n",
      "Iteration: 3208, Loss: 0.026142\n",
      "Iteration: 3209, Loss: 0.026140\n",
      "Iteration: 3210, Loss: 0.026198\n",
      "Iteration: 3211, Loss: 0.026140\n",
      "Iteration: 3212, Loss: 0.026138\n",
      "Iteration: 3213, Loss: 0.026137\n",
      "Iteration: 3214, Loss: 0.026136\n",
      "Iteration: 3215, Loss: 0.026133\n",
      "Iteration: 3216, Loss: 0.026130\n",
      "Iteration: 3217, Loss: 0.026130\n",
      "Iteration: 3218, Loss: 0.026128\n",
      "Iteration: 3219, Loss: 0.026125\n",
      "Iteration: 3220, Loss: 0.026122\n",
      "Iteration: 3221, Loss: 0.026121\n",
      "Iteration: 3222, Loss: 0.026118\n",
      "Iteration: 3223, Loss: 0.026115\n",
      "Iteration: 3224, Loss: 0.026110\n",
      "Iteration: 3225, Loss: 0.026217\n",
      "Iteration: 3226, Loss: 0.026109\n",
      "Iteration: 3227, Loss: 0.026102\n",
      "Iteration: 3228, Loss: 0.026097\n",
      "Iteration: 3229, Loss: 0.026094\n",
      "Iteration: 3230, Loss: 0.026091\n",
      "Iteration: 3231, Loss: 0.026089\n",
      "Iteration: 3232, Loss: 0.026085\n",
      "Iteration: 3233, Loss: 0.026082\n",
      "Iteration: 3234, Loss: 0.026080\n",
      "Iteration: 3235, Loss: 0.026092\n",
      "Iteration: 3236, Loss: 0.026079\n",
      "Iteration: 3237, Loss: 0.026074\n",
      "Iteration: 3238, Loss: 0.026071\n",
      "Iteration: 3239, Loss: 0.026068\n",
      "Iteration: 3240, Loss: 0.026065\n",
      "Iteration: 3241, Loss: 0.026572\n",
      "Iteration: 3242, Loss: 0.026064\n",
      "Iteration: 3243, Loss: 0.026058\n",
      "Iteration: 3244, Loss: 0.026054\n",
      "Iteration: 3245, Loss: 0.026050\n",
      "Iteration: 3246, Loss: 0.026046\n",
      "Iteration: 3247, Loss: 0.026040\n",
      "Iteration: 3248, Loss: 0.026034\n",
      "Iteration: 3249, Loss: 0.026031\n",
      "Iteration: 3250, Loss: 0.026676\n",
      "Iteration: 3251, Loss: 0.026029\n",
      "Iteration: 3252, Loss: 0.026025\n",
      "Iteration: 3253, Loss: 0.026031\n",
      "Iteration: 3254, Loss: 0.026022\n",
      "Iteration: 3255, Loss: 0.026016\n",
      "Iteration: 3256, Loss: 0.026013\n",
      "Iteration: 3257, Loss: 0.026010\n",
      "Iteration: 3258, Loss: 0.026020\n",
      "Iteration: 3259, Loss: 0.026008\n",
      "Iteration: 3260, Loss: 0.026003\n",
      "Iteration: 3261, Loss: 0.025993\n",
      "Iteration: 3262, Loss: 0.025978\n",
      "Iteration: 3263, Loss: 0.025970\n",
      "Iteration: 3264, Loss: 0.025963\n",
      "Iteration: 3265, Loss: 0.025959\n",
      "Iteration: 3266, Loss: 0.025962\n",
      "Iteration: 3267, Loss: 0.025955\n",
      "Iteration: 3268, Loss: 0.025950\n",
      "Iteration: 3269, Loss: 0.025946\n",
      "Iteration: 3270, Loss: 0.025944\n",
      "Iteration: 3271, Loss: 0.025943\n",
      "Iteration: 3272, Loss: 0.025941\n",
      "Iteration: 3273, Loss: 0.025938\n",
      "Iteration: 3274, Loss: 0.025935\n",
      "Iteration: 3275, Loss: 0.025941\n",
      "Iteration: 3276, Loss: 0.025932\n",
      "Iteration: 3277, Loss: 0.025934\n",
      "Iteration: 3278, Loss: 0.025929\n",
      "Iteration: 3279, Loss: 0.025924\n",
      "Iteration: 3280, Loss: 0.025910\n",
      "Iteration: 3281, Loss: 0.025905\n",
      "Iteration: 3282, Loss: 0.025896\n",
      "Iteration: 3283, Loss: 0.025893\n",
      "Iteration: 3284, Loss: 0.025891\n",
      "Iteration: 3285, Loss: 0.025890\n",
      "Iteration: 3286, Loss: 0.025888\n",
      "Iteration: 3287, Loss: 0.025888\n",
      "Iteration: 3288, Loss: 0.025886\n",
      "Iteration: 3289, Loss: 0.025880\n",
      "Iteration: 3290, Loss: 0.025874\n",
      "Iteration: 3291, Loss: 0.025869\n",
      "Iteration: 3292, Loss: 0.025865\n",
      "Iteration: 3293, Loss: 0.025857\n",
      "Iteration: 3294, Loss: 0.025849\n",
      "Iteration: 3295, Loss: 0.025861\n",
      "Iteration: 3296, Loss: 0.025847\n",
      "Iteration: 3297, Loss: 0.025841\n",
      "Iteration: 3298, Loss: 0.025830\n",
      "Iteration: 3299, Loss: 0.025823\n",
      "Iteration: 3300, Loss: 0.025817\n",
      "Iteration: 3301, Loss: 0.025809\n",
      "Iteration: 3302, Loss: 0.025835\n",
      "Iteration: 3303, Loss: 0.025807\n",
      "Iteration: 3304, Loss: 0.025943\n",
      "Iteration: 3305, Loss: 0.025794\n",
      "Iteration: 3306, Loss: 0.025786\n",
      "Iteration: 3307, Loss: 0.025777\n",
      "Iteration: 3308, Loss: 0.025773\n",
      "Iteration: 3309, Loss: 0.025768\n",
      "Iteration: 3310, Loss: 0.025762\n",
      "Iteration: 3311, Loss: 0.025756\n",
      "Iteration: 3312, Loss: 0.025757\n",
      "Iteration: 3313, Loss: 0.025755\n",
      "Iteration: 3314, Loss: 0.025764\n",
      "Iteration: 3315, Loss: 0.025753\n",
      "Iteration: 3316, Loss: 0.025749\n",
      "Iteration: 3317, Loss: 0.025745\n",
      "Iteration: 3318, Loss: 0.025738\n",
      "Iteration: 3319, Loss: 0.025757\n",
      "Iteration: 3320, Loss: 0.025735\n",
      "Iteration: 3321, Loss: 0.025725\n",
      "Iteration: 3322, Loss: 0.025717\n",
      "Iteration: 3323, Loss: 0.025705\n",
      "Iteration: 3324, Loss: 0.025697\n",
      "Iteration: 3325, Loss: 0.025692\n",
      "Iteration: 3326, Loss: 0.025685\n",
      "Iteration: 3327, Loss: 0.025678\n",
      "Iteration: 3328, Loss: 0.025671\n",
      "Iteration: 3329, Loss: 0.025667\n",
      "Iteration: 3330, Loss: 0.025666\n",
      "Iteration: 3331, Loss: 0.025673\n",
      "Iteration: 3332, Loss: 0.025663\n",
      "Iteration: 3333, Loss: 0.025660\n",
      "Iteration: 3334, Loss: 0.025658\n",
      "Iteration: 3335, Loss: 0.025654\n",
      "Iteration: 3336, Loss: 0.025648\n",
      "Iteration: 3337, Loss: 0.025642\n",
      "Iteration: 3338, Loss: 0.025632\n",
      "Iteration: 3339, Loss: 0.025623\n",
      "Iteration: 3340, Loss: 0.025613\n",
      "Iteration: 3341, Loss: 0.025600\n",
      "Iteration: 3342, Loss: 0.025597\n",
      "Iteration: 3343, Loss: 0.025592\n",
      "Iteration: 3344, Loss: 0.025587\n",
      "Iteration: 3345, Loss: 0.025596\n",
      "Iteration: 3346, Loss: 0.025585\n",
      "Iteration: 3347, Loss: 0.025582\n",
      "Iteration: 3348, Loss: 0.025580\n",
      "Iteration: 3349, Loss: 0.025580\n",
      "Iteration: 3350, Loss: 0.025579\n",
      "Iteration: 3351, Loss: 0.025578\n",
      "Iteration: 3352, Loss: 0.025577\n",
      "Iteration: 3353, Loss: 0.025574\n",
      "Iteration: 3354, Loss: 0.025571\n",
      "Iteration: 3355, Loss: 0.025567\n",
      "Iteration: 3356, Loss: 0.025563\n",
      "Iteration: 3357, Loss: 0.025567\n",
      "Iteration: 3358, Loss: 0.025562\n",
      "Iteration: 3359, Loss: 0.025558\n",
      "Iteration: 3360, Loss: 0.025554\n",
      "Iteration: 3361, Loss: 0.025549\n",
      "Iteration: 3362, Loss: 0.025545\n",
      "Iteration: 3363, Loss: 0.025542\n",
      "Iteration: 3364, Loss: 0.025537\n",
      "Iteration: 3365, Loss: 0.025533\n",
      "Iteration: 3366, Loss: 0.025545\n",
      "Iteration: 3367, Loss: 0.025531\n",
      "Iteration: 3368, Loss: 0.025683\n",
      "Iteration: 3369, Loss: 0.025523\n",
      "Iteration: 3370, Loss: 0.025516\n",
      "Iteration: 3371, Loss: 0.025510\n",
      "Iteration: 3372, Loss: 0.025506\n",
      "Iteration: 3373, Loss: 0.025519\n",
      "Iteration: 3374, Loss: 0.025505\n",
      "Iteration: 3375, Loss: 0.025501\n",
      "Iteration: 3376, Loss: 0.025499\n",
      "Iteration: 3377, Loss: 0.025496\n",
      "Iteration: 3378, Loss: 0.025493\n",
      "Iteration: 3379, Loss: 0.025490\n",
      "Iteration: 3380, Loss: 0.025486\n",
      "Iteration: 3381, Loss: 0.025482\n",
      "Iteration: 3382, Loss: 0.025480\n",
      "Iteration: 3383, Loss: 0.025478\n",
      "Iteration: 3384, Loss: 0.025475\n",
      "Iteration: 3385, Loss: 0.025721\n",
      "Iteration: 3386, Loss: 0.025474\n",
      "Iteration: 3387, Loss: 0.025472\n",
      "Iteration: 3388, Loss: 0.025470\n",
      "Iteration: 3389, Loss: 0.025468\n",
      "Iteration: 3390, Loss: 0.025467\n",
      "Iteration: 3391, Loss: 0.025466\n",
      "Iteration: 3392, Loss: 0.025464\n",
      "Iteration: 3393, Loss: 0.025462\n",
      "Iteration: 3394, Loss: 0.025460\n",
      "Iteration: 3395, Loss: 0.025457\n",
      "Iteration: 3396, Loss: 0.025454\n",
      "Iteration: 3397, Loss: 0.025452\n",
      "Iteration: 3398, Loss: 0.025449\n",
      "Iteration: 3399, Loss: 0.025446\n",
      "Iteration: 3400, Loss: 0.025442\n",
      "Iteration: 3401, Loss: 0.025439\n",
      "Iteration: 3402, Loss: 0.025433\n",
      "Iteration: 3403, Loss: 0.025429\n",
      "Iteration: 3404, Loss: 0.025426\n",
      "Iteration: 3405, Loss: 0.025501\n",
      "Iteration: 3406, Loss: 0.025424\n",
      "Iteration: 3407, Loss: 0.025420\n",
      "Iteration: 3408, Loss: 0.025413\n",
      "Iteration: 3409, Loss: 0.025405\n",
      "Iteration: 3410, Loss: 0.025398\n",
      "Iteration: 3411, Loss: 0.025393\n",
      "Iteration: 3412, Loss: 0.025385\n",
      "Iteration: 3413, Loss: 0.025379\n",
      "Iteration: 3414, Loss: 0.025382\n",
      "Iteration: 3415, Loss: 0.025377\n",
      "Iteration: 3416, Loss: 0.025375\n",
      "Iteration: 3417, Loss: 0.025373\n",
      "Iteration: 3418, Loss: 0.025372\n",
      "Iteration: 3419, Loss: 0.025370\n",
      "Iteration: 3420, Loss: 0.025367\n",
      "Iteration: 3421, Loss: 0.025365\n",
      "Iteration: 3422, Loss: 0.025366\n",
      "Iteration: 3423, Loss: 0.025362\n",
      "Iteration: 3424, Loss: 0.025357\n",
      "Iteration: 3425, Loss: 0.025351\n",
      "Iteration: 3426, Loss: 0.025349\n",
      "Iteration: 3427, Loss: 0.025341\n",
      "Iteration: 3428, Loss: 0.025336\n",
      "Iteration: 3429, Loss: 0.025331\n",
      "Iteration: 3430, Loss: 0.025327\n",
      "Iteration: 3431, Loss: 0.025323\n",
      "Iteration: 3432, Loss: 0.025322\n",
      "Iteration: 3433, Loss: 0.025317\n",
      "Iteration: 3434, Loss: 0.025315\n",
      "Iteration: 3435, Loss: 0.025311\n",
      "Iteration: 3436, Loss: 0.025307\n",
      "Iteration: 3437, Loss: 0.025305\n",
      "Iteration: 3438, Loss: 0.025303\n",
      "Iteration: 3439, Loss: 0.025300\n",
      "Iteration: 3440, Loss: 0.025339\n",
      "Iteration: 3441, Loss: 0.025299\n",
      "Iteration: 3442, Loss: 0.025308\n",
      "Iteration: 3443, Loss: 0.025298\n",
      "Iteration: 3444, Loss: 0.025294\n",
      "Iteration: 3445, Loss: 0.025291\n",
      "Iteration: 3446, Loss: 0.025287\n",
      "Iteration: 3447, Loss: 0.025284\n",
      "Iteration: 3448, Loss: 0.025281\n",
      "Iteration: 3449, Loss: 0.025278\n",
      "Iteration: 3450, Loss: 0.025276\n",
      "Iteration: 3451, Loss: 0.025274\n",
      "Iteration: 3452, Loss: 0.025272\n",
      "Iteration: 3453, Loss: 0.025269\n",
      "Iteration: 3454, Loss: 0.025291\n",
      "Iteration: 3455, Loss: 0.025268\n",
      "Iteration: 3456, Loss: 0.025262\n",
      "Iteration: 3457, Loss: 0.025258\n",
      "Iteration: 3458, Loss: 0.025253\n",
      "Iteration: 3459, Loss: 0.025251\n",
      "Iteration: 3460, Loss: 0.025253\n",
      "Iteration: 3461, Loss: 0.025249\n",
      "Iteration: 3462, Loss: 0.025245\n",
      "Iteration: 3463, Loss: 0.025242\n",
      "Iteration: 3464, Loss: 0.025239\n",
      "Iteration: 3465, Loss: 0.025236\n",
      "Iteration: 3466, Loss: 0.025233\n",
      "Iteration: 3467, Loss: 0.025230\n",
      "Iteration: 3468, Loss: 0.025227\n",
      "Iteration: 3469, Loss: 0.025225\n",
      "Iteration: 3470, Loss: 0.025223\n",
      "Iteration: 3471, Loss: 0.025222\n",
      "Iteration: 3472, Loss: 0.025260\n",
      "Iteration: 3473, Loss: 0.025222\n",
      "Iteration: 3474, Loss: 0.025221\n",
      "Iteration: 3475, Loss: 0.025219\n",
      "Iteration: 3476, Loss: 0.025216\n",
      "Iteration: 3477, Loss: 0.025214\n",
      "Iteration: 3478, Loss: 0.025211\n",
      "Iteration: 3479, Loss: 0.025208\n",
      "Iteration: 3480, Loss: 0.025205\n",
      "Iteration: 3481, Loss: 0.025202\n",
      "Iteration: 3482, Loss: 0.025195\n",
      "Iteration: 3483, Loss: 0.025191\n",
      "Iteration: 3484, Loss: 0.025187\n",
      "Iteration: 3485, Loss: 0.025182\n",
      "Iteration: 3486, Loss: 0.025179\n",
      "Iteration: 3487, Loss: 0.025176\n",
      "Iteration: 3488, Loss: 0.025173\n",
      "Iteration: 3489, Loss: 0.025169\n",
      "Iteration: 3490, Loss: 0.025166\n",
      "Iteration: 3491, Loss: 0.025162\n",
      "Iteration: 3492, Loss: 0.025156\n",
      "Iteration: 3493, Loss: 0.025149\n",
      "Iteration: 3494, Loss: 0.025146\n",
      "Iteration: 3495, Loss: 0.025141\n",
      "Iteration: 3496, Loss: 0.025139\n",
      "Iteration: 3497, Loss: 0.025138\n",
      "Iteration: 3498, Loss: 0.025136\n",
      "Iteration: 3499, Loss: 0.025134\n",
      "Iteration: 3500, Loss: 0.025132\n",
      "Iteration: 3501, Loss: 0.025130\n",
      "Iteration: 3502, Loss: 0.025130\n",
      "Iteration: 3503, Loss: 0.025129\n",
      "Iteration: 3504, Loss: 0.025128\n",
      "Iteration: 3505, Loss: 0.025126\n",
      "Iteration: 3506, Loss: 0.025125\n",
      "Iteration: 3507, Loss: 0.025124\n",
      "Iteration: 3508, Loss: 0.025123\n",
      "Iteration: 3509, Loss: 0.025121\n",
      "Iteration: 3510, Loss: 0.025118\n",
      "Iteration: 3511, Loss: 0.025115\n",
      "Iteration: 3512, Loss: 0.025113\n",
      "Iteration: 3513, Loss: 0.025111\n",
      "Iteration: 3514, Loss: 0.025109\n",
      "Iteration: 3515, Loss: 0.025106\n",
      "Iteration: 3516, Loss: 0.025101\n",
      "Iteration: 3517, Loss: 0.025099\n",
      "Iteration: 3518, Loss: 0.025097\n",
      "Iteration: 3519, Loss: 0.025095\n",
      "Iteration: 3520, Loss: 0.025095\n",
      "Iteration: 3521, Loss: 0.025094\n",
      "Iteration: 3522, Loss: 0.025092\n",
      "Iteration: 3523, Loss: 0.025090\n",
      "Iteration: 3524, Loss: 0.025089\n",
      "Iteration: 3525, Loss: 0.025087\n",
      "Iteration: 3526, Loss: 0.025122\n",
      "Iteration: 3527, Loss: 0.025087\n",
      "Iteration: 3528, Loss: 0.025085\n",
      "Iteration: 3529, Loss: 0.025084\n",
      "Iteration: 3530, Loss: 0.025083\n",
      "Iteration: 3531, Loss: 0.025082\n",
      "Iteration: 3532, Loss: 0.025081\n",
      "Iteration: 3533, Loss: 0.025078\n",
      "Iteration: 3534, Loss: 0.025078\n",
      "Iteration: 3535, Loss: 0.025076\n",
      "Iteration: 3536, Loss: 0.025073\n",
      "Iteration: 3537, Loss: 0.025071\n",
      "Iteration: 3538, Loss: 0.025069\n",
      "Iteration: 3539, Loss: 0.025066\n",
      "Iteration: 3540, Loss: 0.025075\n",
      "Iteration: 3541, Loss: 0.025063\n",
      "Iteration: 3542, Loss: 0.025060\n",
      "Iteration: 3543, Loss: 0.025057\n",
      "Iteration: 3544, Loss: 0.025056\n",
      "Iteration: 3545, Loss: 0.025054\n",
      "Iteration: 3546, Loss: 0.025052\n",
      "Iteration: 3547, Loss: 0.025051\n",
      "Iteration: 3548, Loss: 0.025049\n",
      "Iteration: 3549, Loss: 0.025047\n",
      "Iteration: 3550, Loss: 0.025045\n",
      "Iteration: 3551, Loss: 0.025042\n",
      "Iteration: 3552, Loss: 0.025037\n",
      "Iteration: 3553, Loss: 0.025033\n",
      "Iteration: 3554, Loss: 0.025029\n",
      "Iteration: 3555, Loss: 0.025026\n",
      "Iteration: 3556, Loss: 0.025024\n",
      "Iteration: 3557, Loss: 0.025022\n",
      "Iteration: 3558, Loss: 0.025019\n",
      "Iteration: 3559, Loss: 0.025015\n",
      "Iteration: 3560, Loss: 0.025012\n",
      "Iteration: 3561, Loss: 0.025010\n",
      "Iteration: 3562, Loss: 0.025009\n",
      "Iteration: 3563, Loss: 0.025025\n",
      "Iteration: 3564, Loss: 0.025008\n",
      "Iteration: 3565, Loss: 0.025006\n",
      "Iteration: 3566, Loss: 0.025001\n",
      "Iteration: 3567, Loss: 0.024999\n",
      "Iteration: 3568, Loss: 0.024996\n",
      "Iteration: 3569, Loss: 0.025000\n",
      "Iteration: 3570, Loss: 0.024995\n",
      "Iteration: 3571, Loss: 0.024993\n",
      "Iteration: 3572, Loss: 0.024990\n",
      "Iteration: 3573, Loss: 0.024986\n",
      "Iteration: 3574, Loss: 0.024982\n",
      "Iteration: 3575, Loss: 0.024976\n",
      "Iteration: 3576, Loss: 0.024971\n",
      "Iteration: 3577, Loss: 0.024966\n",
      "Iteration: 3578, Loss: 0.024962\n",
      "Iteration: 3579, Loss: 0.024957\n",
      "Iteration: 3580, Loss: 0.024952\n",
      "Iteration: 3581, Loss: 0.024947\n",
      "Iteration: 3582, Loss: 0.024938\n",
      "Iteration: 3583, Loss: 0.024932\n",
      "Iteration: 3584, Loss: 0.024928\n",
      "Iteration: 3585, Loss: 0.024925\n",
      "Iteration: 3586, Loss: 0.024924\n",
      "Iteration: 3587, Loss: 0.024921\n",
      "Iteration: 3588, Loss: 0.024918\n",
      "Iteration: 3589, Loss: 0.024915\n",
      "Iteration: 3590, Loss: 0.024912\n",
      "Iteration: 3591, Loss: 0.024910\n",
      "Iteration: 3592, Loss: 0.024905\n",
      "Iteration: 3593, Loss: 0.024900\n",
      "Iteration: 3594, Loss: 0.024895\n",
      "Iteration: 3595, Loss: 0.024893\n",
      "Iteration: 3596, Loss: 0.024890\n",
      "Iteration: 3597, Loss: 0.024888\n",
      "Iteration: 3598, Loss: 0.024892\n",
      "Iteration: 3599, Loss: 0.024887\n",
      "Iteration: 3600, Loss: 0.024881\n",
      "Iteration: 3601, Loss: 0.024874\n",
      "Iteration: 3602, Loss: 0.024871\n",
      "Iteration: 3603, Loss: 0.024862\n",
      "Iteration: 3604, Loss: 0.024860\n",
      "Iteration: 3605, Loss: 0.024855\n",
      "Iteration: 3606, Loss: 0.024849\n",
      "Iteration: 3607, Loss: 0.024845\n",
      "Iteration: 3608, Loss: 0.024844\n",
      "Iteration: 3609, Loss: 0.024841\n",
      "Iteration: 3610, Loss: 0.024838\n",
      "Iteration: 3611, Loss: 0.024835\n",
      "Iteration: 3612, Loss: 0.024833\n",
      "Iteration: 3613, Loss: 0.024827\n",
      "Iteration: 3614, Loss: 0.024822\n",
      "Iteration: 3615, Loss: 0.024819\n",
      "Iteration: 3616, Loss: 0.024815\n",
      "Iteration: 3617, Loss: 0.024814\n",
      "Iteration: 3618, Loss: 0.024810\n",
      "Iteration: 3619, Loss: 0.024806\n",
      "Iteration: 3620, Loss: 0.024801\n",
      "Iteration: 3621, Loss: 0.024797\n",
      "Iteration: 3622, Loss: 0.024793\n",
      "Iteration: 3623, Loss: 0.024798\n",
      "Iteration: 3624, Loss: 0.024791\n",
      "Iteration: 3625, Loss: 0.024786\n",
      "Iteration: 3626, Loss: 0.024775\n",
      "Iteration: 3627, Loss: 0.024760\n",
      "Iteration: 3628, Loss: 0.024748\n",
      "Iteration: 3629, Loss: 0.024739\n",
      "Iteration: 3630, Loss: 0.024733\n",
      "Iteration: 3631, Loss: 0.024729\n",
      "Iteration: 3632, Loss: 0.024726\n",
      "Iteration: 3633, Loss: 0.024721\n",
      "Iteration: 3634, Loss: 0.024723\n",
      "Iteration: 3635, Loss: 0.024717\n",
      "Iteration: 3636, Loss: 0.024762\n",
      "Iteration: 3637, Loss: 0.024711\n",
      "Iteration: 3638, Loss: 0.024708\n",
      "Iteration: 3639, Loss: 0.024705\n",
      "Iteration: 3640, Loss: 0.024702\n",
      "Iteration: 3641, Loss: 0.024701\n",
      "Iteration: 3642, Loss: 0.024699\n",
      "Iteration: 3643, Loss: 0.024698\n",
      "Iteration: 3644, Loss: 0.024698\n",
      "Iteration: 3645, Loss: 0.024697\n",
      "Iteration: 3646, Loss: 0.024696\n",
      "Iteration: 3647, Loss: 0.024695\n",
      "Iteration: 3648, Loss: 0.024694\n",
      "Iteration: 3649, Loss: 0.024691\n",
      "Iteration: 3650, Loss: 0.024688\n",
      "Iteration: 3651, Loss: 0.024691\n",
      "Iteration: 3652, Loss: 0.024686\n",
      "Iteration: 3653, Loss: 0.024683\n",
      "Iteration: 3654, Loss: 0.024680\n",
      "Iteration: 3655, Loss: 0.024679\n",
      "Iteration: 3656, Loss: 0.024677\n",
      "Iteration: 3657, Loss: 0.024676\n",
      "Iteration: 3658, Loss: 0.024673\n",
      "Iteration: 3659, Loss: 0.024670\n",
      "Iteration: 3660, Loss: 0.024667\n",
      "Iteration: 3661, Loss: 0.024663\n",
      "Iteration: 3662, Loss: 0.024661\n",
      "Iteration: 3663, Loss: 0.024656\n",
      "Iteration: 3664, Loss: 0.024653\n",
      "Iteration: 3665, Loss: 0.024650\n",
      "Iteration: 3666, Loss: 0.024648\n",
      "Iteration: 3667, Loss: 0.024645\n",
      "Iteration: 3668, Loss: 0.024644\n",
      "Iteration: 3669, Loss: 0.024637\n",
      "Iteration: 3670, Loss: 0.024635\n",
      "Iteration: 3671, Loss: 0.024632\n",
      "Iteration: 3672, Loss: 0.024637\n",
      "Iteration: 3673, Loss: 0.024630\n",
      "Iteration: 3674, Loss: 0.024628\n",
      "Iteration: 3675, Loss: 0.024625\n",
      "Iteration: 3676, Loss: 0.024624\n",
      "Iteration: 3677, Loss: 0.024621\n",
      "Iteration: 3678, Loss: 0.024622\n",
      "Iteration: 3679, Loss: 0.024620\n",
      "Iteration: 3680, Loss: 0.024618\n",
      "Iteration: 3681, Loss: 0.024618\n",
      "Iteration: 3682, Loss: 0.024616\n",
      "Iteration: 3683, Loss: 0.024615\n",
      "Iteration: 3684, Loss: 0.024612\n",
      "Iteration: 3685, Loss: 0.024611\n",
      "Iteration: 3686, Loss: 0.024609\n",
      "Iteration: 3687, Loss: 0.024614\n",
      "Iteration: 3688, Loss: 0.024608\n",
      "Iteration: 3689, Loss: 0.024607\n",
      "Iteration: 3690, Loss: 0.024603\n",
      "Iteration: 3691, Loss: 0.024599\n",
      "Iteration: 3692, Loss: 0.024594\n",
      "Iteration: 3693, Loss: 0.024591\n",
      "Iteration: 3694, Loss: 0.024594\n",
      "Iteration: 3695, Loss: 0.024590\n",
      "Iteration: 3696, Loss: 0.024588\n",
      "Iteration: 3697, Loss: 0.024585\n",
      "Iteration: 3698, Loss: 0.024583\n",
      "Iteration: 3699, Loss: 0.024581\n",
      "Iteration: 3700, Loss: 0.024577\n",
      "Iteration: 3701, Loss: 0.024573\n",
      "Iteration: 3702, Loss: 0.024564\n",
      "Iteration: 3703, Loss: 0.024560\n",
      "Iteration: 3704, Loss: 0.024556\n",
      "Iteration: 3705, Loss: 0.024553\n",
      "Iteration: 3706, Loss: 0.024552\n",
      "Iteration: 3707, Loss: 0.024549\n",
      "Iteration: 3708, Loss: 0.024547\n",
      "Iteration: 3709, Loss: 0.024599\n",
      "Iteration: 3710, Loss: 0.024547\n",
      "Iteration: 3711, Loss: 0.024545\n",
      "Iteration: 3712, Loss: 0.024544\n",
      "Iteration: 3713, Loss: 0.024544\n",
      "Iteration: 3714, Loss: 0.024543\n",
      "Iteration: 3715, Loss: 0.024541\n",
      "Iteration: 3716, Loss: 0.024599\n",
      "Iteration: 3717, Loss: 0.024541\n",
      "Iteration: 3718, Loss: 0.024539\n",
      "Iteration: 3719, Loss: 0.024538\n",
      "Iteration: 3720, Loss: 0.024538\n",
      "Iteration: 3721, Loss: 0.024536\n",
      "Iteration: 3722, Loss: 0.024534\n",
      "Iteration: 3723, Loss: 0.024541\n",
      "Iteration: 3724, Loss: 0.024534\n",
      "Iteration: 3725, Loss: 0.024531\n",
      "Iteration: 3726, Loss: 0.024529\n",
      "Iteration: 3727, Loss: 0.024526\n",
      "Iteration: 3728, Loss: 0.024525\n",
      "Iteration: 3729, Loss: 0.024521\n",
      "Iteration: 3730, Loss: 0.024519\n",
      "Iteration: 3731, Loss: 0.024518\n",
      "Iteration: 3732, Loss: 0.024517\n",
      "Iteration: 3733, Loss: 0.024514\n",
      "Iteration: 3734, Loss: 0.024510\n",
      "Iteration: 3735, Loss: 0.024508\n",
      "Iteration: 3736, Loss: 0.024505\n",
      "Iteration: 3737, Loss: 0.024502\n",
      "Iteration: 3738, Loss: 0.024498\n",
      "Iteration: 3739, Loss: 0.024496\n",
      "Iteration: 3740, Loss: 0.024491\n",
      "Iteration: 3741, Loss: 0.024487\n",
      "Iteration: 3742, Loss: 0.024484\n",
      "Iteration: 3743, Loss: 0.024481\n",
      "Iteration: 3744, Loss: 0.024478\n",
      "Iteration: 3745, Loss: 0.024477\n",
      "Iteration: 3746, Loss: 0.024475\n",
      "Iteration: 3747, Loss: 0.024474\n",
      "Iteration: 3748, Loss: 0.024473\n",
      "Iteration: 3749, Loss: 0.024472\n",
      "Iteration: 3750, Loss: 0.024476\n",
      "Iteration: 3751, Loss: 0.024472\n",
      "Iteration: 3752, Loss: 0.024471\n",
      "Iteration: 3753, Loss: 0.024470\n",
      "Iteration: 3754, Loss: 0.024469\n",
      "Iteration: 3755, Loss: 0.024467\n",
      "Iteration: 3756, Loss: 0.024486\n",
      "Iteration: 3757, Loss: 0.024466\n",
      "Iteration: 3758, Loss: 0.024463\n",
      "Iteration: 3759, Loss: 0.024460\n",
      "Iteration: 3760, Loss: 0.024486\n",
      "Iteration: 3761, Loss: 0.024459\n",
      "Iteration: 3762, Loss: 0.024456\n",
      "Iteration: 3763, Loss: 0.024452\n",
      "Iteration: 3764, Loss: 0.024449\n",
      "Iteration: 3765, Loss: 0.024446\n",
      "Iteration: 3766, Loss: 0.024443\n",
      "Iteration: 3767, Loss: 0.024442\n",
      "Iteration: 3768, Loss: 0.024447\n",
      "Iteration: 3769, Loss: 0.024440\n",
      "Iteration: 3770, Loss: 0.024438\n",
      "Iteration: 3771, Loss: 0.024434\n",
      "Iteration: 3772, Loss: 0.024433\n",
      "Iteration: 3773, Loss: 0.024432\n",
      "Iteration: 3774, Loss: 0.024464\n",
      "Iteration: 3775, Loss: 0.024431\n",
      "Iteration: 3776, Loss: 0.024430\n",
      "Iteration: 3777, Loss: 0.024429\n",
      "Iteration: 3778, Loss: 0.024427\n",
      "Iteration: 3779, Loss: 0.024425\n",
      "Iteration: 3780, Loss: 0.024424\n",
      "Iteration: 3781, Loss: 0.024421\n",
      "Iteration: 3782, Loss: 0.024418\n",
      "Iteration: 3783, Loss: 0.024415\n",
      "Iteration: 3784, Loss: 0.024411\n",
      "Iteration: 3785, Loss: 0.024408\n",
      "Iteration: 3786, Loss: 0.024406\n",
      "Iteration: 3787, Loss: 0.024403\n",
      "Iteration: 3788, Loss: 0.024402\n",
      "Iteration: 3789, Loss: 0.024399\n",
      "Iteration: 3790, Loss: 0.024397\n",
      "Iteration: 3791, Loss: 0.024394\n",
      "Iteration: 3792, Loss: 0.024390\n",
      "Iteration: 3793, Loss: 0.024403\n",
      "Iteration: 3794, Loss: 0.024388\n",
      "Iteration: 3795, Loss: 0.024386\n",
      "Iteration: 3796, Loss: 0.024385\n",
      "Iteration: 3797, Loss: 0.024384\n",
      "Iteration: 3798, Loss: 0.024381\n",
      "Iteration: 3799, Loss: 0.024378\n",
      "Iteration: 3800, Loss: 0.024377\n",
      "Iteration: 3801, Loss: 0.024375\n",
      "Iteration: 3802, Loss: 0.024374\n",
      "Iteration: 3803, Loss: 0.024372\n",
      "Iteration: 3804, Loss: 0.024371\n",
      "Iteration: 3805, Loss: 0.024369\n",
      "Iteration: 3806, Loss: 0.024370\n",
      "Iteration: 3807, Loss: 0.024368\n",
      "Iteration: 3808, Loss: 0.024366\n",
      "Iteration: 3809, Loss: 0.024363\n",
      "Iteration: 3810, Loss: 0.024360\n",
      "Iteration: 3811, Loss: 0.024358\n",
      "Iteration: 3812, Loss: 0.024355\n",
      "Iteration: 3813, Loss: 0.024354\n",
      "Iteration: 3814, Loss: 0.024353\n",
      "Iteration: 3815, Loss: 0.024351\n",
      "Iteration: 3816, Loss: 0.024350\n",
      "Iteration: 3817, Loss: 0.024352\n",
      "Iteration: 3818, Loss: 0.024349\n",
      "Iteration: 3819, Loss: 0.024345\n",
      "Iteration: 3820, Loss: 0.024342\n",
      "Iteration: 3821, Loss: 0.024340\n",
      "Iteration: 3822, Loss: 0.024338\n",
      "Iteration: 3823, Loss: 0.024336\n",
      "Iteration: 3824, Loss: 0.024334\n",
      "Iteration: 3825, Loss: 0.024333\n",
      "Iteration: 3826, Loss: 0.024332\n",
      "Iteration: 3827, Loss: 0.024331\n",
      "Iteration: 3828, Loss: 0.024328\n",
      "Iteration: 3829, Loss: 0.024331\n",
      "Iteration: 3830, Loss: 0.024326\n",
      "Iteration: 3831, Loss: 0.024321\n",
      "Iteration: 3832, Loss: 0.024314\n",
      "Iteration: 3833, Loss: 0.024309\n",
      "Iteration: 3834, Loss: 0.024306\n",
      "Iteration: 3835, Loss: 0.024307\n",
      "Iteration: 3836, Loss: 0.024302\n",
      "Iteration: 3837, Loss: 0.024297\n",
      "Iteration: 3838, Loss: 0.024292\n",
      "Iteration: 3839, Loss: 0.024288\n",
      "Iteration: 3840, Loss: 0.024285\n",
      "Iteration: 3841, Loss: 0.024281\n",
      "Iteration: 3842, Loss: 0.024279\n",
      "Iteration: 3843, Loss: 0.024278\n",
      "Iteration: 3844, Loss: 0.024277\n",
      "Iteration: 3845, Loss: 0.024275\n",
      "Iteration: 3846, Loss: 0.024274\n",
      "Iteration: 3847, Loss: 0.024271\n",
      "Iteration: 3848, Loss: 0.024267\n",
      "Iteration: 3849, Loss: 0.024265\n",
      "Iteration: 3850, Loss: 0.024269\n",
      "Iteration: 3851, Loss: 0.024262\n",
      "Iteration: 3852, Loss: 0.024261\n",
      "Iteration: 3853, Loss: 0.024259\n",
      "Iteration: 3854, Loss: 0.024257\n",
      "Iteration: 3855, Loss: 0.024253\n",
      "Iteration: 3856, Loss: 0.024250\n",
      "Iteration: 3857, Loss: 0.024414\n",
      "Iteration: 3858, Loss: 0.024250\n",
      "Iteration: 3859, Loss: 0.024247\n",
      "Iteration: 3860, Loss: 0.024246\n",
      "Iteration: 3861, Loss: 0.024245\n",
      "Iteration: 3862, Loss: 0.024244\n",
      "Iteration: 3863, Loss: 0.024243\n",
      "Iteration: 3864, Loss: 0.024242\n",
      "Iteration: 3865, Loss: 0.024242\n",
      "Iteration: 3866, Loss: 0.024262\n",
      "Iteration: 3867, Loss: 0.024241\n",
      "Iteration: 3868, Loss: 0.024240\n",
      "Iteration: 3869, Loss: 0.024239\n",
      "Iteration: 3870, Loss: 0.024237\n",
      "Iteration: 3871, Loss: 0.024236\n",
      "Iteration: 3872, Loss: 0.024236\n",
      "Iteration: 3873, Loss: 0.024234\n",
      "Iteration: 3874, Loss: 0.024233\n",
      "Iteration: 3875, Loss: 0.024229\n",
      "Iteration: 3876, Loss: 0.024224\n",
      "Iteration: 3877, Loss: 0.024216\n",
      "Iteration: 3878, Loss: 0.024233\n",
      "Iteration: 3879, Loss: 0.024213\n",
      "Iteration: 3880, Loss: 0.024207\n",
      "Iteration: 3881, Loss: 0.024203\n",
      "Iteration: 3882, Loss: 0.024203\n",
      "Iteration: 3883, Loss: 0.024202\n",
      "Iteration: 3884, Loss: 0.024201\n",
      "Iteration: 3885, Loss: 0.024198\n",
      "Iteration: 3886, Loss: 0.024197\n",
      "Iteration: 3887, Loss: 0.024196\n",
      "Iteration: 3888, Loss: 0.024195\n",
      "Iteration: 3889, Loss: 0.024193\n",
      "Iteration: 3890, Loss: 0.024191\n",
      "Iteration: 3891, Loss: 0.024186\n",
      "Iteration: 3892, Loss: 0.024181\n",
      "Iteration: 3893, Loss: 0.024181\n",
      "Iteration: 3894, Loss: 0.024178\n",
      "Iteration: 3895, Loss: 0.024175\n",
      "Iteration: 3896, Loss: 0.024172\n",
      "Iteration: 3897, Loss: 0.024168\n",
      "Iteration: 3898, Loss: 0.024426\n",
      "Iteration: 3899, Loss: 0.024166\n",
      "Iteration: 3900, Loss: 0.024163\n",
      "Iteration: 3901, Loss: 0.024162\n",
      "Iteration: 3902, Loss: 0.024159\n",
      "Iteration: 3903, Loss: 0.024158\n",
      "Iteration: 3904, Loss: 0.024156\n",
      "Iteration: 3905, Loss: 0.024155\n",
      "Iteration: 3906, Loss: 0.024154\n",
      "Iteration: 3907, Loss: 0.024152\n",
      "Iteration: 3908, Loss: 0.024151\n",
      "Iteration: 3909, Loss: 0.024149\n",
      "Iteration: 3910, Loss: 0.024146\n",
      "Iteration: 3911, Loss: 0.024144\n",
      "Iteration: 3912, Loss: 0.024143\n",
      "Iteration: 3913, Loss: 0.024140\n",
      "Iteration: 3914, Loss: 0.024135\n",
      "Iteration: 3915, Loss: 0.024130\n",
      "Iteration: 3916, Loss: 0.024127\n",
      "Iteration: 3917, Loss: 0.024125\n",
      "Iteration: 3918, Loss: 0.024124\n",
      "Iteration: 3919, Loss: 0.024123\n",
      "Iteration: 3920, Loss: 0.024126\n",
      "Iteration: 3921, Loss: 0.024122\n",
      "Iteration: 3922, Loss: 0.024119\n",
      "Iteration: 3923, Loss: 0.024114\n",
      "Iteration: 3924, Loss: 0.024111\n",
      "Iteration: 3925, Loss: 0.024108\n",
      "Iteration: 3926, Loss: 0.024106\n",
      "Iteration: 3927, Loss: 0.024103\n",
      "Iteration: 3928, Loss: 0.024101\n",
      "Iteration: 3929, Loss: 0.024098\n",
      "Iteration: 3930, Loss: 0.024096\n",
      "Iteration: 3931, Loss: 0.024094\n",
      "Iteration: 3932, Loss: 0.024091\n",
      "Iteration: 3933, Loss: 0.024088\n",
      "Iteration: 3934, Loss: 0.024085\n",
      "Iteration: 3935, Loss: 0.024083\n",
      "Iteration: 3936, Loss: 0.024089\n",
      "Iteration: 3937, Loss: 0.024083\n",
      "Iteration: 3938, Loss: 0.024082\n",
      "Iteration: 3939, Loss: 0.024089\n",
      "Iteration: 3940, Loss: 0.024080\n",
      "Iteration: 3941, Loss: 0.024079\n",
      "Iteration: 3942, Loss: 0.024078\n",
      "Iteration: 3943, Loss: 0.024076\n",
      "Iteration: 3944, Loss: 0.024072\n",
      "Iteration: 3945, Loss: 0.024074\n",
      "Iteration: 3946, Loss: 0.024070\n",
      "Iteration: 3947, Loss: 0.024062\n",
      "Iteration: 3948, Loss: 0.024063\n",
      "Iteration: 3949, Loss: 0.024058\n",
      "Iteration: 3950, Loss: 0.024053\n",
      "Iteration: 3951, Loss: 0.024051\n",
      "Iteration: 3952, Loss: 0.024051\n",
      "Iteration: 3953, Loss: 0.024050\n",
      "Iteration: 3954, Loss: 0.024049\n",
      "Iteration: 3955, Loss: 0.024046\n",
      "Iteration: 3956, Loss: 0.024043\n",
      "Iteration: 3957, Loss: 0.024039\n",
      "Iteration: 3958, Loss: 0.024059\n",
      "Iteration: 3959, Loss: 0.024037\n",
      "Iteration: 3960, Loss: 0.024034\n",
      "Iteration: 3961, Loss: 0.024032\n",
      "Iteration: 3962, Loss: 0.024029\n",
      "Iteration: 3963, Loss: 0.024027\n",
      "Iteration: 3964, Loss: 0.024023\n",
      "Iteration: 3965, Loss: 0.024025\n",
      "Iteration: 3966, Loss: 0.024021\n",
      "Iteration: 3967, Loss: 0.024016\n",
      "Iteration: 3968, Loss: 0.024013\n",
      "Iteration: 3969, Loss: 0.024007\n",
      "Iteration: 3970, Loss: 0.024041\n",
      "Iteration: 3971, Loss: 0.024005\n",
      "Iteration: 3972, Loss: 0.024003\n",
      "Iteration: 3973, Loss: 0.023997\n",
      "Iteration: 3974, Loss: 0.023996\n",
      "Iteration: 3975, Loss: 0.023995\n",
      "Iteration: 3976, Loss: 0.023993\n",
      "Iteration: 3977, Loss: 0.023992\n",
      "Iteration: 3978, Loss: 0.023990\n",
      "Iteration: 3979, Loss: 0.023988\n",
      "Iteration: 3980, Loss: 0.023986\n",
      "Iteration: 3981, Loss: 0.023984\n",
      "Iteration: 3982, Loss: 0.023981\n",
      "Iteration: 3983, Loss: 0.023979\n",
      "Iteration: 3984, Loss: 0.023977\n",
      "Iteration: 3985, Loss: 0.023976\n",
      "Iteration: 3986, Loss: 0.023976\n",
      "Iteration: 3987, Loss: 0.023975\n",
      "Iteration: 3988, Loss: 0.023978\n",
      "Iteration: 3989, Loss: 0.023974\n",
      "Iteration: 3990, Loss: 0.023973\n",
      "Iteration: 3991, Loss: 0.023970\n",
      "Iteration: 3992, Loss: 0.023969\n",
      "Iteration: 3993, Loss: 0.023966\n",
      "Iteration: 3994, Loss: 0.023961\n",
      "Iteration: 3995, Loss: 0.023957\n",
      "Iteration: 3996, Loss: 0.023953\n",
      "Iteration: 3997, Loss: 0.023951\n",
      "Iteration: 3998, Loss: 0.023949\n",
      "Iteration: 3999, Loss: 0.023948\n",
      "Iteration: 4000, Loss: 0.023947\n",
      "Iteration: 4001, Loss: 0.023946\n",
      "Iteration: 4002, Loss: 0.023945\n",
      "Iteration: 4003, Loss: 0.023941\n",
      "Iteration: 4004, Loss: 0.024036\n",
      "Iteration: 4005, Loss: 0.023940\n",
      "Iteration: 4006, Loss: 0.023936\n",
      "Iteration: 4007, Loss: 0.023933\n",
      "Iteration: 4008, Loss: 0.023929\n",
      "Iteration: 4009, Loss: 0.023927\n",
      "Iteration: 4010, Loss: 0.023924\n",
      "Iteration: 4011, Loss: 0.023921\n",
      "Iteration: 4012, Loss: 0.023917\n",
      "Iteration: 4013, Loss: 0.023913\n",
      "Iteration: 4014, Loss: 0.023914\n",
      "Iteration: 4015, Loss: 0.023911\n",
      "Iteration: 4016, Loss: 0.023908\n",
      "Iteration: 4017, Loss: 0.023928\n",
      "Iteration: 4018, Loss: 0.023906\n",
      "Iteration: 4019, Loss: 0.023903\n",
      "Iteration: 4020, Loss: 0.023900\n",
      "Iteration: 4021, Loss: 0.023897\n",
      "Iteration: 4022, Loss: 0.023893\n",
      "Iteration: 4023, Loss: 0.023891\n",
      "Iteration: 4024, Loss: 0.023890\n",
      "Iteration: 4025, Loss: 0.023887\n",
      "Iteration: 4026, Loss: 0.023884\n",
      "Iteration: 4027, Loss: 0.023881\n",
      "Iteration: 4028, Loss: 0.023879\n",
      "Iteration: 4029, Loss: 0.023878\n",
      "Iteration: 4030, Loss: 0.023877\n",
      "Iteration: 4031, Loss: 0.023876\n",
      "Iteration: 4032, Loss: 0.023874\n",
      "Iteration: 4033, Loss: 0.023872\n",
      "Iteration: 4034, Loss: 0.023872\n",
      "Iteration: 4035, Loss: 0.023871\n",
      "Iteration: 4036, Loss: 0.023870\n",
      "Iteration: 4037, Loss: 0.023868\n",
      "Iteration: 4038, Loss: 0.023867\n",
      "Iteration: 4039, Loss: 0.023866\n",
      "Iteration: 4040, Loss: 0.023865\n",
      "Iteration: 4041, Loss: 0.023864\n",
      "Iteration: 4042, Loss: 0.023862\n",
      "Iteration: 4043, Loss: 0.023862\n",
      "Iteration: 4044, Loss: 0.023861\n",
      "Iteration: 4045, Loss: 0.023860\n",
      "Iteration: 4046, Loss: 0.023859\n",
      "Iteration: 4047, Loss: 0.023858\n",
      "Iteration: 4048, Loss: 0.023857\n",
      "Iteration: 4049, Loss: 0.023856\n",
      "Iteration: 4050, Loss: 0.023855\n",
      "Iteration: 4051, Loss: 0.023852\n",
      "Iteration: 4052, Loss: 0.023855\n",
      "Iteration: 4053, Loss: 0.023851\n",
      "Iteration: 4054, Loss: 0.023849\n",
      "Iteration: 4055, Loss: 0.023848\n",
      "Iteration: 4056, Loss: 0.023846\n",
      "Iteration: 4057, Loss: 0.023844\n",
      "Iteration: 4058, Loss: 0.023841\n",
      "Iteration: 4059, Loss: 0.023837\n",
      "Iteration: 4060, Loss: 0.023833\n",
      "Iteration: 4061, Loss: 0.023830\n",
      "Iteration: 4062, Loss: 0.023827\n",
      "Iteration: 4063, Loss: 0.023823\n",
      "Iteration: 4064, Loss: 0.023819\n",
      "Iteration: 4065, Loss: 0.023815\n",
      "Iteration: 4066, Loss: 0.023812\n",
      "Iteration: 4067, Loss: 0.023811\n",
      "Iteration: 4068, Loss: 0.023810\n",
      "Iteration: 4069, Loss: 0.023809\n",
      "Iteration: 4070, Loss: 0.023808\n",
      "Iteration: 4071, Loss: 0.023806\n",
      "Iteration: 4072, Loss: 0.023805\n",
      "Iteration: 4073, Loss: 0.023914\n",
      "Iteration: 4074, Loss: 0.023804\n",
      "Iteration: 4075, Loss: 0.023802\n",
      "Iteration: 4076, Loss: 0.023800\n",
      "Iteration: 4077, Loss: 0.023799\n",
      "Iteration: 4078, Loss: 0.023798\n",
      "Iteration: 4079, Loss: 0.023798\n",
      "Iteration: 4080, Loss: 0.023796\n",
      "Iteration: 4081, Loss: 0.023796\n",
      "Iteration: 4082, Loss: 0.023795\n",
      "Iteration: 4083, Loss: 0.023793\n",
      "Iteration: 4084, Loss: 0.023790\n",
      "Iteration: 4085, Loss: 0.023789\n",
      "Iteration: 4086, Loss: 0.023787\n",
      "Iteration: 4087, Loss: 0.023786\n",
      "Iteration: 4088, Loss: 0.023784\n",
      "Iteration: 4089, Loss: 0.023798\n",
      "Iteration: 4090, Loss: 0.023783\n",
      "Iteration: 4091, Loss: 0.023781\n",
      "Iteration: 4092, Loss: 0.023780\n",
      "Iteration: 4093, Loss: 0.023779\n",
      "Iteration: 4094, Loss: 0.023777\n",
      "Iteration: 4095, Loss: 0.023778\n",
      "Iteration: 4096, Loss: 0.023776\n",
      "Iteration: 4097, Loss: 0.023773\n",
      "Iteration: 4098, Loss: 0.023771\n",
      "Iteration: 4099, Loss: 0.023769\n",
      "Iteration: 4100, Loss: 0.023768\n",
      "Iteration: 4101, Loss: 0.023765\n",
      "Iteration: 4102, Loss: 0.023762\n",
      "Iteration: 4103, Loss: 0.023758\n",
      "Iteration: 4104, Loss: 0.023757\n",
      "Iteration: 4105, Loss: 0.023753\n",
      "Iteration: 4106, Loss: 0.023749\n",
      "Iteration: 4107, Loss: 0.023747\n",
      "Iteration: 4108, Loss: 0.023746\n",
      "Iteration: 4109, Loss: 0.023745\n",
      "Iteration: 4110, Loss: 0.023742\n",
      "Iteration: 4111, Loss: 0.023741\n",
      "Iteration: 4112, Loss: 0.023738\n",
      "Iteration: 4113, Loss: 0.023735\n",
      "Iteration: 4114, Loss: 0.023733\n",
      "Iteration: 4115, Loss: 0.023731\n",
      "Iteration: 4116, Loss: 0.023729\n",
      "Iteration: 4117, Loss: 0.023780\n",
      "Iteration: 4118, Loss: 0.023727\n",
      "Iteration: 4119, Loss: 0.023724\n",
      "Iteration: 4120, Loss: 0.023720\n",
      "Iteration: 4121, Loss: 0.023718\n",
      "Iteration: 4122, Loss: 0.023716\n",
      "Iteration: 4123, Loss: 0.023714\n",
      "Iteration: 4124, Loss: 0.023712\n",
      "Iteration: 4125, Loss: 0.023708\n",
      "Iteration: 4126, Loss: 0.023723\n",
      "Iteration: 4127, Loss: 0.023708\n",
      "Iteration: 4128, Loss: 0.023707\n",
      "Iteration: 4129, Loss: 0.023706\n",
      "Iteration: 4130, Loss: 0.023704\n",
      "Iteration: 4131, Loss: 0.023703\n",
      "Iteration: 4132, Loss: 0.023701\n",
      "Iteration: 4133, Loss: 0.023705\n",
      "Iteration: 4134, Loss: 0.023701\n",
      "Iteration: 4135, Loss: 0.023700\n",
      "Iteration: 4136, Loss: 0.023698\n",
      "Iteration: 4137, Loss: 0.023695\n",
      "Iteration: 4138, Loss: 0.023686\n",
      "Iteration: 4139, Loss: 0.023680\n",
      "Iteration: 4140, Loss: 0.023669\n",
      "Iteration: 4141, Loss: 0.023668\n",
      "Iteration: 4142, Loss: 0.023656\n",
      "Iteration: 4143, Loss: 0.023650\n",
      "Iteration: 4144, Loss: 0.023645\n",
      "Iteration: 4145, Loss: 0.023642\n",
      "Iteration: 4146, Loss: 0.023641\n",
      "Iteration: 4147, Loss: 0.023640\n",
      "Iteration: 4148, Loss: 0.023636\n",
      "Iteration: 4149, Loss: 0.023635\n",
      "Iteration: 4150, Loss: 0.023632\n",
      "Iteration: 4151, Loss: 0.023629\n",
      "Iteration: 4152, Loss: 0.023626\n",
      "Iteration: 4153, Loss: 0.023622\n",
      "Iteration: 4154, Loss: 0.023619\n",
      "Iteration: 4155, Loss: 0.023615\n",
      "Iteration: 4156, Loss: 0.023613\n",
      "Iteration: 4157, Loss: 0.023612\n",
      "Iteration: 4158, Loss: 0.023611\n",
      "Iteration: 4159, Loss: 0.023611\n",
      "Iteration: 4160, Loss: 0.023609\n",
      "Iteration: 4161, Loss: 0.023606\n",
      "Iteration: 4162, Loss: 0.023604\n",
      "Iteration: 4163, Loss: 0.023608\n",
      "Iteration: 4164, Loss: 0.023602\n",
      "Iteration: 4165, Loss: 0.023600\n",
      "Iteration: 4166, Loss: 0.023598\n",
      "Iteration: 4167, Loss: 0.023596\n",
      "Iteration: 4168, Loss: 0.023595\n",
      "Iteration: 4169, Loss: 0.023598\n",
      "Iteration: 4170, Loss: 0.023595\n",
      "Iteration: 4171, Loss: 0.023594\n",
      "Iteration: 4172, Loss: 0.023591\n",
      "Iteration: 4173, Loss: 0.023589\n",
      "Iteration: 4174, Loss: 0.023587\n",
      "Iteration: 4175, Loss: 0.023586\n",
      "Iteration: 4176, Loss: 0.023583\n",
      "Iteration: 4177, Loss: 0.023581\n",
      "Iteration: 4178, Loss: 0.023618\n",
      "Iteration: 4179, Loss: 0.023581\n",
      "Iteration: 4180, Loss: 0.023578\n",
      "Iteration: 4181, Loss: 0.023575\n",
      "Iteration: 4182, Loss: 0.023572\n",
      "Iteration: 4183, Loss: 0.023569\n",
      "Iteration: 4184, Loss: 0.023566\n",
      "Iteration: 4185, Loss: 0.023563\n",
      "Iteration: 4186, Loss: 0.023560\n",
      "Iteration: 4187, Loss: 0.023558\n",
      "Iteration: 4188, Loss: 0.023554\n",
      "Iteration: 4189, Loss: 0.023551\n",
      "Iteration: 4190, Loss: 0.023545\n",
      "Iteration: 4191, Loss: 0.023540\n",
      "Iteration: 4192, Loss: 0.023538\n",
      "Iteration: 4193, Loss: 0.023534\n",
      "Iteration: 4194, Loss: 0.023532\n",
      "Iteration: 4195, Loss: 0.023529\n",
      "Iteration: 4196, Loss: 0.023526\n",
      "Iteration: 4197, Loss: 0.023611\n",
      "Iteration: 4198, Loss: 0.023526\n",
      "Iteration: 4199, Loss: 0.023524\n",
      "Iteration: 4200, Loss: 0.023521\n",
      "Iteration: 4201, Loss: 0.023518\n",
      "Iteration: 4202, Loss: 0.023516\n",
      "Iteration: 4203, Loss: 0.023513\n",
      "Iteration: 4204, Loss: 0.023510\n",
      "Iteration: 4205, Loss: 0.023507\n",
      "Iteration: 4206, Loss: 0.023549\n",
      "Iteration: 4207, Loss: 0.023504\n",
      "Iteration: 4208, Loss: 0.023501\n",
      "Iteration: 4209, Loss: 0.023495\n",
      "Iteration: 4210, Loss: 0.023492\n",
      "Iteration: 4211, Loss: 0.023487\n",
      "Iteration: 4212, Loss: 0.023481\n",
      "Iteration: 4213, Loss: 0.023478\n",
      "Iteration: 4214, Loss: 0.023470\n",
      "Iteration: 4215, Loss: 0.023464\n",
      "Iteration: 4216, Loss: 0.023456\n",
      "Iteration: 4217, Loss: 0.023450\n",
      "Iteration: 4218, Loss: 0.023447\n",
      "Iteration: 4219, Loss: 0.023445\n",
      "Iteration: 4220, Loss: 0.023442\n",
      "Iteration: 4221, Loss: 0.023437\n",
      "Iteration: 4222, Loss: 0.023473\n",
      "Iteration: 4223, Loss: 0.023435\n",
      "Iteration: 4224, Loss: 0.023430\n",
      "Iteration: 4225, Loss: 0.023425\n",
      "Iteration: 4226, Loss: 0.023454\n",
      "Iteration: 4227, Loss: 0.023424\n",
      "Iteration: 4228, Loss: 0.023421\n",
      "Iteration: 4229, Loss: 0.023416\n",
      "Iteration: 4230, Loss: 0.023412\n",
      "Iteration: 4231, Loss: 0.023406\n",
      "Iteration: 4232, Loss: 0.023400\n",
      "Iteration: 4233, Loss: 0.023391\n",
      "Iteration: 4234, Loss: 0.023384\n",
      "Iteration: 4235, Loss: 0.023463\n",
      "Iteration: 4236, Loss: 0.023381\n",
      "Iteration: 4237, Loss: 0.023377\n",
      "Iteration: 4238, Loss: 0.023371\n",
      "Iteration: 4239, Loss: 0.023367\n",
      "Iteration: 4240, Loss: 0.023361\n",
      "Iteration: 4241, Loss: 0.023357\n",
      "Iteration: 4242, Loss: 0.023354\n",
      "Iteration: 4243, Loss: 0.023361\n",
      "Iteration: 4244, Loss: 0.023353\n",
      "Iteration: 4245, Loss: 0.023349\n",
      "Iteration: 4246, Loss: 0.023346\n",
      "Iteration: 4247, Loss: 0.023343\n",
      "Iteration: 4248, Loss: 0.023341\n",
      "Iteration: 4249, Loss: 0.023337\n",
      "Iteration: 4250, Loss: 0.023333\n",
      "Iteration: 4251, Loss: 0.023331\n",
      "Iteration: 4252, Loss: 0.023326\n",
      "Iteration: 4253, Loss: 0.023324\n",
      "Iteration: 4254, Loss: 0.023320\n",
      "Iteration: 4255, Loss: 0.024720\n",
      "Iteration: 4256, Loss: 0.023318\n",
      "Iteration: 4257, Loss: 0.023314\n",
      "Iteration: 4258, Loss: 0.023309\n",
      "Iteration: 4259, Loss: 0.023304\n",
      "Iteration: 4260, Loss: 0.023299\n",
      "Iteration: 4261, Loss: 0.023294\n",
      "Iteration: 4262, Loss: 0.023287\n",
      "Iteration: 4263, Loss: 0.023279\n",
      "Iteration: 4264, Loss: 0.023277\n",
      "Iteration: 4265, Loss: 0.023272\n",
      "Iteration: 4266, Loss: 0.023270\n",
      "Iteration: 4267, Loss: 0.023262\n",
      "Iteration: 4268, Loss: 0.023256\n",
      "Iteration: 4269, Loss: 0.023250\n",
      "Iteration: 4270, Loss: 0.023258\n",
      "Iteration: 4271, Loss: 0.023248\n",
      "Iteration: 4272, Loss: 0.023246\n",
      "Iteration: 4273, Loss: 0.023244\n",
      "Iteration: 4274, Loss: 0.023241\n",
      "Iteration: 4275, Loss: 0.023240\n",
      "Iteration: 4276, Loss: 0.023238\n",
      "Iteration: 4277, Loss: 0.023234\n",
      "Iteration: 4278, Loss: 0.023229\n",
      "Iteration: 4279, Loss: 0.023228\n",
      "Iteration: 4280, Loss: 0.023224\n",
      "Iteration: 4281, Loss: 0.023223\n",
      "Iteration: 4282, Loss: 0.023220\n",
      "Iteration: 4283, Loss: 0.023218\n",
      "Iteration: 4284, Loss: 0.023217\n",
      "Iteration: 4285, Loss: 0.023214\n",
      "Iteration: 4286, Loss: 0.023212\n",
      "Iteration: 4287, Loss: 0.023209\n",
      "Iteration: 4288, Loss: 0.023207\n",
      "Iteration: 4289, Loss: 0.023204\n",
      "Iteration: 4290, Loss: 0.023203\n",
      "Iteration: 4291, Loss: 0.023201\n",
      "Iteration: 4292, Loss: 0.023198\n",
      "Iteration: 4293, Loss: 0.023191\n",
      "Iteration: 4294, Loss: 0.023184\n",
      "Iteration: 4295, Loss: 0.023180\n",
      "Iteration: 4296, Loss: 0.023178\n",
      "Iteration: 4297, Loss: 0.023176\n",
      "Iteration: 4298, Loss: 0.023173\n",
      "Iteration: 4299, Loss: 0.023171\n",
      "Iteration: 4300, Loss: 0.023169\n",
      "Iteration: 4301, Loss: 0.023168\n",
      "Iteration: 4302, Loss: 0.023166\n",
      "Iteration: 4303, Loss: 0.023163\n",
      "Iteration: 4304, Loss: 0.023161\n",
      "Iteration: 4305, Loss: 0.023159\n",
      "Iteration: 4306, Loss: 0.023158\n",
      "Iteration: 4307, Loss: 0.023156\n",
      "Iteration: 4308, Loss: 0.023154\n",
      "Iteration: 4309, Loss: 0.023149\n",
      "Iteration: 4310, Loss: 0.023145\n",
      "Iteration: 4311, Loss: 0.023139\n",
      "Iteration: 4312, Loss: 0.023918\n",
      "Iteration: 4313, Loss: 0.023137\n",
      "Iteration: 4314, Loss: 0.023129\n",
      "Iteration: 4315, Loss: 0.023118\n",
      "Iteration: 4316, Loss: 0.023111\n",
      "Iteration: 4317, Loss: 0.023104\n",
      "Iteration: 4318, Loss: 0.023098\n",
      "Iteration: 4319, Loss: 0.023095\n",
      "Iteration: 4320, Loss: 0.023092\n",
      "Iteration: 4321, Loss: 0.023089\n",
      "Iteration: 4322, Loss: 0.023086\n",
      "Iteration: 4323, Loss: 0.023079\n",
      "Iteration: 4324, Loss: 0.023072\n",
      "Iteration: 4325, Loss: 0.023065\n",
      "Iteration: 4326, Loss: 0.023056\n",
      "Iteration: 4327, Loss: 0.023053\n",
      "Iteration: 4328, Loss: 0.023047\n",
      "Iteration: 4329, Loss: 0.023050\n",
      "Iteration: 4330, Loss: 0.023043\n",
      "Iteration: 4331, Loss: 0.023040\n",
      "Iteration: 4332, Loss: 0.023037\n",
      "Iteration: 4333, Loss: 0.023035\n",
      "Iteration: 4334, Loss: 0.023032\n",
      "Iteration: 4335, Loss: 0.023029\n",
      "Iteration: 4336, Loss: 0.023026\n",
      "Iteration: 4337, Loss: 0.023023\n",
      "Iteration: 4338, Loss: 0.023019\n",
      "Iteration: 4339, Loss: 0.023012\n",
      "Iteration: 4340, Loss: 0.023009\n",
      "Iteration: 4341, Loss: 0.023007\n",
      "Iteration: 4342, Loss: 0.023006\n",
      "Iteration: 4343, Loss: 0.023005\n",
      "Iteration: 4344, Loss: 0.023004\n",
      "Iteration: 4345, Loss: 0.023004\n",
      "Iteration: 4346, Loss: 0.023002\n",
      "Iteration: 4347, Loss: 0.022999\n",
      "Iteration: 4348, Loss: 0.023006\n",
      "Iteration: 4349, Loss: 0.022998\n",
      "Iteration: 4350, Loss: 0.022995\n",
      "Iteration: 4351, Loss: 0.022993\n",
      "Iteration: 4352, Loss: 0.023012\n",
      "Iteration: 4353, Loss: 0.022992\n",
      "Iteration: 4354, Loss: 0.022988\n",
      "Iteration: 4355, Loss: 0.022985\n",
      "Iteration: 4356, Loss: 0.022981\n",
      "Iteration: 4357, Loss: 0.022978\n",
      "Iteration: 4358, Loss: 0.022977\n",
      "Iteration: 4359, Loss: 0.022974\n",
      "Iteration: 4360, Loss: 0.022971\n",
      "Iteration: 4361, Loss: 0.022968\n",
      "Iteration: 4362, Loss: 0.022967\n",
      "Iteration: 4363, Loss: 0.022962\n",
      "Iteration: 4364, Loss: 0.022959\n",
      "Iteration: 4365, Loss: 0.022956\n",
      "Iteration: 4366, Loss: 0.022953\n",
      "Iteration: 4367, Loss: 0.022951\n",
      "Iteration: 4368, Loss: 0.022949\n",
      "Iteration: 4369, Loss: 0.022947\n",
      "Iteration: 4370, Loss: 0.022944\n",
      "Iteration: 4371, Loss: 0.022942\n",
      "Iteration: 4372, Loss: 0.022941\n",
      "Iteration: 4373, Loss: 0.022936\n",
      "Iteration: 4374, Loss: 0.022934\n",
      "Iteration: 4375, Loss: 0.022931\n",
      "Iteration: 4376, Loss: 0.022929\n",
      "Iteration: 4377, Loss: 0.022927\n",
      "Iteration: 4378, Loss: 0.022926\n",
      "Iteration: 4379, Loss: 0.022924\n",
      "Iteration: 4380, Loss: 0.022922\n",
      "Iteration: 4381, Loss: 0.022920\n",
      "Iteration: 4382, Loss: 0.022923\n",
      "Iteration: 4383, Loss: 0.022918\n",
      "Iteration: 4384, Loss: 0.022928\n",
      "Iteration: 4385, Loss: 0.022918\n",
      "Iteration: 4386, Loss: 0.022916\n",
      "Iteration: 4387, Loss: 0.022914\n",
      "Iteration: 4388, Loss: 0.022913\n",
      "Iteration: 4389, Loss: 0.022913\n",
      "Iteration: 4390, Loss: 0.022911\n",
      "Iteration: 4391, Loss: 0.022910\n",
      "Iteration: 4392, Loss: 0.022909\n",
      "Iteration: 4393, Loss: 0.022907\n",
      "Iteration: 4394, Loss: 0.022905\n",
      "Iteration: 4395, Loss: 0.022954\n",
      "Iteration: 4396, Loss: 0.022903\n",
      "Iteration: 4397, Loss: 0.022900\n",
      "Iteration: 4398, Loss: 0.022896\n",
      "Iteration: 4399, Loss: 0.022893\n",
      "Iteration: 4400, Loss: 0.022891\n",
      "Iteration: 4401, Loss: 0.022888\n",
      "Iteration: 4402, Loss: 0.022886\n",
      "Iteration: 4403, Loss: 0.022881\n",
      "Iteration: 4404, Loss: 0.022878\n",
      "Iteration: 4405, Loss: 0.022877\n",
      "Iteration: 4406, Loss: 0.022876\n",
      "Iteration: 4407, Loss: 0.022874\n",
      "Iteration: 4408, Loss: 0.022873\n",
      "Iteration: 4409, Loss: 0.022871\n",
      "Iteration: 4410, Loss: 0.022870\n",
      "Iteration: 4411, Loss: 0.022869\n",
      "Iteration: 4412, Loss: 0.022867\n",
      "Iteration: 4413, Loss: 0.022866\n",
      "Iteration: 4414, Loss: 0.022865\n",
      "Iteration: 4415, Loss: 0.022864\n",
      "Iteration: 4416, Loss: 0.022861\n",
      "Iteration: 4417, Loss: 0.022858\n",
      "Iteration: 4418, Loss: 0.022855\n",
      "Iteration: 4419, Loss: 0.022852\n",
      "Iteration: 4420, Loss: 0.022852\n",
      "Iteration: 4421, Loss: 0.022850\n",
      "Iteration: 4422, Loss: 0.022848\n",
      "Iteration: 4423, Loss: 0.022847\n",
      "Iteration: 4424, Loss: 0.022845\n",
      "Iteration: 4425, Loss: 0.022844\n",
      "Iteration: 4426, Loss: 0.022841\n",
      "Iteration: 4427, Loss: 0.022839\n",
      "Iteration: 4428, Loss: 0.022835\n",
      "Iteration: 4429, Loss: 0.022836\n",
      "Iteration: 4430, Loss: 0.022834\n",
      "Iteration: 4431, Loss: 0.022833\n",
      "Iteration: 4432, Loss: 0.022830\n",
      "Iteration: 4433, Loss: 0.022829\n",
      "Iteration: 4434, Loss: 0.022828\n",
      "Iteration: 4435, Loss: 0.022826\n",
      "Iteration: 4436, Loss: 0.022825\n",
      "Iteration: 4437, Loss: 0.022823\n",
      "Iteration: 4438, Loss: 0.022820\n",
      "Iteration: 4439, Loss: 0.022817\n",
      "Iteration: 4440, Loss: 0.022813\n",
      "Iteration: 4441, Loss: 0.022810\n",
      "Iteration: 4442, Loss: 0.022808\n",
      "Iteration: 4443, Loss: 0.022806\n",
      "Iteration: 4444, Loss: 0.022803\n",
      "Iteration: 4445, Loss: 0.022801\n",
      "Iteration: 4446, Loss: 0.022800\n",
      "Iteration: 4447, Loss: 0.022797\n",
      "Iteration: 4448, Loss: 0.022794\n",
      "Iteration: 4449, Loss: 0.022792\n",
      "Iteration: 4450, Loss: 0.022786\n",
      "Iteration: 4451, Loss: 0.022783\n",
      "Iteration: 4452, Loss: 0.022780\n",
      "Iteration: 4453, Loss: 0.022779\n",
      "Iteration: 4454, Loss: 0.022778\n",
      "Iteration: 4455, Loss: 0.022775\n",
      "Iteration: 4456, Loss: 0.022777\n",
      "Iteration: 4457, Loss: 0.022773\n",
      "Iteration: 4458, Loss: 0.022770\n",
      "Iteration: 4459, Loss: 0.022769\n",
      "Iteration: 4460, Loss: 0.022768\n",
      "Iteration: 4461, Loss: 0.022768\n",
      "Iteration: 4462, Loss: 0.022766\n",
      "Iteration: 4463, Loss: 0.022765\n",
      "Iteration: 4464, Loss: 0.022762\n",
      "Iteration: 4465, Loss: 0.022761\n",
      "Iteration: 4466, Loss: 0.022759\n",
      "Iteration: 4467, Loss: 0.022758\n",
      "Iteration: 4468, Loss: 0.022756\n",
      "Iteration: 4469, Loss: 0.022754\n",
      "Iteration: 4470, Loss: 0.022752\n",
      "Iteration: 4471, Loss: 0.022750\n",
      "Iteration: 4472, Loss: 0.022748\n",
      "Iteration: 4473, Loss: 0.022745\n",
      "Iteration: 4474, Loss: 0.022741\n",
      "Iteration: 4475, Loss: 0.022937\n",
      "Iteration: 4476, Loss: 0.022740\n",
      "Iteration: 4477, Loss: 0.022736\n",
      "Iteration: 4478, Loss: 0.022733\n",
      "Iteration: 4479, Loss: 0.022732\n",
      "Iteration: 4480, Loss: 0.022730\n",
      "Iteration: 4481, Loss: 0.022729\n",
      "Iteration: 4482, Loss: 0.022726\n",
      "Iteration: 4483, Loss: 0.022725\n",
      "Iteration: 4484, Loss: 0.022725\n",
      "Iteration: 4485, Loss: 0.022723\n",
      "Iteration: 4486, Loss: 0.022722\n",
      "Iteration: 4487, Loss: 0.022720\n",
      "Iteration: 4488, Loss: 0.022720\n",
      "Iteration: 4489, Loss: 0.022718\n",
      "Iteration: 4490, Loss: 0.022717\n",
      "Iteration: 4491, Loss: 0.022715\n",
      "Iteration: 4492, Loss: 0.022712\n",
      "Iteration: 4493, Loss: 0.022710\n",
      "Iteration: 4494, Loss: 0.022709\n",
      "Iteration: 4495, Loss: 0.022706\n",
      "Iteration: 4496, Loss: 0.022701\n",
      "Iteration: 4497, Loss: 0.022698\n",
      "Iteration: 4498, Loss: 0.022696\n",
      "Iteration: 4499, Loss: 0.022694\n",
      "Iteration: 4500, Loss: 0.022693\n",
      "Iteration: 4501, Loss: 0.022692\n",
      "Iteration: 4502, Loss: 0.022691\n",
      "Iteration: 4503, Loss: 0.022689\n",
      "Iteration: 4504, Loss: 0.022687\n",
      "Iteration: 4505, Loss: 0.022686\n",
      "Iteration: 4506, Loss: 0.022683\n",
      "Iteration: 4507, Loss: 0.022682\n",
      "Iteration: 4508, Loss: 0.022681\n",
      "Iteration: 4509, Loss: 0.022680\n",
      "Iteration: 4510, Loss: 0.022679\n",
      "Iteration: 4511, Loss: 0.022677\n",
      "Iteration: 4512, Loss: 0.022677\n",
      "Iteration: 4513, Loss: 0.022676\n",
      "Iteration: 4514, Loss: 0.022677\n",
      "Iteration: 4515, Loss: 0.022674\n",
      "Iteration: 4516, Loss: 0.022670\n",
      "Iteration: 4517, Loss: 0.022666\n",
      "Iteration: 4518, Loss: 0.022665\n",
      "Iteration: 4519, Loss: 0.022665\n",
      "Iteration: 4520, Loss: 0.022664\n",
      "Iteration: 4521, Loss: 0.022664\n",
      "Iteration: 4522, Loss: 0.022664\n",
      "Iteration: 4523, Loss: 0.022663\n",
      "Iteration: 4524, Loss: 0.022668\n",
      "Iteration: 4525, Loss: 0.022663\n",
      "Iteration: 4526, Loss: 0.022661\n",
      "Iteration: 4527, Loss: 0.022659\n",
      "Iteration: 4528, Loss: 0.022663\n",
      "Iteration: 4529, Loss: 0.022657\n",
      "Iteration: 4530, Loss: 0.022654\n",
      "Iteration: 4531, Loss: 0.022651\n",
      "Iteration: 4532, Loss: 0.022649\n",
      "Iteration: 4533, Loss: 0.022648\n",
      "Iteration: 4534, Loss: 0.022646\n",
      "Iteration: 4535, Loss: 0.022643\n",
      "Iteration: 4536, Loss: 0.022640\n",
      "Iteration: 4537, Loss: 0.022635\n",
      "Iteration: 4538, Loss: 0.022638\n",
      "Iteration: 4539, Loss: 0.022631\n",
      "Iteration: 4540, Loss: 0.022627\n",
      "Iteration: 4541, Loss: 0.022624\n",
      "Iteration: 4542, Loss: 0.022623\n",
      "Iteration: 4543, Loss: 0.022620\n",
      "Iteration: 4544, Loss: 0.022616\n",
      "Iteration: 4545, Loss: 0.022613\n",
      "Iteration: 4546, Loss: 0.022610\n",
      "Iteration: 4547, Loss: 0.022608\n",
      "Iteration: 4548, Loss: 0.022604\n",
      "Iteration: 4549, Loss: 0.022602\n",
      "Iteration: 4550, Loss: 0.022601\n",
      "Iteration: 4551, Loss: 0.022601\n",
      "Iteration: 4552, Loss: 0.022600\n",
      "Iteration: 4553, Loss: 0.022599\n",
      "Iteration: 4554, Loss: 0.022598\n",
      "Iteration: 4555, Loss: 0.022602\n",
      "Iteration: 4556, Loss: 0.022597\n",
      "Iteration: 4557, Loss: 0.022595\n",
      "Iteration: 4558, Loss: 0.022593\n",
      "Iteration: 4559, Loss: 0.022592\n",
      "Iteration: 4560, Loss: 0.022589\n",
      "Iteration: 4561, Loss: 0.022587\n",
      "Iteration: 4562, Loss: 0.022585\n",
      "Iteration: 4563, Loss: 0.022584\n",
      "Iteration: 4564, Loss: 0.022585\n",
      "Iteration: 4565, Loss: 0.022583\n",
      "Iteration: 4566, Loss: 0.022582\n",
      "Iteration: 4567, Loss: 0.022581\n",
      "Iteration: 4568, Loss: 0.022580\n",
      "Iteration: 4569, Loss: 0.022578\n",
      "Iteration: 4570, Loss: 0.022577\n",
      "Iteration: 4571, Loss: 0.022575\n",
      "Iteration: 4572, Loss: 0.022573\n",
      "Iteration: 4573, Loss: 0.022570\n",
      "Iteration: 4574, Loss: 0.022567\n",
      "Iteration: 4575, Loss: 0.022563\n",
      "Iteration: 4576, Loss: 0.022561\n",
      "Iteration: 4577, Loss: 0.022560\n",
      "Iteration: 4578, Loss: 0.022557\n",
      "Iteration: 4579, Loss: 0.022557\n",
      "Iteration: 4580, Loss: 0.022556\n",
      "Iteration: 4581, Loss: 0.022555\n",
      "Iteration: 4582, Loss: 0.022553\n",
      "Iteration: 4583, Loss: 0.022552\n",
      "Iteration: 4584, Loss: 0.022550\n",
      "Iteration: 4585, Loss: 0.022548\n",
      "Iteration: 4586, Loss: 0.022560\n",
      "Iteration: 4587, Loss: 0.022547\n",
      "Iteration: 4588, Loss: 0.022546\n",
      "Iteration: 4589, Loss: 0.022545\n",
      "Iteration: 4590, Loss: 0.022544\n",
      "Iteration: 4591, Loss: 0.022541\n",
      "Iteration: 4592, Loss: 0.022541\n",
      "Iteration: 4593, Loss: 0.022538\n",
      "Iteration: 4594, Loss: 0.022537\n",
      "Iteration: 4595, Loss: 0.022536\n",
      "Iteration: 4596, Loss: 0.022535\n",
      "Iteration: 4597, Loss: 0.022540\n",
      "Iteration: 4598, Loss: 0.022534\n",
      "Iteration: 4599, Loss: 0.022533\n",
      "Iteration: 4600, Loss: 0.022531\n",
      "Iteration: 4601, Loss: 0.022529\n",
      "Iteration: 4602, Loss: 0.022527\n",
      "Iteration: 4603, Loss: 0.022526\n",
      "Iteration: 4604, Loss: 0.022523\n",
      "Iteration: 4605, Loss: 0.022522\n",
      "Iteration: 4606, Loss: 0.022520\n",
      "Iteration: 4607, Loss: 0.022517\n",
      "Iteration: 4608, Loss: 0.022516\n",
      "Iteration: 4609, Loss: 0.022513\n",
      "Iteration: 4610, Loss: 0.022511\n",
      "Iteration: 4611, Loss: 0.022509\n",
      "Iteration: 4612, Loss: 0.022508\n",
      "Iteration: 4613, Loss: 0.022507\n",
      "Iteration: 4614, Loss: 0.022506\n",
      "Iteration: 4615, Loss: 0.022506\n",
      "Iteration: 4616, Loss: 0.022505\n",
      "Iteration: 4617, Loss: 0.022504\n",
      "Iteration: 4618, Loss: 0.022506\n",
      "Iteration: 4619, Loss: 0.022503\n",
      "Iteration: 4620, Loss: 0.022501\n",
      "Iteration: 4621, Loss: 0.022500\n",
      "Iteration: 4622, Loss: 0.022499\n",
      "Iteration: 4623, Loss: 0.022498\n",
      "Iteration: 4624, Loss: 0.022496\n",
      "Iteration: 4625, Loss: 0.022495\n",
      "Iteration: 4626, Loss: 0.022493\n",
      "Iteration: 4627, Loss: 0.022491\n",
      "Iteration: 4628, Loss: 0.022487\n",
      "Iteration: 4629, Loss: 0.022485\n",
      "Iteration: 4630, Loss: 0.022489\n",
      "Iteration: 4631, Loss: 0.022484\n",
      "Iteration: 4632, Loss: 0.022483\n",
      "Iteration: 4633, Loss: 0.022482\n",
      "Iteration: 4634, Loss: 0.022480\n",
      "Iteration: 4635, Loss: 0.022513\n",
      "Iteration: 4636, Loss: 0.022480\n",
      "Iteration: 4637, Loss: 0.022478\n",
      "Iteration: 4638, Loss: 0.022476\n",
      "Iteration: 4639, Loss: 0.022474\n",
      "Iteration: 4640, Loss: 0.022473\n",
      "Iteration: 4641, Loss: 0.022469\n",
      "Iteration: 4642, Loss: 0.022466\n",
      "Iteration: 4643, Loss: 0.022463\n",
      "Iteration: 4644, Loss: 0.022461\n",
      "Iteration: 4645, Loss: 0.022459\n",
      "Iteration: 4646, Loss: 0.022458\n",
      "Iteration: 4647, Loss: 0.022456\n",
      "Iteration: 4648, Loss: 0.022454\n",
      "Iteration: 4649, Loss: 0.022452\n",
      "Iteration: 4650, Loss: 0.022450\n",
      "Iteration: 4651, Loss: 0.022447\n",
      "Iteration: 4652, Loss: 0.022445\n",
      "Iteration: 4653, Loss: 0.022446\n",
      "Iteration: 4654, Loss: 0.022445\n",
      "Iteration: 4655, Loss: 0.022444\n",
      "Iteration: 4656, Loss: 0.022442\n",
      "Iteration: 4657, Loss: 0.022440\n",
      "Iteration: 4658, Loss: 0.022438\n",
      "Iteration: 4659, Loss: 0.022437\n",
      "Iteration: 4660, Loss: 0.022435\n",
      "Iteration: 4661, Loss: 0.022434\n",
      "Iteration: 4662, Loss: 0.022431\n",
      "Iteration: 4663, Loss: 0.022429\n",
      "Iteration: 4664, Loss: 0.022426\n",
      "Iteration: 4665, Loss: 0.022424\n",
      "Iteration: 4666, Loss: 0.022422\n",
      "Iteration: 4667, Loss: 0.022421\n",
      "Iteration: 4668, Loss: 0.022417\n",
      "Iteration: 4669, Loss: 0.022438\n",
      "Iteration: 4670, Loss: 0.022416\n",
      "Iteration: 4671, Loss: 0.022414\n",
      "Iteration: 4672, Loss: 0.022409\n",
      "Iteration: 4673, Loss: 0.022405\n",
      "Iteration: 4674, Loss: 0.022401\n",
      "Iteration: 4675, Loss: 0.022398\n",
      "Iteration: 4676, Loss: 0.022396\n",
      "Iteration: 4677, Loss: 0.022394\n",
      "Iteration: 4678, Loss: 0.022390\n",
      "Iteration: 4679, Loss: 0.022385\n",
      "Iteration: 4680, Loss: 0.022381\n",
      "Iteration: 4681, Loss: 0.022377\n",
      "Iteration: 4682, Loss: 0.022376\n",
      "Iteration: 4683, Loss: 0.022371\n",
      "Iteration: 4684, Loss: 0.022370\n",
      "Iteration: 4685, Loss: 0.022369\n",
      "Iteration: 4686, Loss: 0.022366\n",
      "Iteration: 4687, Loss: 0.022392\n",
      "Iteration: 4688, Loss: 0.022366\n",
      "Iteration: 4689, Loss: 0.022363\n",
      "Iteration: 4690, Loss: 0.022360\n",
      "Iteration: 4691, Loss: 0.022358\n",
      "Iteration: 4692, Loss: 0.022357\n",
      "Iteration: 4693, Loss: 0.022357\n",
      "Iteration: 4694, Loss: 0.022356\n",
      "Iteration: 4695, Loss: 0.022355\n",
      "Iteration: 4696, Loss: 0.022353\n",
      "Iteration: 4697, Loss: 0.022350\n",
      "Iteration: 4698, Loss: 0.022347\n",
      "Iteration: 4699, Loss: 0.022346\n",
      "Iteration: 4700, Loss: 0.022341\n",
      "Iteration: 4701, Loss: 0.022338\n",
      "Iteration: 4702, Loss: 0.022334\n",
      "Iteration: 4703, Loss: 0.022332\n",
      "Iteration: 4704, Loss: 0.022329\n",
      "Iteration: 4705, Loss: 0.022328\n",
      "Iteration: 4706, Loss: 0.022325\n",
      "Iteration: 4707, Loss: 0.022321\n",
      "Iteration: 4708, Loss: 0.022318\n",
      "Iteration: 4709, Loss: 0.022315\n",
      "Iteration: 4710, Loss: 0.022313\n",
      "Iteration: 4711, Loss: 0.022311\n",
      "Iteration: 4712, Loss: 0.022309\n",
      "Iteration: 4713, Loss: 0.022306\n",
      "Iteration: 4714, Loss: 0.022304\n",
      "Iteration: 4715, Loss: 0.022300\n",
      "Iteration: 4716, Loss: 0.022295\n",
      "Iteration: 4717, Loss: 0.022295\n",
      "Iteration: 4718, Loss: 0.022293\n",
      "Iteration: 4719, Loss: 0.022289\n",
      "Iteration: 4720, Loss: 0.022287\n",
      "Iteration: 4721, Loss: 0.022286\n",
      "Iteration: 4722, Loss: 0.022285\n",
      "Iteration: 4723, Loss: 0.022283\n",
      "Iteration: 4724, Loss: 0.022280\n",
      "Iteration: 4725, Loss: 0.022347\n",
      "Iteration: 4726, Loss: 0.022279\n",
      "Iteration: 4727, Loss: 0.022275\n",
      "Iteration: 4728, Loss: 0.022272\n",
      "Iteration: 4729, Loss: 0.022270\n",
      "Iteration: 4730, Loss: 0.022269\n",
      "Iteration: 4731, Loss: 0.022271\n",
      "Iteration: 4732, Loss: 0.022267\n",
      "Iteration: 4733, Loss: 0.022265\n",
      "Iteration: 4734, Loss: 0.022262\n",
      "Iteration: 4735, Loss: 0.022260\n",
      "Iteration: 4736, Loss: 0.022256\n",
      "Iteration: 4737, Loss: 0.022251\n",
      "Iteration: 4738, Loss: 0.022247\n",
      "Iteration: 4739, Loss: 0.022245\n",
      "Iteration: 4740, Loss: 0.022244\n",
      "Iteration: 4741, Loss: 0.022243\n",
      "Iteration: 4742, Loss: 0.022242\n",
      "Iteration: 4743, Loss: 0.022241\n",
      "Iteration: 4744, Loss: 0.022241\n",
      "Iteration: 4745, Loss: 0.022240\n",
      "Iteration: 4746, Loss: 0.022239\n",
      "Iteration: 4747, Loss: 0.022238\n",
      "Iteration: 4748, Loss: 0.022236\n",
      "Iteration: 4749, Loss: 0.022235\n",
      "Iteration: 4750, Loss: 0.022237\n",
      "Iteration: 4751, Loss: 0.022235\n",
      "Iteration: 4752, Loss: 0.022234\n",
      "Iteration: 4753, Loss: 0.022230\n",
      "Iteration: 4754, Loss: 0.022227\n",
      "Iteration: 4755, Loss: 0.022225\n",
      "Iteration: 4756, Loss: 0.022223\n",
      "Iteration: 4757, Loss: 0.022221\n",
      "Iteration: 4758, Loss: 0.022219\n",
      "Iteration: 4759, Loss: 0.022216\n",
      "Iteration: 4760, Loss: 0.022213\n",
      "Iteration: 4761, Loss: 0.022212\n",
      "Iteration: 4762, Loss: 0.022210\n",
      "Iteration: 4763, Loss: 0.022209\n",
      "Iteration: 4764, Loss: 0.022208\n",
      "Iteration: 4765, Loss: 0.022207\n",
      "Iteration: 4766, Loss: 0.022212\n",
      "Iteration: 4767, Loss: 0.022205\n",
      "Iteration: 4768, Loss: 0.022203\n",
      "Iteration: 4769, Loss: 0.022201\n",
      "Iteration: 4770, Loss: 0.022199\n",
      "Iteration: 4771, Loss: 0.022197\n",
      "Iteration: 4772, Loss: 0.022195\n",
      "Iteration: 4773, Loss: 0.022208\n",
      "Iteration: 4774, Loss: 0.022195\n",
      "Iteration: 4775, Loss: 0.022193\n",
      "Iteration: 4776, Loss: 0.022191\n",
      "Iteration: 4777, Loss: 0.022190\n",
      "Iteration: 4778, Loss: 0.022188\n",
      "Iteration: 4779, Loss: 0.022247\n",
      "Iteration: 4780, Loss: 0.022188\n",
      "Iteration: 4781, Loss: 0.022186\n",
      "Iteration: 4782, Loss: 0.022186\n",
      "Iteration: 4783, Loss: 0.022185\n",
      "Iteration: 4784, Loss: 0.022183\n",
      "Iteration: 4785, Loss: 0.022181\n",
      "Iteration: 4786, Loss: 0.022179\n",
      "Iteration: 4787, Loss: 0.022177\n",
      "Iteration: 4788, Loss: 0.022175\n",
      "Iteration: 4789, Loss: 0.022172\n",
      "Iteration: 4790, Loss: 0.022166\n",
      "Iteration: 4791, Loss: 0.022167\n",
      "Iteration: 4792, Loss: 0.022165\n",
      "Iteration: 4793, Loss: 0.022162\n",
      "Iteration: 4794, Loss: 0.022160\n",
      "Iteration: 4795, Loss: 0.022157\n",
      "Iteration: 4796, Loss: 0.022155\n",
      "Iteration: 4797, Loss: 0.022152\n",
      "Iteration: 4798, Loss: 0.022150\n",
      "Iteration: 4799, Loss: 0.022149\n",
      "Iteration: 4800, Loss: 0.022148\n",
      "Iteration: 4801, Loss: 0.022147\n",
      "Iteration: 4802, Loss: 0.022146\n",
      "Iteration: 4803, Loss: 0.022145\n",
      "Iteration: 4804, Loss: 0.022144\n",
      "Iteration: 4805, Loss: 0.022144\n",
      "Iteration: 4806, Loss: 0.022143\n",
      "Iteration: 4807, Loss: 0.022142\n",
      "Iteration: 4808, Loss: 0.022141\n",
      "Iteration: 4809, Loss: 0.022138\n",
      "Iteration: 4810, Loss: 0.022137\n",
      "Iteration: 4811, Loss: 0.022136\n",
      "Iteration: 4812, Loss: 0.022135\n",
      "Iteration: 4813, Loss: 0.022133\n",
      "Iteration: 4814, Loss: 0.022132\n",
      "Iteration: 4815, Loss: 0.022130\n",
      "Iteration: 4816, Loss: 0.022129\n",
      "Iteration: 4817, Loss: 0.022128\n",
      "Iteration: 4818, Loss: 0.022127\n",
      "Iteration: 4819, Loss: 0.022125\n",
      "Iteration: 4820, Loss: 0.022124\n",
      "Iteration: 4821, Loss: 0.022123\n",
      "Iteration: 4822, Loss: 0.022122\n",
      "Iteration: 4823, Loss: 0.022121\n",
      "Iteration: 4824, Loss: 0.022120\n",
      "Iteration: 4825, Loss: 0.022118\n",
      "Iteration: 4826, Loss: 0.022118\n",
      "Iteration: 4827, Loss: 0.022116\n",
      "Iteration: 4828, Loss: 0.022114\n",
      "Iteration: 4829, Loss: 0.022110\n",
      "Iteration: 4830, Loss: 0.022106\n",
      "Iteration: 4831, Loss: 0.022102\n",
      "Iteration: 4832, Loss: 0.022100\n",
      "Iteration: 4833, Loss: 0.022098\n",
      "Iteration: 4834, Loss: 0.022097\n",
      "Iteration: 4835, Loss: 0.022097\n",
      "Iteration: 4836, Loss: 0.022104\n",
      "Iteration: 4837, Loss: 0.022096\n",
      "Iteration: 4838, Loss: 0.022096\n",
      "Iteration: 4839, Loss: 0.022094\n",
      "Iteration: 4840, Loss: 0.022093\n",
      "Iteration: 4841, Loss: 0.022091\n",
      "Iteration: 4842, Loss: 0.022089\n",
      "Iteration: 4843, Loss: 0.022088\n",
      "Iteration: 4844, Loss: 0.022085\n",
      "Iteration: 4845, Loss: 0.022084\n",
      "Iteration: 4846, Loss: 0.022086\n",
      "Iteration: 4847, Loss: 0.022084\n",
      "Iteration: 4848, Loss: 0.022082\n",
      "Iteration: 4849, Loss: 0.022080\n",
      "Iteration: 4850, Loss: 0.022079\n",
      "Iteration: 4851, Loss: 0.022080\n",
      "Iteration: 4852, Loss: 0.022078\n",
      "Iteration: 4853, Loss: 0.022077\n",
      "Iteration: 4854, Loss: 0.022075\n",
      "Iteration: 4855, Loss: 0.022087\n",
      "Iteration: 4856, Loss: 0.022074\n",
      "Iteration: 4857, Loss: 0.022071\n",
      "Iteration: 4858, Loss: 0.022067\n",
      "Iteration: 4859, Loss: 0.022062\n",
      "Iteration: 4860, Loss: 0.022057\n",
      "Iteration: 4861, Loss: 0.022061\n",
      "Iteration: 4862, Loss: 0.022056\n",
      "Iteration: 4863, Loss: 0.022055\n",
      "Iteration: 4864, Loss: 0.022053\n",
      "Iteration: 4865, Loss: 0.022053\n",
      "Iteration: 4866, Loss: 0.022052\n",
      "Iteration: 4867, Loss: 0.022050\n",
      "Iteration: 4868, Loss: 0.022048\n",
      "Iteration: 4869, Loss: 0.022047\n",
      "Iteration: 4870, Loss: 0.022043\n",
      "Iteration: 4871, Loss: 0.022039\n",
      "Iteration: 4872, Loss: 0.022034\n",
      "Iteration: 4873, Loss: 0.022056\n",
      "Iteration: 4874, Loss: 0.022034\n",
      "Iteration: 4875, Loss: 0.022030\n",
      "Iteration: 4876, Loss: 0.022026\n",
      "Iteration: 4877, Loss: 0.022021\n",
      "Iteration: 4878, Loss: 0.022014\n",
      "Iteration: 4879, Loss: 0.022007\n",
      "Iteration: 4880, Loss: 0.022003\n",
      "Iteration: 4881, Loss: 0.021999\n",
      "Iteration: 4882, Loss: 0.021997\n",
      "Iteration: 4883, Loss: 0.021996\n",
      "Iteration: 4884, Loss: 0.021998\n",
      "Iteration: 4885, Loss: 0.021995\n",
      "Iteration: 4886, Loss: 0.021994\n",
      "Iteration: 4887, Loss: 0.021992\n",
      "Iteration: 4888, Loss: 0.021991\n",
      "Iteration: 4889, Loss: 0.021990\n",
      "Iteration: 4890, Loss: 0.021987\n",
      "Iteration: 4891, Loss: 0.021983\n",
      "Iteration: 4892, Loss: 0.021980\n",
      "Iteration: 4893, Loss: 0.021976\n",
      "Iteration: 4894, Loss: 0.021984\n",
      "Iteration: 4895, Loss: 0.021975\n",
      "Iteration: 4896, Loss: 0.021974\n",
      "Iteration: 4897, Loss: 0.021973\n",
      "Iteration: 4898, Loss: 0.021973\n",
      "Iteration: 4899, Loss: 0.021971\n",
      "Iteration: 4900, Loss: 0.021971\n",
      "Iteration: 4901, Loss: 0.021970\n",
      "Iteration: 4902, Loss: 0.021969\n",
      "Iteration: 4903, Loss: 0.021967\n",
      "Iteration: 4904, Loss: 0.021966\n",
      "Iteration: 4905, Loss: 0.021962\n",
      "Iteration: 4906, Loss: 0.021957\n",
      "Iteration: 4907, Loss: 0.021951\n",
      "Iteration: 4908, Loss: 0.021947\n",
      "Iteration: 4909, Loss: 0.021943\n",
      "Iteration: 4910, Loss: 0.021944\n",
      "Iteration: 4911, Loss: 0.021942\n",
      "Iteration: 4912, Loss: 0.021939\n",
      "Iteration: 4913, Loss: 0.021937\n",
      "Iteration: 4914, Loss: 0.021935\n",
      "Iteration: 4915, Loss: 0.021933\n",
      "Iteration: 4916, Loss: 0.021931\n",
      "Iteration: 4917, Loss: 0.021930\n",
      "Iteration: 4918, Loss: 0.021928\n",
      "Iteration: 4919, Loss: 0.021927\n",
      "Iteration: 4920, Loss: 0.021926\n",
      "Iteration: 4921, Loss: 0.021933\n",
      "Iteration: 4922, Loss: 0.021925\n",
      "Iteration: 4923, Loss: 0.021924\n",
      "Iteration: 4924, Loss: 0.021925\n",
      "Iteration: 4925, Loss: 0.021923\n",
      "Iteration: 4926, Loss: 0.021921\n",
      "Iteration: 4927, Loss: 0.021919\n",
      "Iteration: 4928, Loss: 0.021914\n",
      "Iteration: 4929, Loss: 0.021912\n",
      "Iteration: 4930, Loss: 0.021909\n",
      "Iteration: 4931, Loss: 0.021908\n",
      "Iteration: 4932, Loss: 0.021907\n",
      "Iteration: 4933, Loss: 0.021906\n",
      "Iteration: 4934, Loss: 0.021906\n",
      "Iteration: 4935, Loss: 0.021905\n",
      "Iteration: 4936, Loss: 0.021905\n",
      "Iteration: 4937, Loss: 0.021904\n",
      "Iteration: 4938, Loss: 0.021903\n",
      "Iteration: 4939, Loss: 0.021902\n",
      "Iteration: 4940, Loss: 0.021901\n",
      "Iteration: 4941, Loss: 0.021899\n",
      "Iteration: 4942, Loss: 0.021897\n",
      "Iteration: 4943, Loss: 0.021895\n",
      "Iteration: 4944, Loss: 0.021894\n",
      "Iteration: 4945, Loss: 0.021893\n",
      "Iteration: 4946, Loss: 0.021891\n",
      "Iteration: 4947, Loss: 0.021889\n",
      "Iteration: 4948, Loss: 0.021887\n",
      "Iteration: 4949, Loss: 0.021885\n",
      "Iteration: 4950, Loss: 0.021882\n",
      "Iteration: 4951, Loss: 0.021881\n",
      "Iteration: 4952, Loss: 0.021880\n",
      "Iteration: 4953, Loss: 0.021877\n",
      "Iteration: 4954, Loss: 0.021876\n",
      "Iteration: 4955, Loss: 0.021872\n",
      "Iteration: 4956, Loss: 0.021875\n",
      "Iteration: 4957, Loss: 0.021871\n",
      "Iteration: 4958, Loss: 0.021867\n",
      "Iteration: 4959, Loss: 0.021862\n",
      "Iteration: 4960, Loss: 0.021859\n",
      "Iteration: 4961, Loss: 0.021857\n",
      "Iteration: 4962, Loss: 0.021854\n",
      "Iteration: 4963, Loss: 0.021852\n",
      "Iteration: 4964, Loss: 0.021851\n",
      "Iteration: 4965, Loss: 0.021849\n",
      "Iteration: 4966, Loss: 0.021847\n",
      "Iteration: 4967, Loss: 0.021846\n",
      "Iteration: 4968, Loss: 0.021849\n",
      "Iteration: 4969, Loss: 0.021845\n",
      "Iteration: 4970, Loss: 0.021842\n",
      "Iteration: 4971, Loss: 0.021840\n",
      "Iteration: 4972, Loss: 0.021838\n",
      "Iteration: 4973, Loss: 0.021835\n",
      "Iteration: 4974, Loss: 0.021835\n",
      "Iteration: 4975, Loss: 0.021833\n",
      "Iteration: 4976, Loss: 0.021830\n",
      "Iteration: 4977, Loss: 0.021828\n",
      "Iteration: 4978, Loss: 0.021842\n",
      "Iteration: 4979, Loss: 0.021827\n",
      "Iteration: 4980, Loss: 0.021825\n",
      "Iteration: 4981, Loss: 0.021823\n",
      "Iteration: 4982, Loss: 0.021821\n",
      "Iteration: 4983, Loss: 0.021826\n",
      "Iteration: 4984, Loss: 0.021819\n",
      "Iteration: 4985, Loss: 0.021817\n",
      "Iteration: 4986, Loss: 0.021816\n",
      "Iteration: 4987, Loss: 0.021814\n",
      "Iteration: 4988, Loss: 0.021811\n",
      "Iteration: 4989, Loss: 0.021813\n",
      "Iteration: 4990, Loss: 0.021810\n",
      "Iteration: 4991, Loss: 0.021808\n",
      "Iteration: 4992, Loss: 0.021807\n",
      "Iteration: 4993, Loss: 0.021806\n",
      "Iteration: 4994, Loss: 0.021805\n",
      "Iteration: 4995, Loss: 0.021804\n",
      "Iteration: 4996, Loss: 0.021803\n",
      "Iteration: 4997, Loss: 0.021801\n",
      "Iteration: 4998, Loss: 0.021798\n",
      "Iteration: 4999, Loss: 0.021796\n",
      "Iteration: 5000, Loss: 0.021794\n",
      "Iteration: 5001, Loss: 0.021793\n",
      "Iteration: 5002, Loss: 0.021791\n",
      "Iteration: 5003, Loss: 0.021788\n",
      "Iteration: 5004, Loss: 0.021785\n",
      "Iteration: 5005, Loss: 0.021788\n",
      "Iteration: 5006, Loss: 0.021784\n",
      "Iteration: 5007, Loss: 0.021783\n",
      "Iteration: 5008, Loss: 0.021782\n",
      "Iteration: 5009, Loss: 0.021777\n",
      "Iteration: 5010, Loss: 0.021775\n",
      "Iteration: 5011, Loss: 0.021773\n",
      "Iteration: 5012, Loss: 0.021771\n",
      "Iteration: 5013, Loss: 0.021769\n",
      "Iteration: 5014, Loss: 0.021768\n",
      "Iteration: 5015, Loss: 0.021765\n",
      "Iteration: 5016, Loss: 0.021764\n",
      "Iteration: 5017, Loss: 0.021763\n",
      "Iteration: 5018, Loss: 0.021762\n",
      "Iteration: 5019, Loss: 0.021759\n",
      "Iteration: 5020, Loss: 0.021757\n",
      "Iteration: 5021, Loss: 0.021753\n",
      "Iteration: 5022, Loss: 0.021750\n",
      "Iteration: 5023, Loss: 0.021747\n",
      "Iteration: 5024, Loss: 0.021745\n",
      "Iteration: 5025, Loss: 0.021743\n",
      "Iteration: 5026, Loss: 0.021802\n",
      "Iteration: 5027, Loss: 0.021742\n",
      "Iteration: 5028, Loss: 0.021739\n",
      "Iteration: 5029, Loss: 0.021739\n",
      "Iteration: 5030, Loss: 0.021736\n",
      "Iteration: 5031, Loss: 0.021733\n",
      "Iteration: 5032, Loss: 0.021730\n",
      "Iteration: 5033, Loss: 0.021728\n",
      "Iteration: 5034, Loss: 0.021728\n",
      "Iteration: 5035, Loss: 0.021727\n",
      "Iteration: 5036, Loss: 0.021728\n",
      "Iteration: 5037, Loss: 0.021727\n",
      "Iteration: 5038, Loss: 0.021725\n",
      "Iteration: 5039, Loss: 0.021724\n",
      "Iteration: 5040, Loss: 0.021723\n",
      "Iteration: 5041, Loss: 0.021724\n",
      "Iteration: 5042, Loss: 0.021723\n",
      "Iteration: 5043, Loss: 0.021723\n",
      "Iteration: 5044, Loss: 0.021721\n",
      "Iteration: 5045, Loss: 0.021720\n",
      "Iteration: 5046, Loss: 0.021719\n",
      "Iteration: 5047, Loss: 0.021720\n",
      "Iteration: 5048, Loss: 0.021719\n",
      "Iteration: 5049, Loss: 0.021717\n",
      "Iteration: 5050, Loss: 0.021716\n",
      "Iteration: 5051, Loss: 0.021714\n",
      "Iteration: 5052, Loss: 0.021713\n",
      "Iteration: 5053, Loss: 0.021710\n",
      "Iteration: 5054, Loss: 0.021708\n",
      "Iteration: 5055, Loss: 0.021703\n",
      "Iteration: 5056, Loss: 0.021699\n",
      "Iteration: 5057, Loss: 0.021706\n",
      "Iteration: 5058, Loss: 0.021698\n",
      "Iteration: 5059, Loss: 0.021696\n",
      "Iteration: 5060, Loss: 0.021695\n",
      "Iteration: 5061, Loss: 0.021694\n",
      "Iteration: 5062, Loss: 0.021694\n",
      "Iteration: 5063, Loss: 0.021693\n",
      "Iteration: 5064, Loss: 0.021691\n",
      "Iteration: 5065, Loss: 0.021690\n",
      "Iteration: 5066, Loss: 0.021688\n",
      "Iteration: 5067, Loss: 0.021687\n",
      "Iteration: 5068, Loss: 0.021685\n",
      "Iteration: 5069, Loss: 0.021688\n",
      "Iteration: 5070, Loss: 0.021684\n",
      "Iteration: 5071, Loss: 0.021683\n",
      "Iteration: 5072, Loss: 0.021681\n",
      "Iteration: 5073, Loss: 0.021684\n",
      "Iteration: 5074, Loss: 0.021680\n",
      "Iteration: 5075, Loss: 0.021679\n",
      "Iteration: 5076, Loss: 0.021677\n",
      "Iteration: 5077, Loss: 0.021675\n",
      "Iteration: 5078, Loss: 0.021674\n",
      "Iteration: 5079, Loss: 0.021673\n",
      "Iteration: 5080, Loss: 0.021672\n",
      "Iteration: 5081, Loss: 0.021671\n",
      "Iteration: 5082, Loss: 0.021675\n",
      "Iteration: 5083, Loss: 0.021670\n",
      "Iteration: 5084, Loss: 0.021669\n",
      "Iteration: 5085, Loss: 0.021667\n",
      "Iteration: 5086, Loss: 0.021666\n",
      "Iteration: 5087, Loss: 0.021665\n",
      "Iteration: 5088, Loss: 0.021667\n",
      "Iteration: 5089, Loss: 0.021665\n",
      "Iteration: 5090, Loss: 0.021664\n",
      "Iteration: 5091, Loss: 0.021663\n",
      "Iteration: 5092, Loss: 0.021661\n",
      "Iteration: 5093, Loss: 0.021659\n",
      "Iteration: 5094, Loss: 0.021657\n",
      "Iteration: 5095, Loss: 0.021657\n",
      "Iteration: 5096, Loss: 0.021656\n",
      "Iteration: 5097, Loss: 0.021658\n",
      "Iteration: 5098, Loss: 0.021654\n",
      "Iteration: 5099, Loss: 0.021651\n",
      "Iteration: 5100, Loss: 0.021647\n",
      "Iteration: 5101, Loss: 0.021646\n",
      "Iteration: 5102, Loss: 0.021646\n",
      "Iteration: 5103, Loss: 0.021644\n",
      "Iteration: 5104, Loss: 0.021644\n",
      "Iteration: 5105, Loss: 0.021642\n",
      "Iteration: 5106, Loss: 0.021641\n",
      "Iteration: 5107, Loss: 0.021640\n",
      "Iteration: 5108, Loss: 0.021638\n",
      "Iteration: 5109, Loss: 0.021637\n",
      "Iteration: 5110, Loss: 0.021636\n",
      "Iteration: 5111, Loss: 0.021635\n",
      "Iteration: 5112, Loss: 0.021632\n",
      "Iteration: 5113, Loss: 0.021627\n",
      "Iteration: 5114, Loss: 0.021625\n",
      "Iteration: 5115, Loss: 0.021623\n",
      "Iteration: 5116, Loss: 0.021621\n",
      "Iteration: 5117, Loss: 0.021619\n",
      "Iteration: 5118, Loss: 0.021619\n",
      "Iteration: 5119, Loss: 0.021618\n",
      "Iteration: 5120, Loss: 0.021616\n",
      "Iteration: 5121, Loss: 0.021614\n",
      "Iteration: 5122, Loss: 0.021611\n",
      "Iteration: 5123, Loss: 0.021611\n",
      "Iteration: 5124, Loss: 0.021608\n",
      "Iteration: 5125, Loss: 0.021606\n",
      "Iteration: 5126, Loss: 0.021604\n",
      "Iteration: 5127, Loss: 0.021603\n",
      "Iteration: 5128, Loss: 0.021602\n",
      "Iteration: 5129, Loss: 0.021601\n",
      "Iteration: 5130, Loss: 0.021600\n",
      "Iteration: 5131, Loss: 0.021598\n",
      "Iteration: 5132, Loss: 0.021604\n",
      "Iteration: 5133, Loss: 0.021597\n",
      "Iteration: 5134, Loss: 0.021596\n",
      "Iteration: 5135, Loss: 0.021595\n",
      "Iteration: 5136, Loss: 0.021593\n",
      "Iteration: 5137, Loss: 0.021591\n",
      "Iteration: 5138, Loss: 0.021593\n",
      "Iteration: 5139, Loss: 0.021591\n",
      "Iteration: 5140, Loss: 0.021589\n",
      "Iteration: 5141, Loss: 0.021587\n",
      "Iteration: 5142, Loss: 0.021586\n",
      "Iteration: 5143, Loss: 0.021583\n",
      "Iteration: 5144, Loss: 0.021601\n",
      "Iteration: 5145, Loss: 0.021582\n",
      "Iteration: 5146, Loss: 0.021579\n",
      "Iteration: 5147, Loss: 0.021576\n",
      "Iteration: 5148, Loss: 0.021574\n",
      "Iteration: 5149, Loss: 0.021572\n",
      "Iteration: 5150, Loss: 0.021569\n",
      "Iteration: 5151, Loss: 0.021567\n",
      "Iteration: 5152, Loss: 0.021566\n",
      "Iteration: 5153, Loss: 0.021566\n",
      "Iteration: 5154, Loss: 0.021565\n",
      "Iteration: 5155, Loss: 0.021564\n",
      "Iteration: 5156, Loss: 0.021562\n",
      "Iteration: 5157, Loss: 0.021559\n",
      "Iteration: 5158, Loss: 0.021556\n",
      "Iteration: 5159, Loss: 0.021556\n",
      "Iteration: 5160, Loss: 0.021554\n",
      "Iteration: 5161, Loss: 0.021553\n",
      "Iteration: 5162, Loss: 0.021550\n",
      "Iteration: 5163, Loss: 0.021549\n",
      "Iteration: 5164, Loss: 0.021549\n",
      "Iteration: 5165, Loss: 0.021547\n",
      "Iteration: 5166, Loss: 0.021545\n",
      "Iteration: 5167, Loss: 0.021543\n",
      "Iteration: 5168, Loss: 0.021541\n",
      "Iteration: 5169, Loss: 0.021539\n",
      "Iteration: 5170, Loss: 0.021538\n",
      "Iteration: 5171, Loss: 0.021536\n",
      "Iteration: 5172, Loss: 0.021535\n",
      "Iteration: 5173, Loss: 0.021534\n",
      "Iteration: 5174, Loss: 0.021532\n",
      "Iteration: 5175, Loss: 0.021552\n",
      "Iteration: 5176, Loss: 0.021531\n",
      "Iteration: 5177, Loss: 0.021529\n",
      "Iteration: 5178, Loss: 0.021530\n",
      "Iteration: 5179, Loss: 0.021528\n",
      "Iteration: 5180, Loss: 0.021530\n",
      "Iteration: 5181, Loss: 0.021526\n",
      "Iteration: 5182, Loss: 0.021525\n",
      "Iteration: 5183, Loss: 0.021524\n",
      "Iteration: 5184, Loss: 0.021524\n",
      "Iteration: 5185, Loss: 0.021523\n",
      "Iteration: 5186, Loss: 0.021523\n",
      "Iteration: 5187, Loss: 0.021523\n",
      "Iteration: 5188, Loss: 0.021522\n",
      "Iteration: 5189, Loss: 0.021522\n",
      "Iteration: 5190, Loss: 0.021521\n",
      "Iteration: 5191, Loss: 0.021520\n",
      "Iteration: 5192, Loss: 0.021520\n",
      "Iteration: 5193, Loss: 0.021519\n",
      "Iteration: 5194, Loss: 0.021519\n",
      "Iteration: 5195, Loss: 0.021518\n",
      "Iteration: 5196, Loss: 0.021516\n",
      "Iteration: 5197, Loss: 0.021515\n",
      "Iteration: 5198, Loss: 0.021513\n",
      "Iteration: 5199, Loss: 0.021512\n",
      "Iteration: 5200, Loss: 0.021508\n",
      "Iteration: 5201, Loss: 0.021505\n",
      "Iteration: 5202, Loss: 0.021501\n",
      "Iteration: 5203, Loss: 0.021519\n",
      "Iteration: 5204, Loss: 0.021500\n",
      "Iteration: 5205, Loss: 0.021499\n",
      "Iteration: 5206, Loss: 0.021494\n",
      "Iteration: 5207, Loss: 0.021490\n",
      "Iteration: 5208, Loss: 0.021487\n",
      "Iteration: 5209, Loss: 0.021483\n",
      "Iteration: 5210, Loss: 0.021480\n",
      "Iteration: 5211, Loss: 0.021473\n",
      "Iteration: 5212, Loss: 0.021555\n",
      "Iteration: 5213, Loss: 0.021472\n",
      "Iteration: 5214, Loss: 0.021469\n",
      "Iteration: 5215, Loss: 0.021480\n",
      "Iteration: 5216, Loss: 0.021468\n",
      "Iteration: 5217, Loss: 0.021464\n",
      "Iteration: 5218, Loss: 0.021461\n",
      "Iteration: 5219, Loss: 0.021461\n",
      "Iteration: 5220, Loss: 0.021460\n",
      "Iteration: 5221, Loss: 0.021459\n",
      "Iteration: 5222, Loss: 0.021457\n",
      "Iteration: 5223, Loss: 0.021456\n",
      "Iteration: 5224, Loss: 0.021454\n",
      "Iteration: 5225, Loss: 0.021452\n",
      "Iteration: 5226, Loss: 0.021450\n",
      "Iteration: 5227, Loss: 0.021448\n",
      "Iteration: 5228, Loss: 0.021447\n",
      "Iteration: 5229, Loss: 0.021447\n",
      "Iteration: 5230, Loss: 0.021445\n",
      "Iteration: 5231, Loss: 0.021442\n",
      "Iteration: 5232, Loss: 0.021440\n",
      "Iteration: 5233, Loss: 0.021439\n",
      "Iteration: 5234, Loss: 0.021437\n",
      "Iteration: 5235, Loss: 0.021435\n",
      "Iteration: 5236, Loss: 0.021433\n",
      "Iteration: 5237, Loss: 0.021430\n",
      "Iteration: 5238, Loss: 0.021425\n",
      "Iteration: 5239, Loss: 0.021422\n",
      "Iteration: 5240, Loss: 0.021455\n",
      "Iteration: 5241, Loss: 0.021421\n",
      "Iteration: 5242, Loss: 0.021420\n",
      "Iteration: 5243, Loss: 0.021417\n",
      "Iteration: 5244, Loss: 0.021416\n",
      "Iteration: 5245, Loss: 0.021415\n",
      "Iteration: 5246, Loss: 0.021414\n",
      "Iteration: 5247, Loss: 0.021412\n",
      "Iteration: 5248, Loss: 0.021408\n",
      "Iteration: 5249, Loss: 0.021404\n",
      "Iteration: 5250, Loss: 0.021402\n",
      "Iteration: 5251, Loss: 0.021399\n",
      "Iteration: 5252, Loss: 0.021398\n",
      "Iteration: 5253, Loss: 0.021396\n",
      "Iteration: 5254, Loss: 0.021394\n",
      "Iteration: 5255, Loss: 0.021394\n",
      "Iteration: 5256, Loss: 0.021391\n",
      "Iteration: 5257, Loss: 0.021390\n",
      "Iteration: 5258, Loss: 0.021388\n",
      "Iteration: 5259, Loss: 0.021385\n",
      "Iteration: 5260, Loss: 0.021382\n",
      "Iteration: 5261, Loss: 0.021381\n",
      "Iteration: 5262, Loss: 0.021380\n",
      "Iteration: 5263, Loss: 0.021379\n",
      "Iteration: 5264, Loss: 0.021377\n",
      "Iteration: 5265, Loss: 0.021378\n",
      "Iteration: 5266, Loss: 0.021377\n",
      "Iteration: 5267, Loss: 0.021375\n",
      "Iteration: 5268, Loss: 0.021374\n",
      "Iteration: 5269, Loss: 0.021372\n",
      "Iteration: 5270, Loss: 0.021372\n",
      "Iteration: 5271, Loss: 0.021392\n",
      "Iteration: 5272, Loss: 0.021372\n",
      "Iteration: 5273, Loss: 0.021370\n",
      "Iteration: 5274, Loss: 0.021368\n",
      "Iteration: 5275, Loss: 0.021366\n",
      "Iteration: 5276, Loss: 0.021366\n",
      "Iteration: 5277, Loss: 0.021365\n",
      "Iteration: 5278, Loss: 0.021364\n",
      "Iteration: 5279, Loss: 0.021363\n",
      "Iteration: 5280, Loss: 0.021362\n",
      "Iteration: 5281, Loss: 0.021362\n",
      "Iteration: 5282, Loss: 0.021362\n",
      "Iteration: 5283, Loss: 0.021361\n",
      "Iteration: 5284, Loss: 0.021360\n",
      "Iteration: 5285, Loss: 0.021358\n",
      "Iteration: 5286, Loss: 0.021357\n",
      "Iteration: 5287, Loss: 0.021356\n",
      "Iteration: 5288, Loss: 0.021355\n",
      "Iteration: 5289, Loss: 0.021354\n",
      "Iteration: 5290, Loss: 0.021353\n",
      "Iteration: 5291, Loss: 0.021351\n",
      "Iteration: 5292, Loss: 0.021348\n",
      "Iteration: 5293, Loss: 0.021514\n",
      "Iteration: 5294, Loss: 0.021348\n",
      "Iteration: 5295, Loss: 0.021346\n",
      "Iteration: 5296, Loss: 0.021343\n",
      "Iteration: 5297, Loss: 0.021339\n",
      "Iteration: 5298, Loss: 0.021337\n",
      "Iteration: 5299, Loss: 0.021336\n",
      "Iteration: 5300, Loss: 0.021333\n",
      "Iteration: 5301, Loss: 0.021332\n",
      "Iteration: 5302, Loss: 0.021331\n",
      "Iteration: 5303, Loss: 0.021329\n",
      "Iteration: 5304, Loss: 0.021327\n",
      "Iteration: 5305, Loss: 0.021323\n",
      "Iteration: 5306, Loss: 0.021321\n",
      "Iteration: 5307, Loss: 0.021318\n",
      "Iteration: 5308, Loss: 0.021317\n",
      "Iteration: 5309, Loss: 0.021316\n",
      "Iteration: 5310, Loss: 0.021315\n",
      "Iteration: 5311, Loss: 0.021313\n",
      "Iteration: 5312, Loss: 0.021309\n",
      "Iteration: 5313, Loss: 0.021315\n",
      "Iteration: 5314, Loss: 0.021309\n",
      "Iteration: 5315, Loss: 0.021306\n",
      "Iteration: 5316, Loss: 0.021319\n",
      "Iteration: 5317, Loss: 0.021305\n",
      "Iteration: 5318, Loss: 0.021303\n",
      "Iteration: 5319, Loss: 0.021350\n",
      "Iteration: 5320, Loss: 0.021302\n",
      "Iteration: 5321, Loss: 0.021301\n",
      "Iteration: 5322, Loss: 0.021299\n",
      "Iteration: 5323, Loss: 0.021296\n",
      "Iteration: 5324, Loss: 0.021293\n",
      "Iteration: 5325, Loss: 0.021291\n",
      "Iteration: 5326, Loss: 0.021290\n",
      "Iteration: 5327, Loss: 0.021287\n",
      "Iteration: 5328, Loss: 0.021284\n",
      "Iteration: 5329, Loss: 0.021282\n",
      "Iteration: 5330, Loss: 0.021278\n",
      "Iteration: 5331, Loss: 0.021287\n",
      "Iteration: 5332, Loss: 0.021274\n",
      "Iteration: 5333, Loss: 0.021268\n",
      "Iteration: 5334, Loss: 0.021264\n",
      "Iteration: 5335, Loss: 0.021268\n",
      "Iteration: 5336, Loss: 0.021263\n",
      "Iteration: 5337, Loss: 0.021262\n",
      "Iteration: 5338, Loss: 0.021260\n",
      "Iteration: 5339, Loss: 0.021257\n",
      "Iteration: 5340, Loss: 0.021252\n",
      "Iteration: 5341, Loss: 0.021255\n",
      "Iteration: 5342, Loss: 0.021251\n",
      "Iteration: 5343, Loss: 0.021248\n",
      "Iteration: 5344, Loss: 0.021247\n",
      "Iteration: 5345, Loss: 0.021245\n",
      "Iteration: 5346, Loss: 0.021248\n",
      "Iteration: 5347, Loss: 0.021245\n",
      "Iteration: 5348, Loss: 0.021243\n",
      "Iteration: 5349, Loss: 0.021240\n",
      "Iteration: 5350, Loss: 0.021237\n",
      "Iteration: 5351, Loss: 0.021232\n",
      "Iteration: 5352, Loss: 0.021235\n",
      "Iteration: 5353, Loss: 0.021231\n",
      "Iteration: 5354, Loss: 0.021227\n",
      "Iteration: 5355, Loss: 0.021222\n",
      "Iteration: 5356, Loss: 0.021217\n",
      "Iteration: 5357, Loss: 0.021212\n",
      "Iteration: 5358, Loss: 0.021208\n",
      "Iteration: 5359, Loss: 0.021204\n",
      "Iteration: 5360, Loss: 0.021203\n",
      "Iteration: 5361, Loss: 0.021200\n",
      "Iteration: 5362, Loss: 0.021198\n",
      "Iteration: 5363, Loss: 0.021197\n",
      "Iteration: 5364, Loss: 0.021195\n",
      "Iteration: 5365, Loss: 0.021195\n",
      "Iteration: 5366, Loss: 0.021192\n",
      "Iteration: 5367, Loss: 0.021189\n",
      "Iteration: 5368, Loss: 0.021186\n",
      "Iteration: 5369, Loss: 0.021182\n",
      "Iteration: 5370, Loss: 0.021181\n",
      "Iteration: 5371, Loss: 0.021176\n",
      "Iteration: 5372, Loss: 0.021175\n",
      "Iteration: 5373, Loss: 0.021174\n",
      "Iteration: 5374, Loss: 0.021209\n",
      "Iteration: 5375, Loss: 0.021173\n",
      "Iteration: 5376, Loss: 0.021172\n",
      "Iteration: 5377, Loss: 0.021170\n",
      "Iteration: 5378, Loss: 0.021170\n",
      "Iteration: 5379, Loss: 0.021168\n",
      "Iteration: 5380, Loss: 0.021168\n",
      "Iteration: 5381, Loss: 0.021166\n",
      "Iteration: 5382, Loss: 0.021165\n",
      "Iteration: 5383, Loss: 0.021163\n",
      "Iteration: 5384, Loss: 0.021162\n",
      "Iteration: 5385, Loss: 0.021160\n",
      "Iteration: 5386, Loss: 0.021162\n",
      "Iteration: 5387, Loss: 0.021158\n",
      "Iteration: 5388, Loss: 0.021157\n",
      "Iteration: 5389, Loss: 0.021154\n",
      "Iteration: 5390, Loss: 0.021152\n",
      "Iteration: 5391, Loss: 0.021148\n",
      "Iteration: 5392, Loss: 0.021154\n",
      "Iteration: 5393, Loss: 0.021147\n",
      "Iteration: 5394, Loss: 0.021145\n",
      "Iteration: 5395, Loss: 0.021144\n",
      "Iteration: 5396, Loss: 0.021143\n",
      "Iteration: 5397, Loss: 0.021141\n",
      "Iteration: 5398, Loss: 0.021137\n",
      "Iteration: 5399, Loss: 0.021136\n",
      "Iteration: 5400, Loss: 0.021145\n",
      "Iteration: 5401, Loss: 0.021135\n",
      "Iteration: 5402, Loss: 0.021134\n",
      "Iteration: 5403, Loss: 0.021134\n",
      "Iteration: 5404, Loss: 0.021162\n",
      "Iteration: 5405, Loss: 0.021133\n",
      "Iteration: 5406, Loss: 0.021133\n",
      "Iteration: 5407, Loss: 0.021131\n",
      "Iteration: 5408, Loss: 0.021130\n",
      "Iteration: 5409, Loss: 0.021129\n",
      "Iteration: 5410, Loss: 0.021128\n",
      "Iteration: 5411, Loss: 0.021127\n",
      "Iteration: 5412, Loss: 0.021125\n",
      "Iteration: 5413, Loss: 0.021122\n",
      "Iteration: 5414, Loss: 0.021120\n",
      "Iteration: 5415, Loss: 0.021119\n",
      "Iteration: 5416, Loss: 0.021117\n",
      "Iteration: 5417, Loss: 0.021118\n",
      "Iteration: 5418, Loss: 0.021116\n",
      "Iteration: 5419, Loss: 0.021114\n",
      "Iteration: 5420, Loss: 0.021112\n",
      "Iteration: 5421, Loss: 0.021110\n",
      "Iteration: 5422, Loss: 0.021109\n",
      "Iteration: 5423, Loss: 0.021107\n",
      "Iteration: 5424, Loss: 0.021105\n",
      "Iteration: 5425, Loss: 0.021103\n",
      "Iteration: 5426, Loss: 0.021099\n",
      "Iteration: 5427, Loss: 0.021097\n",
      "Iteration: 5428, Loss: 0.021093\n",
      "Iteration: 5429, Loss: 0.021098\n",
      "Iteration: 5430, Loss: 0.021092\n",
      "Iteration: 5431, Loss: 0.021088\n",
      "Iteration: 5432, Loss: 0.021086\n",
      "Iteration: 5433, Loss: 0.021086\n",
      "Iteration: 5434, Loss: 0.021085\n",
      "Iteration: 5435, Loss: 0.021084\n",
      "Iteration: 5436, Loss: 0.021082\n",
      "Iteration: 5437, Loss: 0.021080\n",
      "Iteration: 5438, Loss: 0.021091\n",
      "Iteration: 5439, Loss: 0.021079\n",
      "Iteration: 5440, Loss: 0.021078\n",
      "Iteration: 5441, Loss: 0.021077\n",
      "Iteration: 5442, Loss: 0.021075\n",
      "Iteration: 5443, Loss: 0.021073\n",
      "Iteration: 5444, Loss: 0.021071\n",
      "Iteration: 5445, Loss: 0.021076\n",
      "Iteration: 5446, Loss: 0.021070\n",
      "Iteration: 5447, Loss: 0.021068\n",
      "Iteration: 5448, Loss: 0.021066\n",
      "Iteration: 5449, Loss: 0.021064\n",
      "Iteration: 5450, Loss: 0.021062\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train on GPU\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpinn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 98\u001b[0m, in \u001b[0;36mNavierStokes.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# training loop\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lbfgs.py:428\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[1;32m--> 428\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m    431\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lbfgs.py:50\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[1;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[0;32m     48\u001b[0m g \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# evaluate objective and gradient using initial step\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     52\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[1;34m(x, t, d)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lbfgs.py:280\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[1;34m(self, closure, x, t, d)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m--> 280\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    281\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 86\u001b[0m, in \u001b[0;36mNavierStokes.closure\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls \u001b[38;5;241m=\u001b[39m u_loss \u001b[38;5;241m+\u001b[39m v_loss \u001b[38;5;241m+\u001b[39m f_loss \u001b[38;5;241m+\u001b[39mg_loss\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# derivative with respect to net's weights:\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mihir Chauhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train on GPU\n",
    "pinn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor(x_test, dtype=torch.float32, requires_grad=True)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, requires_grad=True)\n",
    "t_test = torch.tensor(t_test, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pinn.net.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_out, v_out, p_out, f_out, g_out = pinn.function(x_test, y_test, t_test)\n",
    "\n",
    "u_plot = p_out.data.cpu().numpy()\n",
    "u_plot = np.reshape(u_plot, (50, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x29e81d6d910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.contourf(u_plot, levels=30, cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(i):\n",
    "    ax.clear()\n",
    "    u_out, v_out, p_out, f_out, g_out = pinn.function(x_test, y_test, i*t_test)\n",
    "    u_plot = p_out.data.cpu().numpy()\n",
    "    u_plot = np.reshape(u_plot, (50, 100))\n",
    "    cax = ax.contourf(u_plot, levels=20, cmap='jet')\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.xlabel(r'$y$')\n",
    "    plt.title(r'$p(x,\\; y, \\; t)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "# Call animate method\n",
    "ani = animation.FuncAnimation(fig, animate, 20, interval=1, blit=False)\n",
    "ani.save('p_field_lbfgs.gif')\n",
    "plt.close()\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
